{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master's programs: N = 55439\n"
     ]
    }
   ],
   "source": [
    "mas_dat = pd.read_excel(\"mas_dat.xlsx\")\n",
    "\n",
    "mas_dat['UID'] = mas_dat['UID'].astype(str).str.zfill(9)\n",
    "mas_dat['Dept_code'] = mas_dat['Dept_code'].astype(str).str.zfill(4)\n",
    "\n",
    "print(\"Master's programs: N =\",\n",
    "     len(mas_dat['UID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove potential SIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclude potential summer-melt students who only had one row of record: N = 54491\n"
     ]
    }
   ],
   "source": [
    "mas_dat = mas_dat.groupby('UID').filter(\n",
    "    lambda x: not (len(x) == 1 and (x['GPA'] == 0).all())\n",
    ")\n",
    "\n",
    "print(\"Exclude potential summer-melt students who only had one row of record: N =\",\n",
    "     len(mas_dat['UID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix associated majors & keep students with one degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pursue only one degree: N = 53263\n"
     ]
    }
   ],
   "source": [
    "associated_majors = pd.read_excel(\"Associated Majors.xlsx\").dropna().sort_values(by='Associated Major Group')\n",
    "\n",
    "# Create a lookup table with the standard major code and name for each associated major group\n",
    "standard_majors = associated_majors.groupby('Associated Major Group').agg(\n",
    "    Standard_Major_Code=('Major Code', 'last'),\n",
    "    Standard_Major_Name=('Major Name', 'last')\n",
    ").reset_index()\n",
    "\n",
    "# Join the data frame `mas_dat` with the associated_majors\n",
    "mas_dat2 = pd.merge(mas_dat, associated_majors, left_on='Dept_code', right_on='Major Code', how='left')\n",
    "mas_dat2 = pd.merge(mas_dat2, standard_majors, on='Associated Major Group', how='left')\n",
    "\n",
    "# Replace Major_Code and Major_Name with the coalesced values\n",
    "mas_dat2['Major_Code'] = mas_dat2['Standard_Major_Code'].combine_first(mas_dat2['Dept_code'])\n",
    "mas_dat2['Major_Name'] = mas_dat2['Standard_Major_Name'].combine_first(mas_dat2['Dept'])\n",
    "\n",
    "# Select specific columns\n",
    "mas_dat2 = mas_dat2.iloc[:, list(range(2)) + [18, 19] + list(range(4, 13))]\n",
    "\n",
    "# Rename columns\n",
    "mas_dat2.columns.values[2] = 'Dept_code'\n",
    "mas_dat2.columns.values[3] = 'Dept'\n",
    "\n",
    "\n",
    "# Find students with only one degree\n",
    "num_dept = mas_dat2.groupby('UID')['Dept_code'].nunique().reset_index()\n",
    "sgl_depts_UID = num_dept[num_dept['Dept_code'] == 1]['UID']\n",
    "\n",
    "# Filter for single department\n",
    "mas_dat2 = mas_dat2[ (mas_dat2['UID'].isin(sgl_depts_UID)) & (mas_dat2['Dept_code'] != '0001') ]\n",
    "\n",
    "# Exclude students who mastered out from a PhD program\n",
    "mas_dat2 = mas_dat2[~mas_dat2['UID'].isin(['403133806', '903535472'])]\n",
    "\n",
    "print('Pursue only one degree: N =',\n",
    "     len(mas_dat2['UID'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix different ADMIT_TERM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add accurate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find accurate ADMIT_TERM from accurate database\n",
    "mas_accurate = pd.read_excel(\"Mas_Accurate.xlsx\")\n",
    "mas_accurate['UID'] = mas_accurate['UID'].astype(str).str.zfill(9)\n",
    "mas_accurate['Dept_code'] = mas_accurate['Dept_code'].astype(str).str.zfill(4)\n",
    "\n",
    "## Merging data\n",
    "mas_accurate = pd.merge(mas_accurate, associated_majors, left_on='Dept_code', right_on='Major Code', how='left')\n",
    "mas_accurate = pd.merge(mas_accurate, standard_majors, on='Associated Major Group', how='left')\n",
    "\n",
    "## Combining and reordering columns\n",
    "mas_accurate['Major_Code'] = mas_accurate['Standard_Major_Code'].combine_first(mas_accurate['Dept_code'])\n",
    "mas_accurate = mas_accurate.iloc[:, [0, 9] + [2, 3]]\n",
    "mas_accurate.columns.values[1] = 'Dept_code'\n",
    "\n",
    "\n",
    "## Custom sort function\n",
    "def custom_sort(term):\n",
    "    term = str(term)  # Ensure term is a string\n",
    "    year = int(term[1:])  # Extract the year (numeric part)\n",
    "    term_order = {'W': 0, 'S': 1, 'F': 2, 'X': 3}  # Define the order of the term type\n",
    "    term_type_order = term_order.get(term[0], 999)  # Get the order index for the term type\n",
    "    return (year, term_type_order)  # Return a tuple with year first, then term type order\n",
    "\n",
    "## Clean conflicting DEG_TERMs and ADMIT_TERMs for each student\n",
    "def process_group(group):\n",
    "    group = group.sort_values(by='ADMIT_TERM', key=lambda x: x.map(custom_sort))\n",
    "    \n",
    "    deg_term_non_na = group['DEG_TERM'].dropna()\n",
    "    \n",
    "    if group['DEG_TERM'].isna().sum() > 0:            # Have NA DEG_TERMs\n",
    "        if not deg_term_non_na.empty:                   # Include at least one non-NA DEG_TERM (Same major name changed)\n",
    "            admit_term = group['ADMIT_TERM'].iloc[0]       # Earliest ADMIT_TERM\n",
    "            deg_term = deg_term_non_na.iloc[-1]              # Latest non-NA DEG_TERM\n",
    "        else:                                           # All NAs: just take first pair\n",
    "            admit_term = group['ADMIT_TERM'].iloc[0] \n",
    "            deg_term = group['DEG_TERM'].iloc[0]\n",
    "    elif group['DEG_TERM'].isna().sum() == 0:         # Have 2 non-NA DEG_TERMs (2 degrees)\n",
    "        if group['Dept_code'].iloc[0] == '0249':        # Just consider the 1st degree\n",
    "            admit_term = group['ADMIT_TERM'].iloc[0]  \n",
    "            deg_term = group['DEG_TERM'].iloc[0]            \n",
    "        else:                                         # Lasted for that long\n",
    "            admit_term = group['ADMIT_TERM'].iloc[0]        # First ADMIT_TERM\n",
    "            deg_term = group['DEG_TERM'].iloc[-1]           # Last DEG_TERM\n",
    "    \n",
    "    group['ADMIT_TERM'] = admit_term\n",
    "    group['DEG_TERM'] = deg_term\n",
    "    return group\n",
    "\n",
    "mas_accurate = mas_accurate.groupby(['UID', 'Dept_code']).apply(process_group).reset_index(drop=True)\n",
    "\n",
    "## Fill Term NAs with non-NaN value for each student\n",
    "def fill_term_nans(group):\n",
    "    group['ADMIT_TERM'] = group.groupby('UID')['ADMIT_TERM'].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n",
    "    group['DEG_TERM'] = group.groupby('UID')['DEG_TERM'].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n",
    "    return group\n",
    "\n",
    "mas_accurate = mas_accurate.groupby(['UID', 'Dept_code']).apply(fill_term_nans).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Update summer terms\n",
    "def replace_first_char(term):\n",
    "    if pd.isna(term):  # Check if the term is NaN\n",
    "        return term\n",
    "    term = str(term)  # Ensure the term is treated as a string\n",
    "    if term[0] in ['1', '2']:\n",
    "        return 'X' + term[1:]\n",
    "    return term\n",
    "\n",
    "mas_accurate['ADMIT_TERM'] = mas_accurate['ADMIT_TERM'].apply(replace_first_char)\n",
    "mas_accurate['DEG_TERM'] = mas_accurate['DEG_TERM'].apply(replace_first_char)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If mas_dat2 included in mas_accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mas_accurate = pd.merge(mas_dat2, mas_accurate, on=['UID', 'Dept_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If ADMIT_TERM_y = any ADMIT_TERM_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_admit_match = in_mas_accurate[in_mas_accurate['ADMIT_TERM_x'] == in_mas_accurate['ADMIT_TERM_y']]\n",
    "\n",
    "# Choose first-year info\n",
    "xy_admit_match = (xy_admit_match\n",
    "                  .groupby('UID', group_keys=False)  # Group by UID\n",
    "                  .apply(lambda x: x.sort_values(by='ENR_TERM', key=lambda col: col.map(custom_sort))))\n",
    "xy_admit_match_chosen_admit_info = xy_admit_match.drop_duplicates(subset='UID', keep='first')[['UID', 'st_required', 'prev_deg', 'TIME_DEG', 'URM', 'Non_Male', 'STEM', 'ADMIT_TERM_y', 'DEG_TERM_y']]\n",
    "xy_admit_match_chosen_admit_info.columns = [col.replace('_y', '') for col in xy_admit_match_chosen_admit_info.columns]\n",
    "\n",
    "# Add into complete xy_admit_match\n",
    "xy_admit_match = pd.merge(xy_admit_match, xy_admit_match_chosen_admit_info, how = 'left', on = ['UID'], suffixes=('', '_chosen'))\n",
    "\n",
    "# Clean\n",
    "required_columns = ['UID', 'Dept_code', 'Dept', 'ENR_TERM', 'GPA', 'ADMIT_TERM', 'DEG_TERM']\n",
    "chosen_columns = [col for col in xy_admit_match.columns if col.endswith('_chosen')]\n",
    "all_columns = required_columns + chosen_columns\n",
    "xy_admit_match = xy_admit_match[all_columns]\n",
    "xy_admit_match.columns = [col.replace('_chosen', '') for col in xy_admit_match.columns]\n",
    "xy_admit_match = xy_admit_match.reindex(sorted(xy_admit_match.columns), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If ADMIT_TERM_y != any ADMIT_TERM_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_admit_no_match = in_mas_accurate[~in_mas_accurate['UID'].isin(xy_admit_match['UID'])]\n",
    "\n",
    "# Choose first-year info (except for st_required)\n",
    "xy_admit_no_match = (xy_admit_no_match\n",
    "                     .groupby('UID', group_keys=False)  # Group by UID\n",
    "                     .apply(lambda x: x.sort_values(by='ENR_TERM', key=lambda col: col.map(custom_sort))))\n",
    "xy_admit_no_match_chosen_admit_info = xy_admit_no_match.drop_duplicates(subset='UID', keep='first')[['UID', 'prev_deg', 'TIME_DEG', 'URM', 'Non_Male', 'STEM', 'ADMIT_TERM_y', 'DEG_TERM_y']]\n",
    "xy_admit_no_match_chosen_admit_info.columns = [col.replace('_y', '') for col in xy_admit_no_match_chosen_admit_info.columns]\n",
    "\n",
    "# Add into complete xy_admit_no_match\n",
    "xy_admit_no_match = pd.merge(xy_admit_no_match, xy_admit_no_match_chosen_admit_info, how = 'left', on = ['UID'], suffixes=('', '_chosen'))\n",
    "\n",
    "# Clean\n",
    "required_columns = ['UID', 'Dept_code', 'Dept', 'ENR_TERM', 'GPA', 'ADMIT_TERM', 'DEG_TERM']\n",
    "chosen_columns = [col for col in xy_admit_no_match.columns if col.endswith('_chosen')]\n",
    "all_columns = required_columns + chosen_columns\n",
    "xy_admit_no_match = xy_admit_no_match[all_columns]\n",
    "xy_admit_no_match.columns = [col.replace('_chosen', '') for col in xy_admit_no_match.columns]\n",
    "xy_admit_no_match = xy_admit_no_match.reindex(sorted(xy_admit_no_match.columns), axis=1)\n",
    "\n",
    "\n",
    "# Add st_required\n",
    "\n",
    "## Match accurate ADMIT_TERM w/ original Dept_code\n",
    "original_Dept = mas_dat[mas_dat['UID'].isin(xy_admit_no_match['UID'])][['UID', 'Dept_code']].drop_duplicates()\n",
    "original_Dept_admit = pd.merge(original_Dept, xy_admit_no_match, how = 'right', on = ['UID'])[['UID', 'Dept_code_y', 'ADMIT_TERM']].drop_duplicates()\n",
    "original_Dept_admit.columns = [col.replace('_y', '') for col in original_Dept_admit.columns]\n",
    "\n",
    "## Get st_required from Mas_ST_by_Dept_Term, based on \n",
    "Mas_ST_by_Dept_Term = pd.read_excel(\"Mas_ST_by_Dept_Term.xlsx\")\n",
    "Mas_ST_by_Dept_Term['Dept_code'] = Mas_ST_by_Dept_Term['Dept_code'].astype(str).str.zfill(4)\n",
    "\n",
    "\n",
    "\n",
    "## Merge original_Dept_admit and Mas_ST_by_Dept_Term\n",
    "original_Dept_admit['Year'] = original_Dept_admit['ADMIT_TERM'].str[1:].astype(int)\n",
    "original_Dept_admit['TermType'] = original_Dept_admit['ADMIT_TERM'].str[0]\n",
    "\n",
    "Mas_ST_by_Dept_Term['AcademicYear'] = Mas_ST_by_Dept_Term['AcademicYear'].astype(str)\n",
    "Mas_ST_by_Dept_Term['YearStart'] = Mas_ST_by_Dept_Term['AcademicYear'].str[:4].astype(int)\n",
    "Mas_ST_by_Dept_Term['YearEnd'] = Mas_ST_by_Dept_Term['AcademicYear'].str[4:].astype(int)\n",
    "\n",
    "merged = pd.merge(\n",
    "    original_Dept_admit,\n",
    "    Mas_ST_by_Dept_Term,\n",
    "    how='left',\n",
    "    left_on='Dept_code',\n",
    "    right_on='Dept_code'\n",
    ")\n",
    "\n",
    "condition1 = (merged['Year'] == merged['YearStart']) & (merged['TermType'].isin(['F', 'X']))\n",
    "condition2 = (merged['Year'] == merged['YearEnd']) & (merged['TermType'].isin(['W', 'S']))\n",
    "\n",
    "original_Dept_admit_st = merged[condition1 | condition2][['UID', 'st_required']].drop_duplicates()\n",
    "\n",
    "## Add into xy_admit_no_match\n",
    "xy_admit_no_match = pd.merge(xy_admit_no_match, original_Dept_admit_st, how = 'left', on = ['UID'])\n",
    "\n",
    "\n",
    "# Clean\n",
    "xy_admit_no_match = xy_admit_no_match.reindex(sorted(xy_admit_no_match.columns), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If mas_dat2 not included in mas_accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_mas_accurate = mas_dat2[~mas_dat2['UID'].isin(in_mas_accurate['UID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple ADMIT_TERM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_admit_term = not_in_mas_accurate.groupby('UID').filter(lambda x: x['ADMIT_TERM'].nunique() > 1)\n",
    "\n",
    "\n",
    "def calculate_quarters(admit_term, deg_term, current_time_deg):\n",
    "    # Define the term order within a year\n",
    "    term_order = {'W': 0, 'S': 1, 'F': 2, 'X': 3}\n",
    "    \n",
    "    # Handle the case where deg_term starts with 'X'\n",
    "    if pd.notna(deg_term) and deg_term.startswith('X'):\n",
    "        deg_term = 'F' + deg_term[1:]  # Replace 'X' with 'F'\n",
    "\n",
    "    # Ensure terms are strings and handle NaNs\n",
    "    if pd.notna(deg_term):  # Only calculate if DEG_TERM is not NaN\n",
    "        admit_term = str(admit_term)\n",
    "        deg_term = str(deg_term)\n",
    "\n",
    "        # Extract the year and quarter information\n",
    "        admit_year = int(admit_term[1:])  # Year part of ADMIT_TERM\n",
    "        admit_quarter = term_order.get(admit_term[0], -1)  # Quarter part of ADMIT_TERM\n",
    "\n",
    "        deg_year = int(deg_term[1:])  # Year part of DEG_TERM\n",
    "        deg_quarter = term_order.get(deg_term[0], -1)  # Quarter part of DEG_TERM\n",
    "\n",
    "        # Calculate the total number of quarters\n",
    "        total_quarters = (deg_year - admit_year) * 3 + (deg_quarter - admit_quarter) + 1\n",
    "\n",
    "        return total_quarters\n",
    "    else:\n",
    "        return current_time_deg  # Keep the original value if DEG_TERM is NaN\n",
    "\n",
    "\n",
    "    \n",
    "# Calculate the distance for each row\n",
    "multi_admit_term['distance'] = multi_admit_term.apply(\n",
    "    lambda row: calculate_quarters(row['ADMIT_TERM'], row['ENR_TERM'], row['TIME_DEG']), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# For each UID, select the ADMIT_TERM with the smallest non-negative distance\n",
    "def select_best_admit_term(group):\n",
    "    # Filter for non-negative distances\n",
    "    group = group[group['distance'] >= 0]\n",
    "    # If there's a tie, take the one that occurred before the first ENR_TERM\n",
    "    if len(group) > 1:\n",
    "        min_distance = group['distance'].min()\n",
    "        group = group[group['distance'] == min_distance]\n",
    "        group = group.sort_values(by='ADMIT_TERM', ascending=True)  # Sort ADMIT_TERM to pick the earliest one\n",
    "    return group.iloc[0]  # Return the row with the best ADMIT_TERM\n",
    "\n",
    "best_admit_terms = multi_admit_term.groupby('UID').apply(select_best_admit_term).reset_index(drop=True)[['UID', 'ADMIT_TERM', 'DEG_TERM', 'Non_Male', 'STEM', 'TIME_DEG', 'URM', 'prev_deg', 'st_required']].drop_duplicates()\n",
    "\n",
    "multi_admit_term = multi_admit_term.drop(columns=['ADMIT_TERM']).merge(\n",
    "    best_admit_terms,\n",
    "    on='UID',\n",
    "    how='left',\n",
    "    suffixes=('', '_chosen')\n",
    ")\n",
    "\n",
    "# Clean\n",
    "required_columns = ['UID', 'Dept_code', 'Dept', 'ENR_TERM', 'GPA', 'ADMIT_TERM']\n",
    "chosen_columns = [col for col in multi_admit_term.columns if col.endswith('_chosen')]\n",
    "all_columns = required_columns + chosen_columns\n",
    "multi_admit_term = multi_admit_term[all_columns]\n",
    "multi_admit_term.columns = [col.replace('_chosen', '') for col in multi_admit_term.columns]\n",
    "multi_admit_term = multi_admit_term.reindex(sorted(multi_admit_term.columns), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single ADMIT_TERM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgl_admit_term = not_in_mas_accurate.groupby('UID').filter(lambda x: x['ADMIT_TERM'].nunique() == 1)\n",
    "\n",
    "# Take first ENR_TERM info\n",
    "def sync_columns_to_first_row(group):\n",
    "    # Sort the group by ENR_TERM using the custom sort function\n",
    "    group = group.sort_values(by='ENR_TERM', key=lambda x: x.apply(custom_sort))\n",
    "    \n",
    "    # Get the values from the first row\n",
    "    first_row = group.iloc[0]\n",
    "    \n",
    "    # List of columns to sync\n",
    "    columns_to_sync = ['Non_Male', 'STEM', 'TIME_DEG', 'URM', 'prev_deg', 'st_required']\n",
    "    \n",
    "    # Sync the columns to all rows in the group\n",
    "    for column in columns_to_sync:\n",
    "        group[column] = first_row[column]\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the syncing function to each group\n",
    "sgl_admit_term = sgl_admit_term.groupby('UID').apply(sync_columns_to_first_row).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Clean\n",
    "sgl_admit_term = sgl_admit_term.drop_duplicates()\n",
    "sgl_admit_term = sgl_admit_term.reset_index(drop=True)\n",
    "sgl_admit_term = sgl_admit_term.reindex(sorted(sgl_admit_term.columns), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine fixed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas_dat2 = pd.concat([xy_admit_match,\n",
    "                     xy_admit_no_match,\n",
    "                     multi_admit_term,\n",
    "                     sgl_admit_term])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix TTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas_dat2['TIME_DEG'] = mas_dat2.apply(\n",
    "    lambda row: calculate_quarters(row['ADMIT_TERM'], row['DEG_TERM'], row['TIME_DEG']), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unknown ST requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST requirements not unknown (including unclarity and nulls): N = 52544\n"
     ]
    }
   ],
   "source": [
    "mas_dat2 = mas_dat2[~mas_dat2['st_required'].isna()]\n",
    "\n",
    "mas_dat2.to_excel(\"mas_dat2.xlsx\", index=False)\n",
    "\n",
    "print('ST requirements not unknown (including unclarity and nulls): N =',\n",
    "     len(mas_dat2['UID'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add LOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read LOA file\n",
    "Mas_LOA = pd.read_excel(\"Mas_LOA.xlsx\")\n",
    "Mas_LOA['UID'] = Mas_LOA['UID'].astype(str).str.zfill(9)\n",
    "Mas_LOA['Dept_code'] = Mas_LOA['Dept_code'].astype(str).str.zfill(4)\n",
    "\n",
    "# Join the data frame `mas_dat` with the associated_majors\n",
    "Mas_LOA = pd.merge(Mas_LOA, associated_majors, left_on='Dept_code', right_on='Major Code', how='left')\n",
    "Mas_LOA = pd.merge(Mas_LOA, standard_majors, on='Associated Major Group', how='left')\n",
    "\n",
    "# Replace Major_Code and Major_Name with the coalesced values\n",
    "Mas_LOA['Major_Code'] = Mas_LOA['Standard_Major_Code'].combine_first(Mas_LOA['Dept_code'])\n",
    "\n",
    "# Select specific columns\n",
    "Mas_LOA = Mas_LOA.iloc[:, list(range(2)) + [8]]\n",
    "\n",
    "# Rename columns\n",
    "Mas_LOA.columns.values[2] = 'Dept_code'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mas_dat3 = mas_dat2.copy()\n",
    "\n",
    "# Create a combined column for both DataFrames\n",
    "Mas_LOA['combined'] = Mas_LOA['UID'].astype(str) + '_' + Mas_LOA['Dept_code'].astype(str)\n",
    "mas_dat3['combined'] = mas_dat3['UID'].astype(str) + '_' + mas_dat3['Dept_code'].astype(str)\n",
    "# Filter Mas_LOA based on the presence of the combined column in mas_dat3\n",
    "Mas_LOA = Mas_LOA[Mas_LOA['combined'].isin(mas_dat3['combined'])]\n",
    "# Drop the combined column\n",
    "Mas_LOA = Mas_LOA.drop(columns=['combined'])\n",
    "mas_dat3 = mas_dat3.drop(columns=['combined'])\n",
    "# Add LOA indicator\n",
    "Mas_LOA['LOA'] = 1\n",
    "\n",
    "\n",
    "\n",
    "# Merge\n",
    "mas_dat3 = mas_dat3.rename(columns={'ENR_TERM': 'TERM'})\n",
    "Mas_LOA = Mas_LOA.rename(columns={'LOA_TERM': 'TERM'})\n",
    "columns_to_keep = list(mas_dat3.columns) + ['LOA']\n",
    "Mas_LOA = Mas_LOA.reindex(columns=columns_to_keep, fill_value=pd.NA)\n",
    "mas_dat3 = pd.concat([mas_dat3, Mas_LOA], ignore_index=True)\n",
    "\n",
    "# Fix LOA\n",
    "mas_dat3['LOA'] = np.where(mas_dat3['LOA'].isna(), 0, mas_dat3['LOA'])\n",
    "\n",
    "# Fill NaN with the first non-NaN value within each UID group\n",
    "columns_to_fill = ['ADMIT_TERM', 'Dept', 'st_required', 'TIME_DEG', 'prev_deg', 'URM', 'Non_Male', 'STEM']\n",
    "mas_dat3[columns_to_fill] = mas_dat3.groupby('UID')[columns_to_fill].transform(lambda x: x.ffill().bfill())\n",
    "mas_dat3 = mas_dat3.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Find duplicated ENR_TERM & LOA_TERM\n",
    "mas_dat3 = mas_dat3.sort_values(by=['UID', 'TERM'])\n",
    "\n",
    "# Create a new column 'TERM_duplicated' to flag duplicated TERM values within each UID\n",
    "mas_dat3['TERM_duplicated'] = mas_dat3.groupby('UID')['TERM'].transform(lambda x: x.duplicated(keep=False))\n",
    "\n",
    "# Check if duplicated TERMS have one 1 and one 0 in the LOA column\n",
    "def check_loa_match(group):\n",
    "    if group['TERM_duplicated'].any():\n",
    "        # Group by TERM and check if there is exactly one 1 and one 0 in LOA for each duplicated TERM\n",
    "        return group.groupby('TERM').apply(lambda g: sorted(g['LOA']) == [0, 1]).reindex(group.index, fill_value=False)\n",
    "    return pd.Series([False] * len(group), index=group.index)\n",
    "\n",
    "# Apply the function to each UID group and update the 'TERM_duplicated' column\n",
    "mas_dat3['TERM_duplicated'] = mas_dat3.groupby('UID').apply(check_loa_match).reset_index(level=0, drop=True)\n",
    "\n",
    "duplicated_term_uid = mas_dat3[mas_dat3['TERM_duplicated']][['UID', 'TERM']]\n",
    "\n",
    "# Create a combined column for both DataFrames\n",
    "duplicated_term_uid['combined'] = duplicated_term_uid['UID'].astype(str) + '_' + duplicated_term_uid['TERM'].astype(str)\n",
    "mas_dat3['combined'] = mas_dat3['UID'].astype(str) + '_' + mas_dat3['TERM'].astype(str)\n",
    "\n",
    "# Filter mas_dat3 based on the presence of the combined column in duplicated_term_uid\n",
    "mas_dat3_d = mas_dat3[mas_dat3['combined'].isin(duplicated_term_uid['combined'])].sort_values('UID')\n",
    "# Drop the combined column\n",
    "mas_dat3_d = mas_dat3_d.drop(columns=['combined', 'TERM_duplicated'], errors='ignore')\n",
    "# Fix GPA for LOA terms\n",
    "mas_dat3_d['GPA'] = mas_dat3_d.groupby(['UID','TERM'])['GPA'].transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "# Filter mas_dat3 that are not in duplicated_term_uid\n",
    "mas_dat3_nd = mas_dat3[~mas_dat3['combined'].isin(duplicated_term_uid['combined'])].sort_values('UID')\n",
    "# Drop the combined column\n",
    "mas_dat3_nd = mas_dat3_nd.drop(columns=['combined', 'TERM_duplicated'], errors='ignore')\n",
    "\n",
    "    \n",
    "# If next term has changed GPA, that means last term was not LOA\n",
    "mas_dat3 = pd.concat([mas_dat3_d[mas_dat3_d['LOA'] == 1], mas_dat3_nd], ignore_index=True)\n",
    "mas_dat3 = mas_dat3.rename(columns={'TERM': 'ENR_TERM'})\n",
    "\n",
    "# Sort based on ENR_TERM\n",
    "mas_dat3 = mas_dat3.groupby('UID').apply(lambda x: x.sort_values(by='ENR_TERM', key=lambda y: y.map(custom_sort)))\n",
    "\n",
    "mas_dat3 = mas_dat3.reset_index(drop=True)\n",
    "\n",
    "# LOA never come back\n",
    "def set_LOAnotBack(group):\n",
    "    # Check if the last term is LOA and not graduated\n",
    "    last_row = group.iloc[-1]\n",
    "    if last_row['LOA'] == 1 and pd.isna(last_row['TIME_DEG']):\n",
    "        count_rows = len(group)\n",
    "        group['LOAnotBack'] = count_rows\n",
    "    else:\n",
    "        group['LOAnotBack'] = 0\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "mas_dat3 = mas_dat3.groupby('UID').apply(set_LOAnotBack).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Remove ENR_TERM before ADMIT_TERM\n",
    "\n",
    "# Apply custom_sort function to ENR_TERM and ADMIT_TERM\n",
    "mas_dat3['ENR_TERM_SORT'] = mas_dat3['ENR_TERM'].apply(custom_sort)\n",
    "mas_dat3['ADMIT_TERM_SORT'] = mas_dat3['ADMIT_TERM'].apply(custom_sort)\n",
    "\n",
    "# Filter rows where ENR_TERM is not before ADMIT_TERM within each UID group\n",
    "mas_dat3 = mas_dat3[mas_dat3['ENR_TERM_SORT'] >= mas_dat3['ADMIT_TERM_SORT']]\n",
    "\n",
    "# Drop the helper columns\n",
    "mas_dat3 = mas_dat3.drop(columns=['ENR_TERM_SORT', 'ADMIT_TERM_SORT'])\n",
    "\n",
    "# Reset the index\n",
    "mas_dat3 = mas_dat3.reset_index(drop=True)\n",
    "\n",
    "\n",
    "mas_dat3.to_excel(\"mas_dat3.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd status dataset\n",
    "\n",
    "degree_status2 = pd.read_excel(\"Combined Data Set 0001 - 2223 - 060624.xlsx\")\n",
    "degree_status2 = degree_status2[degree_status2['EnteringDegreeDocMas'] == 'M']\n",
    "degree_status2['UID'] = degree_status2['UID'].astype(str).str.zfill(9)\n",
    "degree_status2 = degree_status2[degree_status2['UID'].isin(mas_dat3['UID'])]\n",
    "degree_status2.loc[\n",
    "    (degree_status2['MajorCode'] == '0534'),\n",
    "    'MajorCode'\n",
    "] = '0535'\n",
    "\n",
    "\n",
    "# Repeated info for each UID\n",
    "degree_status2_d = degree_status2[\n",
    "    degree_status2['UID'].isin(mas_dat3['UID']) &\n",
    "    (degree_status2['Outcome'] == 'Completed')\n",
    "].groupby('UID').filter(\n",
    "    lambda x: len(x) > 1 and x['AwardDegreeSameMajorDifferentDegree'].nunique() > 1\n",
    ")\n",
    "degree_status2 = degree_status2[~((degree_status2['UID'].isin(degree_status2_d['UID'])) &\n",
    "                               (degree_status2['AwardDegreeSameMajorDifferentDegree'] != 'PHD'))]\n",
    "\n",
    "# Update AwardMajorDiffMajorSameDeg with associated_majors\n",
    "\n",
    "## Join the data frame with the associated_majors\n",
    "degree_status2 = pd.merge(degree_status2, associated_majors, left_on='MajorCode', right_on='Major Code', how='left')\n",
    "degree_status2 = pd.merge(degree_status2, standard_majors, on='Associated Major Group', how='left')\n",
    "\n",
    "## Replace Major_Code and Major_Name with the coalesced values\n",
    "degree_status2['Major_Code'] = degree_status2['Standard_Major_Code'].combine_first(degree_status2['MajorCode'])\n",
    "degree_status2['Major_Name'] = degree_status2['Standard_Major_Name'].combine_first(degree_status2['MAJOR_NAME'])\n",
    "\n",
    "## List of column names to get indices\n",
    "column_names = ['UID', 'EnteringAcadYr', 'Major_Code', 'Major_Name', 'TTD', 'Outcome', \n",
    "                'AwardTermSameMajorSameDegree', 'AwardDegreeSameMajorSameDegree', \n",
    "                'AwardMajorDiffMajorDiffDeg', 'AwardDegObjDiffMajorDiffObj', 'TTDDiffMajorDiffDeg',\n",
    "                'AwardMajorDiffMajorSameDeg', 'TTDDiffMajorSameDeg',\n",
    "                'AwardDegreeSameMajorDifferentDegree', 'AwardTermSameMajorDifferentDegree']\n",
    "## Get column indices\n",
    "column_indices = [degree_status2.columns.get_loc(col) for col in column_names]\n",
    "## Select columns using iloc\n",
    "degree_status2 = degree_status2.iloc[:, column_indices]\n",
    "\n",
    "# Test whether there are conflicting Dept_code for same student in degree_status2\n",
    "\n",
    "df1 = mas_dat3.merge(degree_status2, how='left', left_on=['UID', 'Dept_code'], right_on=['UID', 'Major_Code'])\n",
    "df2 = mas_dat3.merge(degree_status2, how='left', left_on=['UID'], right_on=['UID'])\n",
    "\n",
    "# Perform a merge with an indicator to find differences\n",
    "diff = pd.merge(df1, df2, how='outer', indicator=True)\n",
    "\n",
    "# Rows only in df1\n",
    "only_in_df1 = diff[diff['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "# Rows only in df2\n",
    "only_in_df2 = diff[diff['_merge'] == 'right_only'].drop(columns=['_merge'])\n",
    "\n",
    "# Filter out double majors\n",
    "degree_status2 = degree_status2[~degree_status2['UID'].isin(only_in_df2['UID'])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Update AwardMajorDiffMajorSameDeg with associated_majors\n",
    "\n",
    "## Join the data frame with the associated_majors\n",
    "degree_status2 = pd.merge(degree_status2, associated_majors, left_on='AwardMajorDiffMajorSameDeg', right_on='Major Code', how='left')\n",
    "degree_status2 = pd.merge(degree_status2, standard_majors, on='Associated Major Group', how='left')\n",
    "\n",
    "## Replace Major_Code and Major_Name with the coalesced values\n",
    "degree_status2['Major_Code_AwardMajorDiffMajorSameDeg'] = degree_status2['Standard_Major_Code'].combine_first(degree_status2['AwardMajorDiffMajorSameDeg'])\n",
    "\n",
    "## List of column names to get indices\n",
    "column_names = ['UID', 'Major_Code', 'EnteringAcadYr', 'Major_Name', 'TTD', 'Outcome', \n",
    "                'AwardTermSameMajorSameDegree', 'AwardDegreeSameMajorSameDegree', \n",
    "                'AwardMajorDiffMajorDiffDeg', 'AwardDegObjDiffMajorDiffObj', 'TTDDiffMajorDiffDeg',\n",
    "                'Major_Code_AwardMajorDiffMajorSameDeg', 'TTDDiffMajorSameDeg',\n",
    "                'AwardDegreeSameMajorDifferentDegree', 'AwardTermSameMajorDifferentDegree']\n",
    "## Get column indices\n",
    "column_indices = [degree_status2.columns.get_loc(col) for col in column_names]\n",
    "## Select columns using iloc\n",
    "degree_status2 = degree_status2.iloc[:, column_indices]\n",
    "degree_status2 = degree_status2.rename(columns={'Major_Code_AwardMajorDiffMajorSameDeg': 'AwardMajorDiffMajorSameDeg'})\n",
    "\n",
    "# Update AwardMajorDiffMajorDiffDeg with associated_majors\n",
    "\n",
    "## Join the data frame with the associated_majors\n",
    "degree_status2 = pd.merge(degree_status2, associated_majors, left_on='AwardMajorDiffMajorDiffDeg', right_on='Major Code', how='left')\n",
    "degree_status2 = pd.merge(degree_status2, standard_majors, on='Associated Major Group', how='left')\n",
    "\n",
    "## Replace Major_Code and Major_Name with the coalesced values\n",
    "degree_status2['Major_Code_AwardMajorDiffMajorDiffDeg'] = degree_status2['Standard_Major_Code'].combine_first(degree_status2['AwardMajorDiffMajorDiffDeg'])\n",
    "\n",
    "## List of column names to get indices\n",
    "column_names = ['UID', 'Major_Code', 'EnteringAcadYr', 'Major_Name', 'TTD', 'Outcome', \n",
    "                'AwardTermSameMajorSameDegree', 'AwardDegreeSameMajorSameDegree', \n",
    "                'Major_Code_AwardMajorDiffMajorDiffDeg', 'AwardDegObjDiffMajorDiffObj', 'TTDDiffMajorDiffDeg',\n",
    "                'AwardMajorDiffMajorSameDeg', 'TTDDiffMajorSameDeg',\n",
    "                'AwardDegreeSameMajorDifferentDegree', 'AwardTermSameMajorDifferentDegree']\n",
    "## Get column indices\n",
    "column_indices = [degree_status2.columns.get_loc(col) for col in column_names]\n",
    "## Select columns using iloc\n",
    "degree_status2 = degree_status2.iloc[:, column_indices]\n",
    "degree_status2 = degree_status2.rename(columns={'Major_Code_AwardMajorDiffMajorDiffDeg': 'AwardMajorDiffMajorDiffDeg'})\n",
    "\n",
    "\n",
    "# Change AwardTermSameMajorDifferentDegree to four-digit year\n",
    "degree_status2['AwardTermSameMajorDifferentDegree'] = (\n",
    "    degree_status2['AwardTermSameMajorDifferentDegree'].str[:1] + '20' + degree_status2['AwardTermSameMajorDifferentDegree'].str[1:]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Dept_code</th>\n",
       "      <th>ADMIT_TERM</th>\n",
       "      <th>TIME_DEG</th>\n",
       "      <th>TTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UID, Dept_code, ADMIT_TERM, TIME_DEG, TTD]\n",
       "Index: []"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge status dataset\n",
    "b = mas_dat3.merge(degree_status2, how='left', left_on=['UID', 'Dept_code'], right_on=['UID', 'Major_Code'])\n",
    "\n",
    "conditions = [\n",
    "    # 1\n",
    "    b['Outcome'] == 'Still Enrolled',\n",
    "    \n",
    "    # 2\n",
    "    (b['Outcome'] == 'Not Enrolled Spring 23') &\n",
    "        (b['LOAnotBack'] != 1),\n",
    "    \n",
    "    # 3\n",
    "    ## Didn't get same major & deg\n",
    "    b['AwardTermSameMajorSameDegree'].isna() & \n",
    "    b['AwardDegreeSameMajorSameDegree'].isna() &\n",
    "    ## And\n",
    "    (   \n",
    "        ## Got non-master deg in same major\n",
    "        b['AwardDegreeSameMajorDifferentDegree'].isin(['PHD', 'DNP', 'DMA', 'DPH', 'EDD', 'JD', 'DDS']) | \n",
    "        ## Or got major that changed code\n",
    "        (b['AwardMajorDiffMajorSameDeg'].notna() & \n",
    "            (b['Major_Code'] != b['AwardMajorDiffMajorSameDeg'])) | \n",
    "        ## Or got non-master deg or diff major (not because of changed code)\n",
    "        (\n",
    "            ## Got non-master deg\n",
    "            (b['AwardMajorDiffMajorDiffDeg'].notna() &  \n",
    "                (b['Major_Code'] != b['AwardMajorDiffMajorDiffDeg'])) |\n",
    "            ### Or got diff major (not because of changed code)\n",
    "            b['AwardDegObjDiffMajorDiffObj'].isin(['PHD', 'DNP', 'DMA', 'DPH', 'EDD', 'JD', 'DDS'])\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    \n",
    "    # 4\n",
    "    ## Got same major & deg\n",
    "    (b['AwardTermSameMajorSameDegree'].notna() & \n",
    "        b['AwardDegreeSameMajorSameDegree'].notna()) |\n",
    "    ## Or got master deg in same major\n",
    "    (b['AwardDegreeSameMajorDifferentDegree'].notna() &\n",
    "        (~b['AwardDegreeSameMajorDifferentDegree'].isin(['PHD', 'DNP', 'DMA', 'DPH', 'EDD', 'JD', 'DDS']))) |\n",
    "    ## Or got major that changed code\n",
    "    (b['Major_Code'] == b['AwardMajorDiffMajorSameDeg']) |\n",
    "    ## Or got master deg in major that changed code\n",
    "    ((b['Major_Code'] == b['AwardMajorDiffMajorDiffDeg']) &\n",
    "         b['AwardDegreeSameMajorDifferentDegree'].notna() &\n",
    "         (~b['AwardDegreeSameMajorDifferentDegree'].isin(['PHD', 'DNP', 'DMA', 'DPH', 'EDD', 'JD', 'DDS']))\n",
    "    )\n",
    "]\n",
    "choices = [1, 2, 3, 4]\n",
    "b['event'] = np.select(conditions, choices, default=np.nan)\n",
    "# Replace event w/ higher priority if diff\n",
    "b['event'] = b.groupby('UID')['event'].transform('max')\n",
    "\n",
    "b = b.drop_duplicates()\n",
    "\n",
    "\n",
    "# List of column names to get indices\n",
    "column_names = ['event', 'TTD']\n",
    "\n",
    "# Get column indices\n",
    "column_indices = [b.columns.get_loc(col) for col in column_names]\n",
    "\n",
    "# Select columns using iloc\n",
    "mas_dat4 = b.iloc[:, list(range(0, 15)) + column_indices]\n",
    "\n",
    "\n",
    "# Fill missing TTD with TIME_DEG, and vice versa\n",
    "mas_dat4['TTD'].fillna(mas_dat4['TIME_DEG'], inplace=True)\n",
    "mas_dat4['TIME_DEG'].fillna(mas_dat4['TTD'], inplace=True)\n",
    "\n",
    "# TIME_DEG vs TTD \n",
    "\n",
    "diff_TTD = mas_dat4[\n",
    "    (mas_dat4['TTD'] != mas_dat4['TIME_DEG']) &\n",
    "     mas_dat4['TTD'].notna() &\n",
    "     mas_dat4['TIME_DEG'].isna()\n",
    "     \n",
    "][['UID', 'Dept_code', 'ADMIT_TERM', 'TIME_DEG', 'TTD']].drop_duplicates()\n",
    "\n",
    "diff_TTD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Dept_code</th>\n",
       "      <th>ADMIT_TERM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UID, Dept_code, ADMIT_TERM]\n",
       "Index: []"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If event == 2,3,4, then not LOAnotBack \n",
    "mas_dat4['event'] = pd.to_numeric(mas_dat4['event'], errors='coerce')\n",
    "mas_dat4.loc[mas_dat4['event'].between(2,4), 'LOAnotBack'] = 0\n",
    "\n",
    "# If event == 3, then TIME_DEG = NA\n",
    "mas_dat4.loc[mas_dat4['event'] == 3, 'TIME_DEG'] = np.nan\n",
    "\n",
    "# If have TTD, then completed\n",
    "mas_dat4.loc[~mas_dat4['TIME_DEG'].isna(), 'event'] = 4\n",
    "\n",
    "\n",
    "# Define the conditions for separation\n",
    "def separation_condition(row, year_threshold):\n",
    "    return 1 if (row['LOAnotBack'] > 0 and row['LOAnotBack'] < year_threshold) else 0\n",
    "\n",
    "# Apply conditions to each year column\n",
    "for i, threshold in enumerate(list(range(4, 33, 3)), 1):\n",
    "    mas_dat4[f'separated_{i}'] = mas_dat4.apply(lambda row: separation_condition(row, threshold), axis=1)\n",
    "\n",
    "    \n",
    "# Fix GPA\n",
    "mas_dat4['GPA'] = np.where(mas_dat4['GPA'] == 0, np.nan, mas_dat4['GPA'])\n",
    "\n",
    "mas_dat4.drop_duplicates(inplace=True)\n",
    "\n",
    "# Fix event\n",
    "def categorize_event(group):\n",
    "    if ('S24' not in group['ENR_TERM'].values and          # Not enrolled S24\n",
    "        group['TIME_DEG'].isna().all() and                 # Not graduated\n",
    "        (group['LOAnotBack'] == 0).all() and               # LOA but came back\n",
    "        group['event'].isna().all()):                      # Not dropped out explicitly\n",
    "        group['event'] = '2'  # Dropped out\n",
    "        \n",
    "    elif (('S24' in group['ENR_TERM'].values or            # Enrolled S24\n",
    "        group['TIME_DEG'].isna().all() and                 # Not graduated\n",
    "        (group['LOAnotBack'] > 0).all()) and               # LOA never came back\n",
    "        group['event'].isna().all()):                      # Not dropped out explicitly\n",
    "        group['event'] = '1'  # Continuing or LOA never came back\n",
    "\n",
    "    return group\n",
    "\n",
    "mas_dat4 = mas_dat4.groupby('UID').apply(categorize_event).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Define a generalized function to update separated columns based on 'i'\n",
    "def update_separated_i(group, i):\n",
    "    # Dynamically determine the column name for the given year 'i'\n",
    "    separated_col = f'separated_{i}'\n",
    "    \n",
    "    # Check if the first 3*i rows satisfy the conditions\n",
    "    if (group.head(3 * i)['LOA'].eq(0).all() and\n",
    "        group.head(3 * i)[separated_col].isna().all()):\n",
    "        group[separated_col] = 0  # If no LOA and all values are NaN, mark as 0\n",
    "    elif (group.head(3 * i)['LOA'].eq(1).any() and\n",
    "          group.head(3 * i)[separated_col].isna().all()):\n",
    "        group[separated_col] = 0  # If there is LOA but no separation, mark as 0\n",
    "    return group\n",
    "\n",
    "# Apply the function iteratively for all years from 1 to 10\n",
    "for i in range(1, 11):\n",
    "    mas_dat4 = mas_dat4.groupby('UID').apply(lambda group: update_separated_i(group, i)).reset_index(drop=True)\n",
    "\n",
    "complete_but_missing_TTD = mas_dat4[ (mas_dat4['TIME_DEG'].isna()) & (mas_dat4['event'] == 4) ][['UID', 'Dept_code', 'ADMIT_TERM']].drop_duplicates()\n",
    "complete_but_missing_TTD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add completed by 8/10 years\n",
    "mas_dat4['completed_8'] = np.where(mas_dat4['TIME_DEG'] <= 3*8, 1, 0)\n",
    "mas_dat4['completed_10'] = np.where(mas_dat4['TIME_DEG'] <= 3*10, 1, 0)\n",
    "\n",
    "mas_dat4 = mas_dat4.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Graduates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclude doctorate master-outs: N = 51975\n"
     ]
    }
   ],
   "source": [
    "early_grad = mas_dat4[mas_dat4['TIME_DEG'] <= 2][['UID', 'ADMIT_TERM', 'Dept_code', 'Dept', 'TIME_DEG']].drop_duplicates().sort_values(['TIME_DEG', 'Dept'])\n",
    "early_grad.to_excel(\"/Users/joyjiayilin/Downloads/ST/Mas/Mas_Early Graduates.xlsx\", index=False)\n",
    "\n",
    "# Remove early graduates\n",
    "mas_dat4 = mas_dat4[\n",
    "    (mas_dat4['TIME_DEG'] >= 3) |\n",
    "    (mas_dat4['TIME_DEG'].isna())\n",
    "]\n",
    "\n",
    "# Save the result to a new Excel file\n",
    "mas_dat4.to_excel(\"/Users/joyjiayilin/Downloads/ST/Mas/mas_dat4.xlsx\", index=False)\n",
    "\n",
    "print(\"Exclude doctorate master-outs: N =\",\n",
    "     len(mas_dat4['UID'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ST Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the data frame with the associated_majors and standardize\n",
    "Mas_ST_by_Dept_Term2 = pd.merge(Mas_ST_by_Dept_Term, associated_majors, left_on='Dept_code', right_on='Major Code', how='left')\n",
    "Mas_ST_by_Dept_Term2 = pd.merge(Mas_ST_by_Dept_Term2, standard_majors, on='Associated Major Group', how='left')\n",
    "\n",
    "# Replace Major_Code and Major_Name with the coalesced values\n",
    "Mas_ST_by_Dept_Term2['Major_Code'] = Mas_ST_by_Dept_Term2['Standard_Major_Code'].combine_first(Mas_ST_by_Dept_Term2['Dept_code'])\n",
    "Mas_ST_by_Dept_Term2['Major_Name'] = Mas_ST_by_Dept_Term2['Standard_Major_Name'].combine_first(Mas_ST_by_Dept_Term2['Dept'])\n",
    "\n",
    "# Select specific columns\n",
    "Mas_ST_by_Dept_Term3 = Mas_ST_by_Dept_Term2[['AcademicYear', 'Major_Code', 'Major_Name', 'st_required']]\n",
    "\n",
    "# Rename columns\n",
    "Mas_ST_by_Dept_Term3.columns.values[1] = 'Dept_code'\n",
    "Mas_ST_by_Dept_Term3.columns.values[2] = 'Dept'\n",
    "\n",
    "# Select cleaned Dept\n",
    "Mas_ST_by_Dept_Term3 = Mas_ST_by_Dept_Term3[Mas_ST_by_Dept_Term3['Dept_code'].isin(mas_dat4['Dept_code'])]\n",
    "Mas_ST_by_Dept_Term3 = Mas_ST_by_Dept_Term3.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pivot table\n",
    "\n",
    "mas_sensitive_analysis_agg = Mas_ST_by_Dept_Term3.groupby(['Dept', 'AcademicYear']).agg({'st_required': 'mean'}).reset_index()\n",
    "\n",
    "pivot_mas_sensitive_analysis = mas_sensitive_analysis_agg.pivot(index='Dept', columns='AcademicYear', values='st_required')\n",
    "\n",
    "pivot_mas_sensitive_analysis.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# ST changed only\n",
    "def contains_both_zero_and_one(row):\n",
    "    return 0 in row.values and 1 in row.values\n",
    "\n",
    "st_change_pivot_mas_sensitive_analysis = pivot_mas_sensitive_analysis[pivot_mas_sensitive_analysis.apply(contains_both_zero_and_one, axis=1)]\n",
    "\n",
    "\n",
    "# Replace values with words\n",
    "\n",
    "pivot_mas_sensitive_analysis = pivot_mas_sensitive_analysis.replace({1: 'Required', 0: 'Optional', np.nan: 'Unknown'})\n",
    "# Separate the first column\n",
    "first_column = pivot_mas_sensitive_analysis.iloc[:, 0]\n",
    "# Apply the lambda function to all other columns\n",
    "other_columns = pivot_mas_sensitive_analysis.iloc[:, 1:].applymap(lambda x: 'Conflicting req' if x not in ['Required', 'Optional', 'Unknown'] else x)\n",
    "# Concatenate the first column back with the modified other columns\n",
    "pivot_mas_sensitive_analysis = pd.concat([first_column, other_columns], axis=1)\n",
    "\n",
    "st_change_pivot_mas_sensitive_analysis = st_change_pivot_mas_sensitive_analysis.replace({1: 'Required', 0: 'Optional', np.nan: 'Unknown'})\n",
    "# Separate the first column\n",
    "first_column = st_change_pivot_mas_sensitive_analysis.iloc[:, 0]\n",
    "# Apply the lambda function to all other columns\n",
    "other_columns = st_change_pivot_mas_sensitive_analysis.iloc[:, 1:].applymap(lambda x: 'Conflicting req' if x not in ['Required', 'Optional', 'Unknown'] else x)\n",
    "# Concatenate the first column back with the modified other columns\n",
    "st_change_pivot_mas_sensitive_analysis = pd.concat([first_column, other_columns], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export & color\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# Save the data to Excel\n",
    "file_path = '/Users/joyjiayilin/Downloads/ST/Mas/Mas_ST Req.xlsx'\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "    pivot_mas_sensitive_analysis.to_excel(writer, sheet_name='All Dept', index=False)\n",
    "    st_change_pivot_mas_sensitive_analysis.to_excel(writer, sheet_name='ST Changed Only', index=False)\n",
    "\n",
    "# Load the workbook to apply cell colors\n",
    "wb = load_workbook(file_path)\n",
    "\n",
    "# Define the fill colors\n",
    "required_fill = PatternFill(start_color=\"FFFF99\", end_color=\"FFFF99\", fill_type=\"solid\")  # Light yellow\n",
    "optional_fill = PatternFill(start_color=\"CCFFCC\", end_color=\"CCFFCC\", fill_type=\"solid\")  # Light green\n",
    "unknown_fill = PatternFill(start_color=\"CCFFFF\", end_color=\"CCFFFF\", fill_type=\"solid\")   # Light blue\n",
    "conflict_fill = PatternFill(start_color=\"FFCCCC\", end_color=\"FFCCCC\", fill_type=\"solid\")  # Light red\n",
    "\n",
    "# Function to apply colors based on cell values\n",
    "def apply_colors(sheet):\n",
    "    for row in sheet.iter_rows(min_row=2, max_col=sheet.max_column, max_row=sheet.max_row):\n",
    "        for cell in row[1:]:  # Skip the 'Dept' column\n",
    "            if cell.value == \"Required\":\n",
    "                cell.fill = required_fill\n",
    "            elif cell.value == \"Optional\":\n",
    "                cell.fill = optional_fill\n",
    "            elif cell.value == \"Unknown\":\n",
    "                cell.fill = unknown_fill\n",
    "            elif cell.value == \"Conflicting req\":\n",
    "                cell.fill = conflict_fill\n",
    "\n",
    "# Apply colors to each sheet\n",
    "apply_colors(wb['All Dept'])\n",
    "apply_colors(wb['ST Changed Only'])\n",
    "\n",
    "# Save the updated Excel file\n",
    "wb.save(file_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List conflicting req\n",
    "\n",
    "conflict_dept = pivot_mas_sensitive_analysis[pivot_mas_sensitive_analysis.apply(lambda row: 'Conflicting req' in row.values, axis=1)]['Dept']\n",
    "\n",
    "with pd.ExcelWriter('/Users/joyjiayilin/Downloads/ST/Mas/Mas_ST Req.xlsx', mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "    for conflict_dept_i in conflict_dept:\n",
    "        # Get departments for the conflicting requirement\n",
    "        dept = Mas_ST_by_Dept_Term2[Mas_ST_by_Dept_Term2['Standard_Major_Name'] == conflict_dept_i]['Dept'].unique()\n",
    "\n",
    "        # Initialize DataFrame for the current conflict_dept_i\n",
    "        dept_i_dfs = pd.DataFrame()\n",
    "\n",
    "        for dept_i in dept:\n",
    "            # Filter data for the department\n",
    "            dept_i_df = Mas_ST_by_Dept_Term[Mas_ST_by_Dept_Term['Dept'] == dept_i][['AcademicYear', 'Dept', 'st_required', 'Tests']]\n",
    "\n",
    "            # Rename conflicting columns if they already have the '_x' or '_y' suffix\n",
    "            existing_suffixes = ['_x', '_y']\n",
    "            conflicting_columns = [col for col in dept_i_dfs.columns if any(col.endswith(suffix) for suffix in existing_suffixes)]\n",
    "\n",
    "            if conflicting_columns:\n",
    "                dept_i_dfs = dept_i_dfs.rename(columns={col: col.replace('_x', '_old_x').replace('_y', '_old_y') for col in conflicting_columns})\n",
    "\n",
    "            # Merge with the main DataFrame\n",
    "            if dept_i_dfs.empty:\n",
    "                dept_i_dfs = dept_i_df\n",
    "            else:\n",
    "                dept_i_dfs = pd.merge(dept_i_dfs, dept_i_df, on='AcademicYear', how='outer', suffixes=('_x', '_y'))\n",
    "\n",
    "        # Write to Excel sheet named after the conflict department\n",
    "        sheet_name = f'Conflict_{conflict_dept_i}'\n",
    "        if len(sheet_name) > 31:\n",
    "            sheet_name = sheet_name[:31]  # Excel sheet name length limit\n",
    "\n",
    "        dept_i_dfs.to_excel(writer, sheet_name=sheet_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color conflicting req\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# Define fill color\n",
    "highlight_fill = PatternFill(start_color='FFFFC0CB', end_color='FFFFC0CB', fill_type='solid')\n",
    "\n",
    "# Load the existing workbook\n",
    "file_path = '/Users/joyjiayilin/Downloads/ST/Mas/Mas_ST Req.xlsx'\n",
    "wb = load_workbook(file_path)\n",
    "\n",
    "# Iterate over each sheet in the workbook\n",
    "for sheet_name in wb.sheetnames:\n",
    "    sheet = wb[sheet_name]\n",
    "    \n",
    "    # Read the sheet into a DataFrame\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    \n",
    "    # Check if relevant columns exist in the DataFrame\n",
    "    if 'st_required_x' in df.columns and 'st_required_y' in df.columns:\n",
    "        for row_idx, row in df.iterrows():\n",
    "            st_required_x = row['st_required_x']\n",
    "            st_required_y = row['st_required_y']\n",
    "            \n",
    "            if pd.notna(st_required_x) and pd.notna(st_required_y) and st_required_x != st_required_y:\n",
    "                sheet.cell(row=row_idx + 2, column=df.columns.get_loc('st_required_x') + 1).fill = highlight_fill\n",
    "                sheet.cell(row=row_idx + 2, column=df.columns.get_loc('st_required_y') + 1).fill = highlight_fill\n",
    "\n",
    "    if 'st_required_x' in df.columns and 'st_required' in df.columns:\n",
    "        for row_idx, row in df.iterrows():\n",
    "            st_required_x = row['st_required_x']\n",
    "            st_required = row['st_required']\n",
    "            \n",
    "            if pd.notna(st_required_x) and pd.notna(st_required) and st_required_x != st_required:\n",
    "                sheet.cell(row=row_idx + 2, column=df.columns.get_loc('st_required_x') + 1).fill = highlight_fill\n",
    "                sheet.cell(row=row_idx + 2, column=df.columns.get_loc('st_required') + 1).fill = highlight_fill\n",
    "\n",
    "    if 'st_required_y' in df.columns and 'st_required' in df.columns:\n",
    "        for row_idx, row in df.iterrows():\n",
    "            st_required_y = row['st_required_y']\n",
    "            st_required = row['st_required']\n",
    "            \n",
    "            if pd.notna(st_required_y) and pd.notna(st_required) and st_required_y != st_required:\n",
    "                sheet.cell(row=row_idx + 2, column=df.columns.get_loc('st_required_y') + 1).fill = highlight_fill\n",
    "                sheet.cell(row=row_idx + 2, column=df.columns.get_loc('st_required') + 1).fill = highlight_fill\n",
    "\n",
    "# Save the workbook with highlights\n",
    "wb.save(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mas_dat4 = pd.read_excel(\"mas_dat4.xlsx\")\n",
    "\n",
    "# mas_dat4['UID'] = mas_dat4['UID'].astype(str).str.zfill(9)\n",
    "# mas_dat4['Dept_code'] = mas_dat4['Dept_code'].astype(str).str.zfill(4)\n",
    "\n",
    "# st_change_pivot_mas_sensitive_analysis = pd.read_excel(\"Mas_ST Req.xlsx\", sheet_name='ST Changed Only')\n",
    "\n",
    "\n",
    "mas_st_change_dat4 = mas_dat4[mas_dat4['Dept'].isin(st_change_pivot_mas_sensitive_analysis['Dept'])]\n",
    "\n",
    "mas_st_change_dat4.to_excel(\"/Users/joyjiayilin/Downloads/ST/Mas/mas_st_change_dat4.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing TIME_DEG Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mas_dat4 = pd.read_excel(\"mas_dat4.xlsx\")\n",
    "# mas_dat4['UID'] = mas_dat4['UID'].astype(str).str.zfill(9)\n",
    "# mas_dat4['Dept_code'] = mas_dat4['Dept_code'].astype(str).str.zfill(4)\n",
    "# st_change_pivot_mas_sensitive_analysis = pd.read_excel(\"Mas_ST Req.xlsx\", sheet_name='ST Changed Only')\n",
    "# mas_st_change_dat4 = pd.read_excel(\"mas_st_change_dat4.xlsx\")\n",
    "# mas_st_change_dat4['UID'] = mas_st_change_dat4['UID'].astype(str).str.zfill(9)\n",
    "# mas_st_change_dat4['Dept_code'] = mas_st_change_dat4['Dept_code'].astype(str).str.zfill(4)\n",
    "\n",
    "def calculate_stats(dataframe):\n",
    "    dataframe['event'] = pd.to_numeric(dataframe['event'], errors='coerce')\n",
    "    total_missing_TTD = len(dataframe[dataframe['TIME_DEG'].isna()]['UID'].unique())\n",
    "    \n",
    "    continues = len(dataframe[(dataframe['TIME_DEG'].isna()) & (dataframe['event'] == 1)]['UID'].unique())\n",
    "    dropouts = len(dataframe[(dataframe['TIME_DEG'].isna()) & (dataframe['event'] == 2)]['UID'].unique())\n",
    "    master_outs = len(dataframe[(dataframe['TIME_DEG'].isna()) & (dataframe['event'] == 3)]['UID'].unique())\n",
    "\n",
    "    continues_perc = round(continues / total_missing_TTD * 100, 2)\n",
    "    dropouts_perc = round(dropouts / total_missing_TTD * 100, 2)\n",
    "    master_outs_perc = round(master_outs / total_missing_TTD * 100, 2)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Category': ['Missing TTD Total', 'Not finished yet', 'Dropouts', 'Master-outs'],\n",
    "        'Value': [f\"{total_missing_TTD} (100%)\",\n",
    "                  f\"{continues} ({continues_perc}%)\",\n",
    "                  f\"{dropouts} ({dropouts_perc}%)\",\n",
    "                  f\"{master_outs} ({master_outs_perc}%)\"]\n",
    "    })\n",
    "\n",
    "# Load and process general data\n",
    "mas_dat4 = pd.read_excel(\"mas_dat4.xlsx\")\n",
    "mas_dat4['UID'] = mas_dat4['UID'].astype(str).str.zfill(9)\n",
    "mas_dat4['Dept_code'] = mas_dat4['Dept_code'].astype(str).str.zfill(4)\n",
    "\n",
    "# General statistics\n",
    "mas_TTD_stats = calculate_stats(mas_dat4)\n",
    "\n",
    "# STEM and Non-STEM statistics\n",
    "mas_dat4_stem = mas_dat4[mas_dat4['STEM'] == 1]\n",
    "mas_stem_TTD_stats = calculate_stats(mas_dat4_stem)\n",
    "\n",
    "mas_dat4_non_stem = mas_dat4[mas_dat4['STEM'] == 0]\n",
    "mas_non_stem_TTD_stats = calculate_stats(mas_dat4_non_stem)\n",
    "\n",
    "# Load and process ST change data\n",
    "mas_st_change_dat4 = mas_dat4[mas_dat4['Dept'].isin(st_change_pivot_mas_sensitive_analysis['Dept'])]\n",
    "mas_st_change_TTD_stats = calculate_stats(mas_st_change_dat4)\n",
    "\n",
    "mas_st_change_dat4_stem = mas_st_change_dat4[mas_st_change_dat4['STEM'] == 1]\n",
    "mas_st_change_stem_TTD_stats = calculate_stats(mas_st_change_dat4_stem)\n",
    "\n",
    "mas_st_change_dat4_non_stem = mas_st_change_dat4[mas_st_change_dat4['STEM'] == 0]\n",
    "mas_st_change_non_stem_TTD_stats = calculate_stats(mas_st_change_dat4_non_stem)\n",
    "\n",
    "# Export results\n",
    "with pd.ExcelWriter('/Users/joyjiayilin/Downloads/ST/Shiny/Mas_Missing_TTD_Stats.xlsx', engine='xlsxwriter') as writer:\n",
    "    mas_TTD_stats.to_excel(writer, sheet_name='ttd_stats', index=False)\n",
    "    mas_stem_TTD_stats.to_excel(writer, sheet_name='ttd_stats_s', index=False)\n",
    "    mas_non_stem_TTD_stats.to_excel(writer, sheet_name='ttd_stats_n', index=False)\n",
    "    mas_st_change_TTD_stats.to_excel(writer, sheet_name='ttd_st_change_stats', index=False)\n",
    "    mas_st_change_stem_TTD_stats.to_excel(writer, sheet_name='ttd_st_change_stats_s', index=False)\n",
    "    mas_st_change_non_stem_TTD_stats.to_excel(writer, sheet_name='ttd_st_change_stats_n', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mas_dat3 = pd.read_excel(\"mas_dat3.xlsx\")\n",
    "# # mas_dat4 = pd.read_excel(\"mas_dat4.xlsx\")\n",
    "# # degree_status = pd.read_excel(\"degree_status.xlsx\")\n",
    "\n",
    "# def calculate_separation_stats(degree_status, st_change_pivot_mas_sensitive_analysis=None):\n",
    "    \n",
    "#     # Ensure IDs are formatted correctly\n",
    "#     mas_dat3['UID'] = mas_dat3['UID'].astype(str).str.zfill(9)\n",
    "#     mas_dat3['Dept_code'] = mas_dat3['Dept_code'].astype(str).str.zfill(4)\n",
    "#     mas_dat4['UID'] = mas_dat4['UID'].astype(str).str.zfill(9)\n",
    "#     mas_dat4['Dept_code'] = mas_dat4['Dept_code'].astype(str).str.zfill(4)\n",
    "    \n",
    "#     # Merge data\n",
    "#     a = mas_dat3.merge(degree_status, how='left', left_on=['UID', 'Dept_code'], right_on=['UID', 'Major_Code'])\n",
    "    \n",
    "#     # Total UIDs\n",
    "#     total_UIDs = len(mas_dat4['UID'].unique())\n",
    "    \n",
    "#     def calculate_category_stats(dataframe, a):\n",
    "#         # Calculate results for each category\n",
    "#         year_1_sep = len(dataframe[dataframe['separated_1'] == 1]['UID'].unique())\n",
    "#         year_2_sep = len(dataframe[dataframe['separated_2'] == 1]['UID'].unique())\n",
    "#         year_1_dropouts = len(a[a['Year 1'] == \"Dropout\"]['UID'].unique())\n",
    "#         year_2_dropouts = len(a[a['Year 2'] == \"Dropout\"]['UID'].unique())\n",
    "#         year_1_master_outs = len(a[a['Year 1'] == \"Terminal Master's\"]['UID'].unique())\n",
    "#         year_2_master_outs = len(a[a['Year 2'] == \"Terminal Master's\"]['UID'].unique())\n",
    "#         year_1_loa = len(a[~a['Year 1'].isin([\"Dropout\", \"Terminal Master's\"]) & \n",
    "#                             (a['LOAnotBack'] > 0) & (a['LOAnotBack'] < 4)]['UID'].unique())\n",
    "#         year_2_loa = len(a[~a['Year 2'].isin([\"Dropout\", \"Terminal Master's\"]) & \n",
    "#                             (a['LOAnotBack'] > 0) & (a['LOAnotBack'] < 7)]['UID'].unique())\n",
    "\n",
    "#         # Calculate percentages\n",
    "#         year_1_sep_perc = round(year_1_sep / total_UIDs * 100, 2)\n",
    "#         year_2_sep_perc = round(year_2_sep / total_UIDs * 100, 2)\n",
    "#         year_1_dropouts_perc = round(year_1_dropouts / total_UIDs * 100, 2)\n",
    "#         year_2_dropouts_perc = round(year_2_dropouts / total_UIDs * 100, 2)\n",
    "#         year_1_master_outs_perc = round(year_1_master_outs / total_UIDs * 100, 2)\n",
    "#         year_2_master_outs_perc = round(year_2_master_outs / total_UIDs * 100, 2)\n",
    "#         year_1_loa_perc = round(year_1_loa / total_UIDs * 100, 2)\n",
    "#         year_2_loa_perc = round(year_2_loa / total_UIDs * 100, 2)\n",
    "\n",
    "#         return pd.DataFrame({\n",
    "#             'Category': ['Separation Total', \n",
    "#                          'Dropouts', \n",
    "#                          'Master-outs', \n",
    "#                          'LOA and Never Came Back'],\n",
    "#             'Value': [f\"{year_1_sep} ({year_1_sep_perc}%)\",\n",
    "#                       f\"{year_1_dropouts} ({year_1_dropouts_perc}%)\",\n",
    "#                       f\"{year_1_master_outs} ({year_1_master_outs_perc}%)\",\n",
    "#                       f\"{year_1_loa} ({year_1_loa_perc}%)\"]\n",
    "#         }), pd.DataFrame({\n",
    "#             'Category': ['Separation Total', \n",
    "#                          'Dropouts', \n",
    "#                          'Master-outs', \n",
    "#                          'LOA and Never Came Back'],\n",
    "#             'Value': [f\"{year_2_sep} ({year_2_sep_perc}%)\",\n",
    "#                       f\"{year_2_dropouts} ({year_2_dropouts_perc}%)\",\n",
    "#                       f\"{year_2_master_outs} ({year_2_master_outs_perc}%)\",\n",
    "#                       f\"{year_2_loa} ({year_2_loa_perc}%)\"]\n",
    "#         })\n",
    "\n",
    "#     # Calculate stats for all data\n",
    "#     mas_sep1_stats, mas_sep2_stats = calculate_category_stats(mas_dat4, a)\n",
    "\n",
    "#     # Calculate stats for STEM\n",
    "#     a_stem = a[a['STEM'] == 1]\n",
    "#     mas_dat4_stem = mas_dat4[mas_dat4['STEM'] == 1]\n",
    "#     total_UIDs = len(mas_dat4_stem['UID'].unique())\n",
    "#     mas_stem_sep1_stats, mas_stem_sep2_stats = calculate_category_stats(mas_dat4_stem, a_stem)\n",
    "\n",
    "#     # Calculate stats for Non-STEM\n",
    "#     a_non_stem = a[a['STEM'] == 0]\n",
    "#     mas_dat4_non_stem = mas_dat4[mas_dat4['STEM'] == 0]\n",
    "#     total_UIDs = len(mas_dat4_non_stem['UID'].unique())\n",
    "#     mas_non_stem_sep1_stats, mas_non_stem_sep2_stats = calculate_category_stats(mas_dat4_non_stem, a_non_stem)\n",
    "\n",
    "#     # Calculate stats for data with ST change\n",
    "#     mas_st_change_dat3 = mas_dat3[mas_dat3['Dept'].isin(st_change_pivot_mas_sensitive_analysis['Dept'])]\n",
    "#     a = mas_st_change_dat3.merge(degree_status, how='left', left_on=['UID', 'Dept_code'], right_on=['UID', 'Major_Code'])\n",
    "#     mas_st_change_dat4 = mas_dat4[mas_dat4['Dept'].isin(st_change_pivot_mas_sensitive_analysis['Dept'])]\n",
    "#     total_UIDs = len(mas_st_change_dat4['UID'].unique())\n",
    "#     mas_st_change_sep1_stats, mas_st_change_sep2_stats = calculate_category_stats(mas_st_change_dat4, a)\n",
    "\n",
    "#     # Calculate stats for STEM with ST change\n",
    "#     a_stem = a[a['STEM'] == 1]\n",
    "#     mas_st_change_dat4_stem = mas_st_change_dat4[mas_st_change_dat4['STEM'] == 1]\n",
    "#     total_UIDs = len(mas_st_change_dat4_stem['UID'].unique())\n",
    "#     mas_st_change_stem_sep1_stats, mas_st_change_stem_sep2_stats = calculate_category_stats(mas_st_change_dat4_stem, a_stem)\n",
    "\n",
    "#     # Calculate stats for Non-STEM with ST change\n",
    "#     a_non_stem = a[a['STEM'] == 0]\n",
    "#     mas_st_change_dat4_non_stem = mas_st_change_dat4[mas_st_change_dat4['STEM'] == 0]\n",
    "#     total_UIDs = len(mas_st_change_dat4_non_stem['UID'].unique())\n",
    "#     mas_st_change_non_stem_sep1_stats, mas_st_change_non_stem_sep2_stats = calculate_category_stats(mas_st_change_dat4_non_stem, a_non_stem)\n",
    "\n",
    "#     # Export results\n",
    "#     with pd.ExcelWriter('/Users/joyjiayilin/Downloads/ST/Shiny/Mas_Sep_Stats.xlsx', engine='xlsxwriter') as writer:\n",
    "#         mas_sep1_stats.to_excel(writer, sheet_name='sep1_stats', index=False)\n",
    "#         mas_sep2_stats.to_excel(writer, sheet_name='sep2_stats', index=False)\n",
    "#         mas_stem_sep1_stats.to_excel(writer, sheet_name='sep1_stats_s', index=False)\n",
    "#         mas_stem_sep2_stats.to_excel(writer, sheet_name='sep2_stats_s', index=False)\n",
    "#         mas_non_stem_sep1_stats.to_excel(writer, sheet_name='sep1_stats_n', index=False)\n",
    "#         mas_non_stem_sep2_stats.to_excel(writer, sheet_name='sep2_stats_n', index=False)\n",
    "#         mas_st_change_sep1_stats.to_excel(writer, sheet_name='sep1_st_change_stats', index=False)\n",
    "#         mas_st_change_sep2_stats.to_excel(writer, sheet_name='sep2_st_change_stats', index=False)\n",
    "#         mas_st_change_stem_sep1_stats.to_excel(writer, sheet_name='sep1_st_change_stats_s', index=False)\n",
    "#         mas_st_change_stem_sep2_stats.to_excel(writer, sheet_name='sep2_st_change_stats_s', index=False)\n",
    "#         mas_st_change_non_stem_sep1_stats.to_excel(writer, sheet_name='sep1_st_change_stats_n', index=False)\n",
    "#         mas_st_change_non_stem_sep2_stats.to_excel(writer, sheet_name='sep2_st_change_stats_n', index=False)\n",
    "\n",
    "        \n",
    "        \n",
    "# calculate_separation_stats(degree_status2, st_change_pivot_mas_sensitive_analysis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completion Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate stats and return DataFrame\n",
    "def calculate_completion_stats(data, comp_col, total_col='UID'):\n",
    "    total_UIDs = len(data[total_col].unique())\n",
    "    completed_num = len(data[data[comp_col] == 1][total_col].unique())\n",
    "    total_completed = len(data[data['TIME_DEG'].notna()][total_col].unique())\n",
    "    completed_more_than_num = len(data[(data[comp_col] == 0) & (data['TIME_DEG'].notna())][total_col].unique())\n",
    "    no_completed_num = len(data[(data[comp_col] == 0) & (data['TIME_DEG'].isna())][total_col].unique())\n",
    "\n",
    "    completed_perc_all = round(completed_num / total_UIDs * 100, 2)\n",
    "    completed_perc = round(completed_num / total_completed * 100, 2)\n",
    "    completed_more_than_perc = round(completed_more_than_num / total_UIDs * 100, 2)\n",
    "    no_completed_perc = round(no_completed_num / total_UIDs * 100, 2)\n",
    "\n",
    "    stats_df = pd.DataFrame({\n",
    "        'Category': ['Total Sample Size', \n",
    "                     'Completed within range', \n",
    "                     #'Completed within range (among all degree completers)',\n",
    "                     'Completed outside range', \n",
    "                     'Not completed'],\n",
    "        'Value': [\n",
    "            f\"{total_UIDs} (100%)\",\n",
    "            f\"{completed_num} ({completed_perc_all}%)\",\n",
    "            #f\"{completed_perc}% (among {total_completed} completors)\",\n",
    "            f\"{completed_more_than_num} ({completed_more_than_perc}%)\",\n",
    "            f\"{no_completed_num} ({no_completed_perc}%)\"\n",
    "        ]\n",
    "    })\n",
    "    return stats_df\n",
    "\n",
    "# Writing stats to Excel\n",
    "def write_stats_to_excel(writer, data, sheet_name, comp_col):\n",
    "    stats_df = calculate_completion_stats(data, comp_col)\n",
    "    stats_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# Paths and column names\n",
    "excel_path = '/Users/joyjiayilin/Downloads/ST/Shiny/Mas_Completion_Stats.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "    # Overall stats\n",
    "    write_stats_to_excel(writer, mas_dat4, '8', 'completed_8')\n",
    "    write_stats_to_excel(writer, mas_dat4, '10', 'completed_10')\n",
    "    \n",
    "    # STEM stats\n",
    "    mas_dat4_stem = mas_dat4[mas_dat4['STEM'] == 1]\n",
    "    write_stats_to_excel(writer, mas_dat4_stem, '8_s', 'completed_8')\n",
    "    write_stats_to_excel(writer, mas_dat4_stem, '10_s', 'completed_10')\n",
    "    \n",
    "    # Non-STEM stats\n",
    "    mas_dat4_non_stem = mas_dat4[mas_dat4['STEM'] == 0]\n",
    "    write_stats_to_excel(writer, mas_dat4_non_stem, '8_n', 'completed_8')\n",
    "    write_stats_to_excel(writer, mas_dat4_non_stem, '10_n', 'completed_10')\n",
    "    \n",
    "    # ST Change stats\n",
    "    write_stats_to_excel(writer, mas_st_change_dat4, 'st_change_8', 'completed_8')\n",
    "    write_stats_to_excel(writer, mas_st_change_dat4, 'st_change_10', 'completed_10')\n",
    "    \n",
    "    # ST Change STEM stats\n",
    "    mas_st_change_dat4_stem = mas_st_change_dat4[mas_st_change_dat4['STEM'] == 1]\n",
    "    write_stats_to_excel(writer, mas_st_change_dat4_stem, 'st_change_8_s', 'completed_8')\n",
    "    write_stats_to_excel(writer, mas_st_change_dat4_stem, 'st_change_10_s', 'completed_10')\n",
    "    \n",
    "    # ST Change Non-STEM stats\n",
    "    mas_st_change_dat4_non_stem = mas_st_change_dat4[mas_st_change_dat4['STEM'] == 0]\n",
    "    write_stats_to_excel(writer, mas_st_change_dat4_non_stem, 'st_change_8_n', 'completed_8')\n",
    "    write_stats_to_excel(writer, mas_st_change_dat4_non_stem, 'st_change_10_n', 'completed_10')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPA Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"dat5.xlsx\")\n",
    "column_data = data['year_1_gpa']\n",
    "\n",
    "# Convert the column to a numpy array\n",
    "data = column_data.to_numpy()\n",
    "\n",
    "# Original data\n",
    "sns.histplot(data, kde=True)\n",
    "plt.title('Original Left-Skewed Data')\n",
    "plt.show()\n",
    "\n",
    "# Yeo-Johnson Transformation\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "yeo_johnson_data = pt.fit_transform(data.reshape(-1, 1))\n",
    "\n",
    "sns.histplot(yeo_johnson_data, kde=True)\n",
    "plt.title('Yeo-Johnson Transformed Data')\n",
    "plt.show()\n",
    "\n",
    "# Trimming data (removing extreme 5% on each side)\n",
    "trimmed_data = stats.trim1(data, proportiontocut=0.05)\n",
    "\n",
    "sns.histplot(trimmed_data, kde=True)\n",
    "plt.title('Trimmed Data')\n",
    "plt.show()\n",
    "\n",
    "# Winsorizing data (setting extreme values to the 5th and 95th percentiles)\n",
    "winsorized_data = stats.mstats.winsorize(data, limits=[0.05, 0.05])\n",
    "\n",
    "sns.histplot(winsorized_data, kde=True)\n",
    "plt.title('Winsorized Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_excel(\"dat5.xlsx\")\n",
    "column_data = data['year_2_gpa']\n",
    "\n",
    "# Convert the column to a numpy array\n",
    "data = column_data.to_numpy()\n",
    "\n",
    "# Original data\n",
    "sns.histplot(data, kde=True)\n",
    "plt.title('Original Left-Skewed Data')\n",
    "plt.show()\n",
    "\n",
    "# Yeo-Johnson Transformation\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "yeo_johnson_data = pt.fit_transform(data.reshape(-1, 1))\n",
    "\n",
    "sns.histplot(yeo_johnson_data, kde=True)\n",
    "plt.title('Yeo-Johnson Transformed Data')\n",
    "plt.show()\n",
    "\n",
    "# Trimming data (removing extreme 5% on each side)\n",
    "trimmed_data = stats.trim1(data, proportiontocut=0.05)\n",
    "\n",
    "sns.histplot(trimmed_data, kde=True)\n",
    "plt.title('Trimmed Data')\n",
    "plt.show()\n",
    "\n",
    "# Winsorizing data (setting extreme values to the 5th and 95th percentiles)\n",
    "winsorized_data = stats.mstats.winsorize(data, limits=[0.05, 0.05])\n",
    "\n",
    "sns.histplot(winsorized_data, kde=True)\n",
    "plt.title('Winsorized Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPA: Linear regression\n",
    "\n",
    "## First year GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cp/yvxc2mxs2bqgmwd6cm4_cwsc0000gn/T/ipykernel_831/3632096320.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['gre_required'] = pd.to_numeric(X['gre_required'], errors='coerce')\n",
      "/var/folders/cp/yvxc2mxs2bqgmwd6cm4_cwsc0000gn/T/ipykernel_831/3632096320.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = pd.to_numeric(X[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const                       float64\n",
      "gre_required                  int64\n",
      "Dept_Applied Linguistics      uint8\n",
      "Dept_Archaeology              uint8\n",
      "Dept_Architecture             uint8\n",
      "                             ...   \n",
      "ADMIT_TERM_X17                uint8\n",
      "ADMIT_TERM_X18                uint8\n",
      "ADMIT_TERM_X19                uint8\n",
      "ADMIT_TERM_X20                uint8\n",
      "ADMIT_TERM_X21                uint8\n",
      "Length: 148, dtype: object\n",
      "float64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             year_1_gpa   R-squared:                       0.159\n",
      "Model:                            OLS   Adj. R-squared:                  0.151\n",
      "Method:                 Least Squares   F-statistic:                     19.94\n",
      "Date:                Thu, 11 Jul 2024   Prob (F-statistic):               0.00\n",
      "Time:                        21:46:58   Log-Likelihood:                 2671.8\n",
      "No. Observations:               15688   AIC:                            -5048.\n",
      "Df Residuals:                   15540   BIC:                            -3914.\n",
      "Df Model:                         147                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================================================================================\n",
      "                                                                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                                              3.9570      0.085     46.326      0.000       3.790       4.124\n",
      "gre_required                                                                      -0.0188      0.008     -2.398      0.017      -0.034      -0.003\n",
      "Dept_Applied Linguistics                                                          -0.0378      0.030     -1.259      0.208      -0.097       0.021\n",
      "Dept_Archaeology                                                                  -0.0275      0.026     -1.070      0.284      -0.078       0.023\n",
      "Dept_Architecture                                                                 -0.1182      0.028     -4.268      0.000      -0.173      -0.064\n",
      "Dept_Art History                                                                  -0.0474      0.022     -2.125      0.034      -0.091      -0.004\n",
      "Dept_Asian Lang & Cult                                                            -0.0521      0.021     -2.462      0.014      -0.094      -0.011\n",
      "Dept_Astronomy                                                                    -0.1191      0.025     -4.846      0.000      -0.167      -0.071\n",
      "Dept_Atmospheric Sciences                                                         -0.1546      0.022     -7.141      0.000      -0.197      -0.112\n",
      "Dept_Bioengineering                                                               -0.2366      0.016    -14.399      0.000      -0.269      -0.204\n",
      "Dept_Bioinformatics                                                               -0.0548      0.022     -2.497      0.013      -0.098      -0.012\n",
      "Dept_Biology                                                                      -0.0189      0.019     -1.007      0.314      -0.056       0.018\n",
      "Dept_Biomedical Physics                                                           -0.0837      0.022     -3.805      0.000      -0.127      -0.041\n",
      "Dept_Biostatistics                                                                -0.0783      0.022     -3.503      0.000      -0.122      -0.034\n",
      "Dept_Chemical Engineering                                                         -0.2112      0.018    -11.879      0.000      -0.246      -0.176\n",
      "Dept_Chemistry                                                                    -0.2475      0.014    -17.126      0.000      -0.276      -0.219\n",
      "Dept_Chicana and Chicano Studies                                                  -0.0709      0.030     -2.333      0.020      -0.130      -0.011\n",
      "Dept_Choreographic Inquiry                                                        -0.0200      0.024     -0.830      0.406      -0.067       0.027\n",
      "Dept_Civil Engineering                                                            -0.1645      0.017     -9.422      0.000      -0.199      -0.130\n",
      "Dept_Clinical Research                                                            -0.1227      0.033     -3.682      0.000      -0.188      -0.057\n",
      "Dept_Communication                                                                -0.1028      0.052     -1.989      0.047      -0.204      -0.001\n",
      "Dept_Community Health Sciences                                                    -0.1050      0.029     -3.642      0.000      -0.162      -0.049\n",
      "Dept_Comparative Literature                                                       -0.0402      0.024     -1.642      0.101      -0.088       0.008\n",
      "Dept_Computer Science                                                             -0.1353      0.015     -8.966      0.000      -0.165      -0.106\n",
      "Dept_Conservation of Material Culture                                             -0.1114      0.093     -1.201      0.230      -0.293       0.070\n",
      "Dept_Economics                                                                    -0.2727      0.016    -16.558      0.000      -0.305      -0.240\n",
      "Dept_Education                                                                     0.0050      0.015      0.336      0.737      -0.024       0.034\n",
      "Dept_Education - Joint doctoral program in Special Education w/ Cal State - LA     0.0010      0.034      0.031      0.976      -0.065       0.067\n",
      "Dept_Elect. Engineerig                                                            -0.1106      0.015     -7.436      0.000      -0.140      -0.081\n",
      "Dept_English                                                                      -0.0643      0.018     -3.479      0.001      -0.101      -0.028\n",
      "Dept_Environment and Sustainability                                               -0.0905      0.041     -2.207      0.027      -0.171      -0.010\n",
      "Dept_Environmental Health Sciences                                                -0.1376      0.030     -4.551      0.000      -0.197      -0.078\n",
      "Dept_Epidemiology                                                                 -0.1071      0.019     -5.708      0.000      -0.144      -0.070\n",
      "Dept_Ethnomusicology                                                              -0.0717      0.036     -1.986      0.047      -0.142      -0.001\n",
      "Dept_Film and TV (MA or PhD)                                                       0.0116      0.024      0.488      0.626      -0.035       0.058\n",
      "Dept_French & Francophone St                                                      -0.1101      0.028     -3.965      0.000      -0.164      -0.056\n",
      "Dept_Gender Studies                                                               -0.0056      0.029     -0.190      0.849      -0.063       0.052\n",
      "Dept_Geography                                                                    -0.0375      0.020     -1.909      0.056      -0.076       0.001\n",
      "Dept_Geophysics & Space Phy                                                       -0.1357      0.019     -7.017      0.000      -0.174      -0.098\n",
      "Dept_Greek                                                                        -0.1493      0.026     -5.662      0.000      -0.201      -0.098\n",
      "Dept_Health Services                                                              -0.1639      0.022     -7.549      0.000      -0.206      -0.121\n",
      "Dept_History                                                                      -0.0471      0.016     -2.866      0.004      -0.079      -0.015\n",
      "Dept_Human Genetics                                                               -0.1773      0.025     -7.045      0.000      -0.227      -0.128\n",
      "Dept_Indo-European Studies                                                        -0.1536      0.055     -2.794      0.005      -0.261      -0.046\n",
      "Dept_Information Studies                                                          -0.1136      0.025     -4.517      0.000      -0.163      -0.064\n",
      "Dept_Islamic Studies                                                              -0.0603      0.020     -2.957      0.003      -0.100      -0.020\n",
      "Dept_Italian                                                                      -0.0153      0.032     -0.483      0.629      -0.077       0.047\n",
      "Dept_Linguistics                                                                  -0.0280      0.022     -1.280      0.200      -0.071       0.015\n",
      "Dept_Management: M.B.A.                                                           -0.2195      0.023     -9.715      0.000      -0.264      -0.175\n",
      "Dept_Manufacturing Engr.                                                          -0.1882      0.015    -12.454      0.000      -0.218      -0.159\n",
      "Dept_Materials Science and Engineering                                            -0.2337      0.017    -14.087      0.000      -0.266      -0.201\n",
      "Dept_Mathematics                                                                  -0.0979      0.016     -6.269      0.000      -0.129      -0.067\n",
      "Dept_Molecular Biology                                                            -0.1425      0.016     -9.064      0.000      -0.173      -0.112\n",
      "Dept_Molecular Toxicology                                                         -0.1137      0.033     -3.473      0.001      -0.178      -0.050\n",
      "Dept_Molecular and Medical Pharmacology                                           -0.0864      0.020     -4.341      0.000      -0.125      -0.047\n",
      "Dept_Music                                                                        -0.0933      0.029     -3.185      0.001      -0.151      -0.036\n",
      "Dept_Musicology                                                                   -0.0065      0.025     -0.258      0.797      -0.056       0.043\n",
      "Dept_Neurobiology                                                                 -0.2600      0.018    -14.588      0.000      -0.295      -0.225\n",
      "Dept_Nursing                                                                      -0.1490      0.022     -6.931      0.000      -0.191      -0.107\n",
      "Dept_Oral Biology                                                                 -0.1702      0.030     -5.650      0.000      -0.229      -0.111\n",
      "Dept_Philosophy                                                                   -0.1429      0.022     -6.436      0.000      -0.186      -0.099\n",
      "Dept_Physics                                                                      -0.2460      0.016    -15.301      0.000      -0.278      -0.214\n",
      "Dept_Planetary Science                                                            -0.1665      0.146     -1.142      0.253      -0.452       0.119\n",
      "Dept_Political Science                                                            -0.0739      0.017     -4.400      0.000      -0.107      -0.041\n",
      "Dept_Psychology                                                                   -0.0692      0.015     -4.551      0.000      -0.099      -0.039\n",
      "Dept_Public Health                                                                -0.1525      0.027     -5.630      0.000      -0.206      -0.099\n",
      "Dept_Scandinavian Section                                                         -0.0843      0.036     -2.329      0.020      -0.155      -0.013\n",
      "Dept_Slavic Lang & Lit                                                            -0.0439      0.037     -1.198      0.231      -0.116       0.028\n",
      "Dept_Social Welfare                                                               -0.1389      0.022     -6.237      0.000      -0.182      -0.095\n",
      "Dept_Sociology                                                                    -0.0993      0.017     -5.691      0.000      -0.133      -0.065\n",
      "Dept_Spanish                                                                      -0.0163      0.021     -0.787      0.431      -0.057       0.024\n",
      "Dept_Statistics                                                                   -0.0434      0.019     -2.285      0.022      -0.081      -0.006\n",
      "Dept_Theater & Performance St                                                     -0.1124      0.030     -3.703      0.000      -0.172      -0.053\n",
      "Dept_UCLA ACCESS to Programs in the Molecular and Cellular Life Sciences          -0.3267      0.037     -8.859      0.000      -0.399      -0.254\n",
      "Dept_Urban & Regional Planning                                                    -0.0574      0.024     -2.372      0.018      -0.105      -0.010\n",
      "ADMIT_TERM_F03                                                                    -0.0521      0.084     -0.618      0.537      -0.218       0.113\n",
      "ADMIT_TERM_F04                                                                    -0.0457      0.084     -0.541      0.588      -0.211       0.120\n",
      "ADMIT_TERM_F05                                                                    -0.0427      0.084     -0.506      0.613      -0.208       0.123\n",
      "ADMIT_TERM_F06                                                                    -0.0469      0.084     -0.556      0.578      -0.212       0.118\n",
      "ADMIT_TERM_F07                                                                    -0.0208      0.084     -0.247      0.805      -0.186       0.144\n",
      "ADMIT_TERM_F08                                                                    -0.0209      0.084     -0.248      0.804      -0.186       0.144\n",
      "ADMIT_TERM_F09                                                                    -0.0186      0.084     -0.220      0.826      -0.184       0.147\n",
      "ADMIT_TERM_F10                                                                    -0.0227      0.084     -0.269      0.788      -0.188       0.143\n",
      "ADMIT_TERM_F11                                                                    -0.0299      0.084     -0.355      0.723      -0.195       0.135\n",
      "ADMIT_TERM_F12                                                                    -0.0276      0.084     -0.326      0.744      -0.193       0.138\n",
      "ADMIT_TERM_F13                                                                    -0.0150      0.084     -0.178      0.859      -0.180       0.150\n",
      "ADMIT_TERM_F14                                                                    -0.0251      0.084     -0.297      0.766      -0.190       0.140\n",
      "ADMIT_TERM_F15                                                                    -0.0031      0.084     -0.037      0.971      -0.168       0.162\n",
      "ADMIT_TERM_F16                                                                     0.0113      0.084      0.134      0.893      -0.154       0.177\n",
      "ADMIT_TERM_F17                                                                     0.0180      0.084      0.214      0.831      -0.147       0.183\n",
      "ADMIT_TERM_F18                                                                     0.0186      0.084      0.221      0.825      -0.147       0.184\n",
      "ADMIT_TERM_F19                                                                     0.0424      0.084      0.503      0.615      -0.123       0.208\n",
      "ADMIT_TERM_F20                                                                     0.0614      0.084      0.728      0.467      -0.104       0.227\n",
      "ADMIT_TERM_F21                                                                     0.0382      0.084      0.452      0.651      -0.127       0.204\n",
      "ADMIT_TERM_F22                                                                     0.0220      0.085      0.261      0.794      -0.144       0.188\n",
      "ADMIT_TERM_S04                                                                    -0.1215      0.119     -1.022      0.307      -0.355       0.112\n",
      "ADMIT_TERM_S05                                                                    -0.0198      0.124     -0.159      0.873      -0.264       0.224\n",
      "ADMIT_TERM_S06                                                                     0.2527      0.133      1.905      0.057      -0.007       0.513\n",
      "ADMIT_TERM_S07                                                                     0.0377      0.133      0.284      0.776      -0.222       0.298\n",
      "ADMIT_TERM_S08                                                                     0.0145      0.106      0.137      0.891      -0.194       0.223\n",
      "ADMIT_TERM_S09                                                                    -0.0104      0.102     -0.103      0.918      -0.210       0.189\n",
      "ADMIT_TERM_S10                                                                     0.0335      0.098      0.343      0.731      -0.158       0.225\n",
      "ADMIT_TERM_S11                                                                    -0.0430      0.108     -0.396      0.692      -0.255       0.169\n",
      "ADMIT_TERM_S12                                                                    -0.0081      0.095     -0.085      0.932      -0.194       0.178\n",
      "ADMIT_TERM_S13                                                                     0.0404      0.099      0.410      0.682      -0.153       0.234\n",
      "ADMIT_TERM_S14                                                                    -0.0419      0.100     -0.417      0.676      -0.239       0.155\n",
      "ADMIT_TERM_S15                                                                    -0.1505      0.102     -1.482      0.138      -0.350       0.049\n",
      "ADMIT_TERM_S16                                                                    -0.0530      0.103     -0.515      0.606      -0.255       0.149\n",
      "ADMIT_TERM_S17                                                                     0.0354      0.099      0.359      0.720      -0.158       0.229\n",
      "ADMIT_TERM_S18                                                                     0.0742      0.096      0.770      0.442      -0.115       0.263\n",
      "ADMIT_TERM_S19                                                                     0.0573      0.091      0.628      0.530      -0.121       0.236\n",
      "ADMIT_TERM_S20                                                                     0.0480      0.099      0.482      0.630      -0.147       0.243\n",
      "ADMIT_TERM_S21                                                                     0.0400      0.094      0.424      0.672      -0.145       0.225\n",
      "ADMIT_TERM_S22                                                                     0.1239      0.099      1.258      0.209      -0.069       0.317\n",
      "ADMIT_TERM_W03                                                                    -0.0601      0.087     -0.692      0.489      -0.230       0.110\n",
      "ADMIT_TERM_W04                                                                    -0.0016      0.146     -0.011      0.991      -0.288       0.285\n",
      "ADMIT_TERM_W05                                                                     0.1247      0.222      0.562      0.574      -0.310       0.559\n",
      "ADMIT_TERM_W06                                                                    -0.1321      0.168     -0.787      0.431      -0.461       0.197\n",
      "ADMIT_TERM_W07                                                                    -0.0068      0.109     -0.063      0.950      -0.220       0.206\n",
      "ADMIT_TERM_W08                                                                    -0.0883      0.108     -0.815      0.415      -0.301       0.124\n",
      "ADMIT_TERM_W09                                                                    -0.2111      0.102     -2.077      0.038      -0.410      -0.012\n",
      "ADMIT_TERM_W10                                                                     0.0252      0.093      0.270      0.787      -0.158       0.208\n",
      "ADMIT_TERM_W11                                                                     0.0422      0.099      0.425      0.671      -0.153       0.237\n",
      "ADMIT_TERM_W12                                                                     0.0454      0.102      0.447      0.655      -0.154       0.245\n",
      "ADMIT_TERM_W13                                                                     0.0326      0.106      0.307      0.759      -0.175       0.241\n",
      "ADMIT_TERM_W14                                                                     0.0996      0.098      1.019      0.308      -0.092       0.291\n",
      "ADMIT_TERM_W15                                                                    -0.0088      0.098     -0.090      0.929      -0.200       0.183\n",
      "ADMIT_TERM_W16                                                                     0.0186      0.104      0.178      0.858      -0.186       0.223\n",
      "ADMIT_TERM_W17                                                                     0.0456      0.108      0.421      0.674      -0.167       0.258\n",
      "ADMIT_TERM_W18                                                                     0.0707      0.093      0.763      0.445      -0.111       0.252\n",
      "ADMIT_TERM_W19                                                                     0.0574      0.099      0.577      0.564      -0.137       0.252\n",
      "ADMIT_TERM_W20                                                                     0.0414      0.095      0.437      0.662      -0.144       0.227\n",
      "ADMIT_TERM_W21                                                                    -0.0182      0.098     -0.186      0.852      -0.210       0.173\n",
      "ADMIT_TERM_W22                                                                     0.0744      0.099      0.755      0.450      -0.119       0.268\n",
      "ADMIT_TERM_X06                                                                     0.1339      0.168      0.798      0.425      -0.195       0.463\n",
      "ADMIT_TERM_X07                                                                    -0.3465      0.222     -1.562      0.118      -0.781       0.088\n",
      "ADMIT_TERM_X08                                                                     0.1454      0.222      0.656      0.512      -0.289       0.580\n",
      "ADMIT_TERM_X11                                                                     0.0566      0.145      0.389      0.697      -0.228       0.341\n",
      "ADMIT_TERM_X12                                                                     0.0044      0.125      0.035      0.972      -0.240       0.249\n",
      "ADMIT_TERM_X13                                                                     0.0099      0.145      0.068      0.946      -0.275       0.295\n",
      "ADMIT_TERM_X14                                                                    -0.0836      0.168     -0.498      0.618      -0.412       0.245\n",
      "ADMIT_TERM_X15                                                                     0.0571      0.133      0.430      0.667      -0.203       0.317\n",
      "ADMIT_TERM_X16                                                                     0.1269      0.168      0.756      0.449      -0.202       0.456\n",
      "ADMIT_TERM_X17                                                                    -0.0025      0.119     -0.021      0.983      -0.235       0.230\n",
      "ADMIT_TERM_X18                                                                     0.1682      0.168      1.002      0.316      -0.161       0.497\n",
      "ADMIT_TERM_X19                                                                    -0.1431      0.168     -0.853      0.394      -0.472       0.186\n",
      "ADMIT_TERM_X20                                                                     0.1724      0.222      0.777      0.437      -0.262       0.607\n",
      "ADMIT_TERM_X21                                                                     0.1724      0.222      0.777      0.437      -0.262       0.607\n",
      "==============================================================================\n",
      "Omnibus:                     8411.918   Durbin-Watson:                   1.974\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           109219.337\n",
      "Skew:                          -2.293   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.085   Cond. No.                         616.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(\"dat5.xlsx\")\n",
    "df = df.dropna(subset=['year_1_gpa'])\n",
    "df = df.drop(columns=['Dept_code'])\n",
    "\n",
    "# Convert year_1_gpa to numeric\n",
    "df['year_1_gpa'] = pd.to_numeric(df['year_1_gpa'], errors='coerce')\n",
    "\n",
    "# Create dummy variables\n",
    "df = pd.get_dummies(df, columns=['Dept', 'ADMIT_TERM'], drop_first=True)\n",
    "\n",
    "# Define X and y\n",
    "X = df[['st_required'] + list(df.columns[df.columns.str.startswith('Dept_')]) + list(df.columns[df.columns.str.startswith('ADMIT_TERM_')])]\n",
    "y = df['year_1_gpa']\n",
    "\n",
    "# Convert st_required to numeric\n",
    "X['st_required'] = pd.to_numeric(X['st_required'], errors='coerce')\n",
    "\n",
    "# Ensure all dummy variables are numeric\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "# Add constant to X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Check for any remaining non-numeric columns\n",
    "print(X.dtypes)\n",
    "print(y.dtypes)\n",
    "\n",
    "# Drop rows with NaN or infinite values\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "# Fit OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second year GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cp/yvxc2mxs2bqgmwd6cm4_cwsc0000gn/T/ipykernel_831/1166618272.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['gre_required'] = pd.to_numeric(X['gre_required'], errors='coerce')\n",
      "/var/folders/cp/yvxc2mxs2bqgmwd6cm4_cwsc0000gn/T/ipykernel_831/1166618272.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = pd.to_numeric(X[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const                       float64\n",
      "gre_required                  int64\n",
      "Dept_Applied Linguistics      uint8\n",
      "Dept_Archaeology              uint8\n",
      "Dept_Architecture             uint8\n",
      "                             ...   \n",
      "ADMIT_TERM_X17                uint8\n",
      "ADMIT_TERM_X18                uint8\n",
      "ADMIT_TERM_X19                uint8\n",
      "ADMIT_TERM_X20                uint8\n",
      "ADMIT_TERM_X21                uint8\n",
      "Length: 145, dtype: object\n",
      "float64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             year_2_gpa   R-squared:                       0.170\n",
      "Model:                            OLS   Adj. R-squared:                  0.160\n",
      "Method:                 Least Squares   F-statistic:                     18.03\n",
      "Date:                Thu, 11 Jul 2024   Prob (F-statistic):               0.00\n",
      "Time:                        21:47:07   Log-Likelihood:                 3588.2\n",
      "No. Observations:               12833   AIC:                            -6886.\n",
      "Df Residuals:                   12688   BIC:                            -5805.\n",
      "Df Model:                         144                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================================================================================\n",
      "                                                                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                                              3.9717      0.094     42.336      0.000       3.788       4.156\n",
      "gre_required                                                                      -0.0247      0.008     -2.932      0.003      -0.041      -0.008\n",
      "Dept_Applied Linguistics                                                          -0.0311      0.028     -1.090      0.276      -0.087       0.025\n",
      "Dept_Archaeology                                                                  -0.0210      0.026     -0.797      0.425      -0.073       0.031\n",
      "Dept_Architecture                                                                 -0.0687      0.029     -2.398      0.016      -0.125      -0.013\n",
      "Dept_Art History                                                                  -0.0327      0.022     -1.457      0.145      -0.077       0.011\n",
      "Dept_Asian Lang & Cult                                                            -0.0708      0.020     -3.452      0.001      -0.111      -0.031\n",
      "Dept_Astronomy                                                                    -0.1383      0.025     -5.523      0.000      -0.187      -0.089\n",
      "Dept_Atmospheric Sciences                                                         -0.1220      0.022     -5.448      0.000      -0.166      -0.078\n",
      "Dept_Bioengineering                                                               -0.2227      0.017    -13.408      0.000      -0.255      -0.190\n",
      "Dept_Bioinformatics                                                               -0.0690      0.022     -3.196      0.001      -0.111      -0.027\n",
      "Dept_Biology                                                                      -0.0267      0.019     -1.440      0.150      -0.063       0.010\n",
      "Dept_Biomedical Physics                                                           -0.0670      0.022     -3.107      0.002      -0.109      -0.025\n",
      "Dept_Biostatistics                                                                -0.0890      0.022     -4.041      0.000      -0.132      -0.046\n",
      "Dept_Chemical Engineering                                                         -0.2088      0.018    -11.805      0.000      -0.243      -0.174\n",
      "Dept_Chemistry                                                                    -0.2333      0.014    -16.112      0.000      -0.262      -0.205\n",
      "Dept_Chicana and Chicano Studies                                                  -0.0601      0.030     -2.029      0.042      -0.118      -0.002\n",
      "Dept_Choreographic Inquiry                                                        -0.0250      0.024     -1.056      0.291      -0.071       0.021\n",
      "Dept_Civil Engineering                                                            -0.1510      0.017     -8.682      0.000      -0.185      -0.117\n",
      "Dept_Clinical Research                                                            -0.1202      0.032     -3.714      0.000      -0.184      -0.057\n",
      "Dept_Communication                                                                -0.1162      0.055     -2.114      0.035      -0.224      -0.008\n",
      "Dept_Community Health Sciences                                                    -0.1084      0.028     -3.827      0.000      -0.164      -0.053\n",
      "Dept_Comparative Literature                                                       -0.0749      0.024     -3.136      0.002      -0.122      -0.028\n",
      "Dept_Computer Science                                                             -0.1310      0.015     -8.567      0.000      -0.161      -0.101\n",
      "Dept_Conservation of Material Culture                                             -0.0681      0.131     -0.520      0.603      -0.325       0.188\n",
      "Dept_Economics                                                                    -0.2182      0.016    -13.313      0.000      -0.250      -0.186\n",
      "Dept_Education                                                                     0.0046      0.015      0.312      0.755      -0.024       0.034\n",
      "Dept_Education - Joint doctoral program in Special Education w/ Cal State - LA     0.0153      0.033      0.471      0.638      -0.049       0.079\n",
      "Dept_Elect. Engineerig                                                            -0.1007      0.015     -6.689      0.000      -0.130      -0.071\n",
      "Dept_English                                                                      -0.0670      0.018     -3.708      0.000      -0.102      -0.032\n",
      "Dept_Environment and Sustainability                                               -0.0742      0.041     -1.825      0.068      -0.154       0.005\n",
      "Dept_Environmental Health Sciences                                                -0.1229      0.031     -4.022      0.000      -0.183      -0.063\n",
      "Dept_Epidemiology                                                                 -0.1119      0.019     -5.992      0.000      -0.148      -0.075\n",
      "Dept_Ethnomusicology                                                              -0.0636      0.037     -1.717      0.086      -0.136       0.009\n",
      "Dept_Film and TV (MA or PhD)                                                       0.0011      0.023      0.048      0.962      -0.045       0.047\n",
      "Dept_French & Francophone St                                                      -0.0894      0.028     -3.185      0.001      -0.144      -0.034\n",
      "Dept_Gender Studies                                                               -0.0496      0.029     -1.716      0.086      -0.106       0.007\n",
      "Dept_Geography                                                                    -0.0407      0.020     -2.036      0.042      -0.080      -0.002\n",
      "Dept_Geophysics & Space Phy                                                       -0.1230      0.019     -6.518      0.000      -0.160      -0.086\n",
      "Dept_Greek                                                                        -0.1370      0.027     -5.144      0.000      -0.189      -0.085\n",
      "Dept_Health Services                                                              -0.1604      0.021     -7.461      0.000      -0.202      -0.118\n",
      "Dept_History                                                                      -0.0393      0.017     -2.378      0.017      -0.072      -0.007\n",
      "Dept_Human Genetics                                                               -0.1687      0.025     -6.814      0.000      -0.217      -0.120\n",
      "Dept_Indo-European Studies                                                        -0.0719      0.058     -1.247      0.212      -0.185       0.041\n",
      "Dept_Information Studies                                                          -0.0996      0.025     -4.028      0.000      -0.148      -0.051\n",
      "Dept_Islamic Studies                                                              -0.0504      0.021     -2.416      0.016      -0.091      -0.010\n",
      "Dept_Italian                                                                      -0.0021      0.033     -0.065      0.948      -0.066       0.062\n",
      "Dept_Linguistics                                                                  -0.0369      0.022     -1.657      0.098      -0.081       0.007\n",
      "Dept_Management: M.B.A.                                                           -0.1941      0.023     -8.570      0.000      -0.239      -0.150\n",
      "Dept_Manufacturing Engr.                                                          -0.1652      0.015    -10.837      0.000      -0.195      -0.135\n",
      "Dept_Materials Science and Engineering                                            -0.2177      0.017    -13.013      0.000      -0.251      -0.185\n",
      "Dept_Mathematics                                                                  -0.0767      0.016     -4.914      0.000      -0.107      -0.046\n",
      "Dept_Molecular Biology                                                            -0.1481      0.016     -9.485      0.000      -0.179      -0.118\n",
      "Dept_Molecular Toxicology                                                         -0.0853      0.031     -2.715      0.007      -0.147      -0.024\n",
      "Dept_Molecular and Medical Pharmacology                                           -0.0855      0.019     -4.423      0.000      -0.123      -0.048\n",
      "Dept_Music                                                                        -0.0721      0.030     -2.366      0.018      -0.132      -0.012\n",
      "Dept_Musicology                                                                   -0.0028      0.024     -0.115      0.909      -0.050       0.045\n",
      "Dept_Neurobiology                                                                 -0.2706      0.018    -15.433      0.000      -0.305      -0.236\n",
      "Dept_Nursing                                                                      -0.1509      0.021     -7.190      0.000      -0.192      -0.110\n",
      "Dept_Oral Biology                                                                 -0.1672      0.032     -5.241      0.000      -0.230      -0.105\n",
      "Dept_Philosophy                                                                   -0.1606      0.022     -7.403      0.000      -0.203      -0.118\n",
      "Dept_Physics                                                                      -0.2353      0.016    -14.738      0.000      -0.267      -0.204\n",
      "Dept_Political Science                                                            -0.0622      0.017     -3.747      0.000      -0.095      -0.030\n",
      "Dept_Psychology                                                                   -0.0718      0.015     -4.760      0.000      -0.101      -0.042\n",
      "Dept_Public Health                                                                -0.1450      0.026     -5.609      0.000      -0.196      -0.094\n",
      "Dept_Scandinavian Section                                                         -0.0594      0.038     -1.571      0.116      -0.133       0.015\n",
      "Dept_Slavic Lang & Lit                                                            -0.0892      0.038     -2.357      0.018      -0.163      -0.015\n",
      "Dept_Social Welfare                                                               -0.1111      0.022     -4.937      0.000      -0.155      -0.067\n",
      "Dept_Sociology                                                                    -0.0872      0.018     -4.862      0.000      -0.122      -0.052\n",
      "Dept_Spanish                                                                      -0.0114      0.020     -0.558      0.577      -0.051       0.029\n",
      "Dept_Statistics                                                                   -0.0416      0.019     -2.158      0.031      -0.079      -0.004\n",
      "Dept_Theater & Performance St                                                     -0.0676      0.031     -2.202      0.028      -0.128      -0.007\n",
      "Dept_UCLA ACCESS to Programs in the Molecular and Cellular Life Sciences          -0.4860      0.185     -2.633      0.008      -0.848      -0.124\n",
      "Dept_Urban & Regional Planning                                                    -0.0657      0.023     -2.840      0.005      -0.111      -0.020\n",
      "ADMIT_TERM_F03                                                                    -0.0610      0.093     -0.657      0.511      -0.243       0.121\n",
      "ADMIT_TERM_F04                                                                    -0.0530      0.093     -0.571      0.568      -0.235       0.129\n",
      "ADMIT_TERM_F05                                                                    -0.0397      0.093     -0.427      0.669      -0.222       0.142\n",
      "ADMIT_TERM_F06                                                                    -0.0534      0.093     -0.575      0.565      -0.235       0.129\n",
      "ADMIT_TERM_F07                                                                    -0.0310      0.093     -0.334      0.739      -0.213       0.151\n",
      "ADMIT_TERM_F08                                                                    -0.0354      0.093     -0.382      0.703      -0.217       0.146\n",
      "ADMIT_TERM_F09                                                                    -0.0276      0.093     -0.297      0.766      -0.209       0.154\n",
      "ADMIT_TERM_F10                                                                    -0.0276      0.093     -0.298      0.766      -0.210       0.154\n",
      "ADMIT_TERM_F11                                                                    -0.0292      0.093     -0.315      0.753      -0.211       0.153\n",
      "ADMIT_TERM_F12                                                                    -0.0188      0.093     -0.202      0.840      -0.201       0.163\n",
      "ADMIT_TERM_F13                                                                    -0.0225      0.093     -0.242      0.808      -0.204       0.159\n",
      "ADMIT_TERM_F14                                                                    -0.0186      0.093     -0.200      0.841      -0.200       0.163\n",
      "ADMIT_TERM_F15                                                                    -0.0076      0.093     -0.082      0.935      -0.189       0.174\n",
      "ADMIT_TERM_F16                                                                     0.0008      0.093      0.009      0.993      -0.181       0.183\n",
      "ADMIT_TERM_F17                                                                     0.0014      0.093      0.015      0.988      -0.180       0.183\n",
      "ADMIT_TERM_F18                                                                     0.0017      0.093      0.018      0.985      -0.180       0.184\n",
      "ADMIT_TERM_F19                                                                     0.0346      0.093      0.373      0.709      -0.147       0.216\n",
      "ADMIT_TERM_F20                                                                     0.0559      0.093      0.603      0.547      -0.126       0.238\n",
      "ADMIT_TERM_F21                                                                     0.0364      0.093      0.392      0.695      -0.146       0.218\n",
      "ADMIT_TERM_F22                                                                     0.0470      0.207      0.227      0.821      -0.359       0.453\n",
      "ADMIT_TERM_S04                                                                    -0.0347      0.124     -0.279      0.780      -0.278       0.208\n",
      "ADMIT_TERM_S05                                                                    -0.0493      0.124     -0.398      0.691      -0.292       0.194\n",
      "ADMIT_TERM_S06                                                                     0.2862      0.160      1.792      0.073      -0.027       0.599\n",
      "ADMIT_TERM_S07                                                                     0.0054      0.131      0.041      0.967      -0.250       0.261\n",
      "ADMIT_TERM_S08                                                                     0.0207      0.116      0.178      0.858      -0.207       0.248\n",
      "ADMIT_TERM_S09                                                                    -0.0853      0.113     -0.753      0.451      -0.307       0.137\n",
      "ADMIT_TERM_S10                                                                     0.0170      0.103      0.165      0.869      -0.184       0.218\n",
      "ADMIT_TERM_S11                                                                    -0.0645      0.116     -0.558      0.577      -0.291       0.162\n",
      "ADMIT_TERM_S12                                                                    -0.0161      0.101     -0.159      0.874      -0.215       0.183\n",
      "ADMIT_TERM_S13                                                                     0.0004      0.106      0.004      0.997      -0.207       0.208\n",
      "ADMIT_TERM_S14                                                                    -0.0606      0.106     -0.574      0.566      -0.268       0.147\n",
      "ADMIT_TERM_S15                                                                    -0.1611      0.107     -1.508      0.131      -0.370       0.048\n",
      "ADMIT_TERM_S16                                                                    -0.0202      0.109     -0.184      0.854      -0.235       0.194\n",
      "ADMIT_TERM_S17                                                                     0.0087      0.109      0.080      0.937      -0.206       0.223\n",
      "ADMIT_TERM_S18                                                                     0.0618      0.103      0.601      0.548      -0.140       0.263\n",
      "ADMIT_TERM_S19                                                                    -0.0035      0.099     -0.035      0.972      -0.197       0.190\n",
      "ADMIT_TERM_S20                                                                     0.0070      0.107      0.065      0.948      -0.202       0.216\n",
      "ADMIT_TERM_S21                                                                     0.0337      0.102      0.331      0.740      -0.166       0.233\n",
      "ADMIT_TERM_W03                                                                    -0.0812      0.095     -0.853      0.394      -0.268       0.105\n",
      "ADMIT_TERM_W04                                                                     0.0031      0.208      0.015      0.988      -0.405       0.411\n",
      "ADMIT_TERM_W05                                                                     0.0977      0.206      0.474      0.636      -0.306       0.502\n",
      "ADMIT_TERM_W06                                                                    -0.1930      0.160     -1.206      0.228      -0.506       0.121\n",
      "ADMIT_TERM_W07                                                                    -0.0426      0.113     -0.376      0.707      -0.265       0.180\n",
      "ADMIT_TERM_W08                                                                    -0.1142      0.113     -1.010      0.312      -0.336       0.107\n",
      "ADMIT_TERM_W09                                                                    -0.2272      0.111     -2.042      0.041      -0.445      -0.009\n",
      "ADMIT_TERM_W10                                                                     0.0328      0.100      0.327      0.744      -0.164       0.230\n",
      "ADMIT_TERM_W11                                                                     0.0786      0.109      0.718      0.473      -0.136       0.293\n",
      "ADMIT_TERM_W12                                                                     0.0039      0.113      0.035      0.972      -0.218       0.226\n",
      "ADMIT_TERM_W13                                                                     0.0699      0.119      0.587      0.557      -0.164       0.303\n",
      "ADMIT_TERM_W14                                                                     0.0940      0.108      0.871      0.384      -0.118       0.306\n",
      "ADMIT_TERM_W15                                                                    -0.0292      0.103     -0.282      0.778      -0.232       0.174\n",
      "ADMIT_TERM_W16                                                                     0.0058      0.109      0.053      0.958      -0.209       0.220\n",
      "ADMIT_TERM_W17                                                                     0.0290      0.119      0.243      0.808      -0.205       0.263\n",
      "ADMIT_TERM_W18                                                                     0.0591      0.100      0.591      0.554      -0.137       0.255\n",
      "ADMIT_TERM_W19                                                                     0.0323      0.104      0.310      0.757      -0.172       0.236\n",
      "ADMIT_TERM_W20                                                                     0.0229      0.102      0.224      0.823      -0.178       0.223\n",
      "ADMIT_TERM_W21                                                                    -0.0039      0.105     -0.037      0.971      -0.209       0.202\n",
      "ADMIT_TERM_X06                                                                     0.1162      0.160      0.727      0.467      -0.197       0.429\n",
      "ADMIT_TERM_X07                                                                    -0.3713      0.206     -1.801      0.072      -0.775       0.033\n",
      "ADMIT_TERM_X08                                                                     0.1267      0.206      0.615      0.539      -0.277       0.531\n",
      "ADMIT_TERM_X11                                                                     0.0404      0.141      0.286      0.775      -0.236       0.317\n",
      "ADMIT_TERM_X12                                                                    -0.0041      0.124     -0.033      0.973      -0.247       0.239\n",
      "ADMIT_TERM_X13                                                                    -0.0119      0.141     -0.085      0.933      -0.288       0.264\n",
      "ADMIT_TERM_X14                                                                    -0.1023      0.160     -0.640      0.522      -0.416       0.211\n",
      "ADMIT_TERM_X15                                                                     0.0355      0.131      0.272      0.786      -0.221       0.291\n",
      "ADMIT_TERM_X16                                                                     0.1082      0.160      0.677      0.499      -0.205       0.421\n",
      "ADMIT_TERM_X17                                                                    -0.0203      0.119     -0.170      0.865      -0.254       0.214\n",
      "ADMIT_TERM_X18                                                                     0.1519      0.160      0.950      0.342      -0.162       0.465\n",
      "ADMIT_TERM_X19                                                                    -0.1673      0.160     -1.047      0.295      -0.481       0.146\n",
      "ADMIT_TERM_X20                                                                     0.1537      0.206      0.746      0.456      -0.250       0.558\n",
      "ADMIT_TERM_X21                                                                     0.1537      0.206      0.746      0.456      -0.250       0.558\n",
      "==============================================================================\n",
      "Omnibus:                     4267.167   Durbin-Watson:                   1.951\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            17533.462\n",
      "Skew:                          -1.604   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.743   Cond. No.                         680.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(\"dat5.xlsx\")\n",
    "df = df.dropna(subset=['year_2_gpa'])\n",
    "df = df.drop(columns=['Dept_code'])\n",
    "\n",
    "# Convert year_1_gpa to numeric\n",
    "df['year_2_gpa'] = pd.to_numeric(df['year_2_gpa'], errors='coerce')\n",
    "\n",
    "# Create dummy variables\n",
    "df = pd.get_dummies(df, columns=['Dept', 'ADMIT_TERM'], drop_first=True)\n",
    "\n",
    "# Define X and y\n",
    "X = df[['st_required'] + list(df.columns[df.columns.str.startswith('Dept_')]) + list(df.columns[df.columns.str.startswith('ADMIT_TERM_')])]\n",
    "y = df['year_2_gpa']\n",
    "\n",
    "# Convert st_required to numeric\n",
    "X['st_required'] = pd.to_numeric(X['st_required'], errors='coerce')\n",
    "\n",
    "# Ensure all dummy variables are numeric\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "# Add constant to X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Check for any remaining non-numeric columns\n",
    "print(X.dtypes)\n",
    "print(y.dtypes)\n",
    "\n",
    "# Drop rows with NaN or infinite values\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "# Fit OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Separation: Logistic Regression\n",
    "\n",
    "## First year separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average marginal effects for 'gre_required': -6.486116791383242e-06\n",
      "P-value for 'gre_required': 0.999636910894242\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            separated_1   No. Observations:                15735\n",
      "Model:                            GLM   Df Residuals:                    15587\n",
      "Model Family:                Binomial   Df Model:                          147\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -89.313\n",
      "Date:                Thu, 11 Jul 2024   Deviance:                       178.63\n",
      "Time:                        21:47:15   Pearson chi2:                 2.21e+03\n",
      "No. Iterations:                    29   Pseudo R-squ. (CS):           0.006410\n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================================================================================\n",
      "                                                                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                                            -53.7424   1.09e+06  -4.94e-05      1.000   -2.13e+06    2.13e+06\n",
      "gre_required                                                                      23.4924   5.16e+04      0.000      1.000   -1.01e+05    1.01e+05\n",
      "Dept_Applied Linguistics                                                          -0.0060   3.29e+05  -1.82e-08      1.000   -6.45e+05    6.45e+05\n",
      "Dept_Archaeology                                                                   0.0246   2.88e+05   8.54e-08      1.000   -5.65e+05    5.65e+05\n",
      "Dept_Architecture                                                                  0.0974   3.11e+05   3.13e-07      1.000    -6.1e+05     6.1e+05\n",
      "Dept_Art History                                                                  -0.2425   2.52e+05  -9.64e-07      1.000   -4.93e+05    4.93e+05\n",
      "Dept_Asian Lang & Cult                                                             0.0682   2.39e+05   2.86e-07      1.000   -4.68e+05    4.68e+05\n",
      "Dept_Astronomy                                                                     0.9771   2.62e+05   3.73e-06      1.000   -5.14e+05    5.14e+05\n",
      "Dept_Atmospheric Sciences                                                          0.2523   2.42e+05   1.04e-06      1.000   -4.74e+05    4.74e+05\n",
      "Dept_Bioengineering                                                               25.0877   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Bioinformatics                                                                1.8038   2.31e+05   7.81e-06      1.000   -4.53e+05    4.53e+05\n",
      "Dept_Biology                                                                      -0.4084   2.07e+05  -1.97e-06      1.000   -4.06e+05    4.06e+05\n",
      "Dept_Biomedical Physics                                                           -0.0938   2.49e+05  -3.77e-07      1.000   -4.88e+05    4.88e+05\n",
      "Dept_Biostatistics                                                                25.5850   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Chemical Engineering                                                         -0.0452      2e+05  -2.26e-07      1.000   -3.91e+05    3.91e+05\n",
      "Dept_Chemistry                                                                     0.4062    1.6e+05   2.53e-06      1.000   -3.14e+05    3.14e+05\n",
      "Dept_Chicana and Chicano Studies                                                   2.1656   3.26e+05   6.64e-06      1.000   -6.39e+05    6.39e+05\n",
      "Dept_Choreographic Inquiry                                                        25.8588   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Civil Engineering                                                             0.1049   1.95e+05   5.37e-07      1.000   -3.83e+05    3.83e+05\n",
      "Dept_Clinical Research                                                             0.2451   3.67e+05   6.67e-07      1.000    -7.2e+05     7.2e+05\n",
      "Dept_Communication                                                                -0.6961    6.3e+05   -1.1e-06      1.000   -1.23e+06    1.23e+06\n",
      "Dept_Community Health Sciences                                                    28.0455   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Comparative Literature                                                       -0.3102   2.79e+05  -1.11e-06      1.000   -5.46e+05    5.46e+05\n",
      "Dept_Computer Science                                                             24.3781   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Conservation of Material Culture                                             24.2564   1.13e+06   2.15e-05      1.000   -2.21e+06    2.21e+06\n",
      "Dept_Economics                                                                    -0.1774   1.86e+05  -9.54e-07      1.000   -3.65e+05    3.65e+05\n",
      "Dept_Education                                                                    23.3797   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Education - Joint doctoral program in Special Education w/ Cal State - LA     0.0863   3.81e+05   2.27e-07      1.000   -7.46e+05    7.46e+05\n",
      "Dept_Elect. Engineerig                                                            23.7011   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_English                                                                      -0.5826   2.08e+05   -2.8e-06      1.000   -4.08e+05    4.08e+05\n",
      "Dept_Environment and Sustainability                                                0.1863   4.63e+05   4.03e-07      1.000   -9.07e+05    9.07e+05\n",
      "Dept_Environmental Health Sciences                                                -0.5725   3.47e+05  -1.65e-06      1.000   -6.81e+05    6.81e+05\n",
      "Dept_Epidemiology                                                                 -0.0023    2.1e+05  -1.12e-08      1.000   -4.11e+05    4.11e+05\n",
      "Dept_Ethnomusicology                                                              24.5297   3.93e+05   6.25e-05      1.000    -7.7e+05     7.7e+05\n",
      "Dept_Film and TV (MA or PhD)                                                      -0.1966   2.69e+05   -7.3e-07      1.000   -5.28e+05    5.28e+05\n",
      "Dept_French & Francophone St                                                      -0.1499   3.13e+05  -4.79e-07      1.000   -6.13e+05    6.13e+05\n",
      "Dept_Gender Studies                                                                0.4461    3.2e+05    1.4e-06      1.000   -6.27e+05    6.27e+05\n",
      "Dept_Geography                                                                    -0.1422   2.22e+05  -6.41e-07      1.000   -4.35e+05    4.35e+05\n",
      "Dept_Geophysics & Space Phy                                                       -0.2590   2.19e+05  -1.18e-06      1.000   -4.29e+05    4.29e+05\n",
      "Dept_Greek                                                                        -0.4590   3.02e+05  -1.52e-06      1.000   -5.92e+05    5.92e+05\n",
      "Dept_Health Services                                                              -0.0994   2.44e+05  -4.08e-07      1.000   -4.78e+05    4.78e+05\n",
      "Dept_History                                                                      -0.3543   1.86e+05  -1.91e-06      1.000   -3.64e+05    3.64e+05\n",
      "Dept_Human Genetics                                                               26.3186   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Indo-European Studies                                                        24.3216   6.15e+05   3.96e-05      1.000    -1.2e+06     1.2e+06\n",
      "Dept_Information Studies                                                          25.7744   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Islamic Studies                                                              -0.3077   2.31e+05  -1.33e-06      1.000   -4.52e+05    4.52e+05\n",
      "Dept_Italian                                                                      -0.2762    3.6e+05  -7.66e-07      1.000   -7.06e+05    7.06e+05\n",
      "Dept_Linguistics                                                                   0.7977   2.28e+05   3.51e-06      1.000   -4.46e+05    4.46e+05\n",
      "Dept_Management: M.B.A.                                                           23.0448   2.48e+05   9.31e-05      1.000   -4.85e+05    4.85e+05\n",
      "Dept_Manufacturing Engr.                                                          23.7308   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Materials Science and Engineering                                            24.3613   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Mathematics                                                                  -0.0749   1.76e+05  -4.26e-07      1.000   -3.45e+05    3.45e+05\n",
      "Dept_Molecular Biology                                                             0.6828   1.73e+05   3.94e-06      1.000   -3.39e+05    3.39e+05\n",
      "Dept_Molecular Toxicology                                                         -0.1988   3.74e+05  -5.32e-07      1.000   -7.33e+05    7.33e+05\n",
      "Dept_Molecular and Medical Pharmacology                                           -0.0314   2.23e+05  -1.41e-07      1.000   -4.38e+05    4.38e+05\n",
      "Dept_Music                                                                        23.9378   3.16e+05   7.58e-05      1.000   -6.19e+05    6.19e+05\n",
      "Dept_Musicology                                                                   -0.1392   2.86e+05  -4.87e-07      1.000    -5.6e+05     5.6e+05\n",
      "Dept_Neurobiology                                                                 -0.0311   1.97e+05  -1.57e-07      1.000   -3.87e+05    3.87e+05\n",
      "Dept_Nursing                                                                      -0.2696   2.44e+05   -1.1e-06      1.000   -4.79e+05    4.79e+05\n",
      "Dept_Oral Biology                                                                 -0.0269   3.41e+05  -7.89e-08      1.000   -6.68e+05    6.68e+05\n",
      "Dept_Philosophy                                                                   -0.0348    2.5e+05  -1.39e-07      1.000   -4.89e+05    4.89e+05\n",
      "Dept_Physics                                                                       0.8251   1.75e+05    4.7e-06      1.000   -3.44e+05    3.44e+05\n",
      "Dept_Planetary Science                                                            45.7009   1.87e+06   2.45e-05      1.000   -3.66e+06    3.66e+06\n",
      "Dept_Political Science                                                            24.6488   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Psychology                                                                   23.6091   1.46e+05      0.000      1.000   -2.86e+05    2.86e+05\n",
      "Dept_Public Health                                                                -0.4513   3.14e+05  -1.44e-06      1.000   -6.15e+05    6.15e+05\n",
      "Dept_Scandinavian Section                                                         -0.1689   4.14e+05  -4.08e-07      1.000   -8.12e+05    8.12e+05\n",
      "Dept_Slavic Lang & Lit                                                            -0.3553   4.19e+05  -8.48e-07      1.000   -8.21e+05    8.21e+05\n",
      "Dept_Social Welfare                                                               -0.0295   2.53e+05  -1.17e-07      1.000   -4.96e+05    4.96e+05\n",
      "Dept_Sociology                                                                    -0.3263   1.98e+05  -1.65e-06      1.000   -3.88e+05    3.88e+05\n",
      "Dept_Spanish                                                                      -0.1905   2.33e+05  -8.17e-07      1.000   -4.57e+05    4.57e+05\n",
      "Dept_Statistics                                                                    0.2913   2.11e+05   1.38e-06      1.000   -4.14e+05    4.14e+05\n",
      "Dept_Theater & Performance St                                                     -0.3191   3.45e+05  -9.26e-07      1.000   -6.75e+05    6.75e+05\n",
      "Dept_UCLA ACCESS to Programs in the Molecular and Cellular Life Sciences           0.4487   4.07e+05    1.1e-06      1.000   -7.97e+05    7.97e+05\n",
      "Dept_Urban & Regional Planning                                                    -0.2070   2.74e+05  -7.55e-07      1.000   -5.37e+05    5.37e+05\n",
      "ADMIT_TERM_F03                                                                     0.2287   1.08e+06   2.12e-07      1.000   -2.11e+06    2.11e+06\n",
      "ADMIT_TERM_F04                                                                     1.5323   1.08e+06   1.42e-06      1.000   -2.11e+06    2.11e+06\n",
      "ADMIT_TERM_F05                                                                   -23.1119   1.08e+06  -2.14e-05      1.000   -2.12e+06    2.12e+06\n",
      "ADMIT_TERM_F06                                                                     1.4546   1.08e+06   1.35e-06      1.000   -2.11e+06    2.11e+06\n",
      "ADMIT_TERM_F07                                                                     0.1757   1.08e+06   1.63e-07      1.000   -2.11e+06    2.11e+06\n",
      "ADMIT_TERM_F08                                                                   -23.3401   1.08e+06  -2.16e-05      1.000   -2.12e+06    2.12e+06\n",
      "ADMIT_TERM_F09                                                                   -23.5378   1.08e+06  -2.18e-05      1.000   -2.12e+06    2.12e+06\n",
      "ADMIT_TERM_F10                                                                     0.1933   1.08e+06   1.79e-07      1.000   -2.11e+06    2.11e+06\n",
      "ADMIT_TERM_F11                                                                     1.5969   1.08e+06   1.48e-06      1.000   -2.11e+06    2.11e+06\n",
      "ADMIT_TERM_F12                                                                   -23.2531   1.08e+06  -2.15e-05      1.000   -2.12e+06    2.12e+06\n",
      "ADMIT_TERM_F13                                                                   -23.3087   1.08e+06  -2.16e-05      1.000   -2.12e+06    2.12e+06\n",
      "ADMIT_TERM_F14                                                                    -0.4675   1.08e+06  -4.34e-07      1.000   -2.11e+06    2.11e+06\n",
      "ADMIT_TERM_F15                                                                   -23.9257   1.08e+06  -2.22e-05      1.000   -2.12e+06    2.12e+06\n",
      "ADMIT_TERM_F16                                                                   -24.0706   1.08e+06  -2.23e-05      1.000   -2.12e+06    2.12e+06\n",
      "ADMIT_TERM_F17                                                                   -23.9641   1.08e+06  -2.22e-05      1.000   -2.12e+06    2.12e+06\n",
      "ADMIT_TERM_F18                                                                   -24.0429   1.08e+06  -2.23e-05      1.000   -2.12e+06    2.12e+06\n",
      "ADMIT_TERM_F19                                                                   -23.9507   1.08e+06  -2.22e-05      1.000   -2.12e+06    2.12e+06\n",
      "ADMIT_TERM_F20                                                                     0.8906   1.08e+06   8.27e-07      1.000   -2.11e+06    2.11e+06\n",
      "ADMIT_TERM_F21                                                                     0.6490   1.08e+06   6.03e-07      1.000   -2.11e+06    2.11e+06\n",
      "ADMIT_TERM_F22                                                                   -22.5246   1.08e+06  -2.09e-05      1.000   -2.12e+06    2.12e+06\n",
      "ADMIT_TERM_S04                                                                     0.0213   1.51e+06   1.41e-08      1.000   -2.95e+06    2.95e+06\n",
      "ADMIT_TERM_S05                                                                     4.8382   1.08e+06   4.49e-06      1.000   -2.11e+06    2.11e+06\n",
      "ADMIT_TERM_S06                                                                   -22.3739   1.57e+06  -1.43e-05      1.000   -3.07e+06    3.07e+06\n",
      "ADMIT_TERM_S07                                                                   -23.8751    1.7e+06  -1.41e-05      1.000   -3.33e+06    3.33e+06\n",
      "ADMIT_TERM_S08                                                                   -24.5801   1.32e+06  -1.87e-05      1.000   -2.58e+06    2.58e+06\n",
      "ADMIT_TERM_S09                                                                   -24.8504   1.28e+06  -1.93e-05      1.000   -2.52e+06    2.52e+06\n",
      "ADMIT_TERM_S10                                                                   -23.6408   1.22e+06  -1.94e-05      1.000   -2.38e+06    2.38e+06\n",
      "ADMIT_TERM_S11                                                                   -23.9095   1.35e+06  -1.77e-05      1.000   -2.64e+06    2.64e+06\n",
      "ADMIT_TERM_S12                                                                   -24.6618   1.19e+06  -2.07e-05      1.000   -2.34e+06    2.34e+06\n",
      "ADMIT_TERM_S13                                                                   -23.7310   1.25e+06   -1.9e-05      1.000   -2.45e+06    2.45e+06\n",
      "ADMIT_TERM_S14                                                                   -23.2346   1.25e+06  -1.86e-05      1.000   -2.45e+06    2.45e+06\n",
      "ADMIT_TERM_S15                                                                   -23.6704   1.27e+06  -1.86e-05      1.000   -2.49e+06    2.49e+06\n",
      "ADMIT_TERM_S16                                                                   -23.6130   1.27e+06  -1.85e-05      1.000    -2.5e+06     2.5e+06\n",
      "ADMIT_TERM_S17                                                                   -23.4787   1.24e+06   -1.9e-05      1.000   -2.42e+06    2.42e+06\n",
      "ADMIT_TERM_S18                                                                   -23.8344   1.22e+06  -1.96e-05      1.000   -2.38e+06    2.38e+06\n",
      "ADMIT_TERM_S19                                                                   -24.0343   1.16e+06  -2.08e-05      1.000   -2.27e+06    2.27e+06\n",
      "ADMIT_TERM_S20                                                                   -24.1661   1.26e+06  -1.92e-05      1.000   -2.47e+06    2.47e+06\n",
      "ADMIT_TERM_S21                                                                   -23.9795   1.19e+06  -2.01e-05      1.000   -2.33e+06    2.33e+06\n",
      "ADMIT_TERM_S22                                                                   -23.5844   1.23e+06  -1.92e-05      1.000    -2.4e+06     2.4e+06\n",
      "ADMIT_TERM_W03                                                                   -24.0397   1.11e+06  -2.18e-05      1.000   -2.17e+06    2.17e+06\n",
      "ADMIT_TERM_W04                                                                    -0.0624   1.87e+06  -3.34e-08      1.000   -3.67e+06    3.67e+06\n",
      "ADMIT_TERM_W05                                                                    -0.2412   2.84e+06  -8.48e-08      1.000   -5.58e+06    5.58e+06\n",
      "ADMIT_TERM_W06                                                                     0.7127   2.03e+06   3.51e-07      1.000   -3.98e+06    3.98e+06\n",
      "ADMIT_TERM_W07                                                                   -22.6708   1.32e+06  -1.71e-05      1.000    -2.6e+06     2.6e+06\n",
      "ADMIT_TERM_W08                                                                   -24.3049   1.36e+06  -1.79e-05      1.000   -2.66e+06    2.66e+06\n",
      "ADMIT_TERM_W09                                                                   -23.4044   1.26e+06  -1.86e-05      1.000   -2.46e+06    2.46e+06\n",
      "ADMIT_TERM_W10                                                                   -21.7565   1.16e+06  -1.88e-05      1.000   -2.27e+06    2.27e+06\n",
      "ADMIT_TERM_W11                                                                   -23.2684   1.24e+06  -1.88e-05      1.000   -2.43e+06    2.43e+06\n",
      "ADMIT_TERM_W12                                                                   -24.3110   1.27e+06  -1.92e-05      1.000   -2.49e+06    2.49e+06\n",
      "ADMIT_TERM_W13                                                                   -23.6851   1.33e+06  -1.77e-05      1.000   -2.62e+06    2.62e+06\n",
      "ADMIT_TERM_W14                                                                   -24.2516   1.23e+06  -1.96e-05      1.000   -2.42e+06    2.42e+06\n",
      "ADMIT_TERM_W15                                                                   -25.3023    1.2e+06  -2.11e-05      1.000   -2.35e+06    2.35e+06\n",
      "ADMIT_TERM_W16                                                                   -25.7518   1.27e+06  -2.03e-05      1.000   -2.49e+06    2.49e+06\n",
      "ADMIT_TERM_W17                                                                   -23.2381    1.3e+06  -1.79e-05      1.000   -2.55e+06    2.55e+06\n",
      "ADMIT_TERM_W18                                                                   -23.6002   1.17e+06  -2.01e-05      1.000    -2.3e+06     2.3e+06\n",
      "ADMIT_TERM_W19                                                                   -23.7811   1.25e+06  -1.91e-05      1.000   -2.44e+06    2.44e+06\n",
      "ADMIT_TERM_W20                                                                   -24.2735    1.2e+06  -2.03e-05      1.000   -2.35e+06    2.35e+06\n",
      "ADMIT_TERM_W21                                                                   -24.2096   1.24e+06  -1.96e-05      1.000   -2.42e+06    2.42e+06\n",
      "ADMIT_TERM_W22                                                                   -22.9406   1.22e+06  -1.87e-05      1.000    -2.4e+06     2.4e+06\n",
      "ADMIT_TERM_X06                                                                   -24.0172   2.15e+06  -1.12e-05      1.000   -4.21e+06    4.21e+06\n",
      "ADMIT_TERM_X07                                                                   -24.6774   2.84e+06  -8.68e-06      1.000   -5.57e+06    5.57e+06\n",
      "ADMIT_TERM_X08                                                                   -24.0172   2.84e+06  -8.45e-06      1.000   -5.57e+06    5.57e+06\n",
      "ADMIT_TERM_X11                                                                   -23.5003    1.8e+06  -1.31e-05      1.000   -3.52e+06    3.52e+06\n",
      "ADMIT_TERM_X12                                                                   -24.0172    1.6e+06  -1.51e-05      1.000   -3.13e+06    3.13e+06\n",
      "ADMIT_TERM_X13                                                                   -23.8912   1.79e+06  -1.33e-05      1.000   -3.52e+06    3.52e+06\n",
      "ADMIT_TERM_X14                                                                   -24.0172   2.15e+06  -1.12e-05      1.000   -4.21e+06    4.21e+06\n",
      "ADMIT_TERM_X15                                                                   -24.2226   1.69e+06  -1.43e-05      1.000   -3.32e+06    3.32e+06\n",
      "ADMIT_TERM_X16                                                                   -24.0172   2.15e+06  -1.12e-05      1.000   -4.21e+06    4.21e+06\n",
      "ADMIT_TERM_X17                                                                   -23.5003   1.48e+06  -1.59e-05      1.000    -2.9e+06     2.9e+06\n",
      "ADMIT_TERM_X18                                                                    -0.1687   2.15e+06  -7.84e-08      1.000   -4.22e+06    4.22e+06\n",
      "ADMIT_TERM_X19                                                                   -24.0172   2.15e+06  -1.12e-05      1.000   -4.21e+06    4.21e+06\n",
      "ADMIT_TERM_X20                                                                   -24.0172   2.84e+06  -8.45e-06      1.000   -5.57e+06    5.57e+06\n",
      "ADMIT_TERM_X21                                                                   -24.0172   2.84e+06  -8.45e-06      1.000   -5.57e+06    5.57e+06\n",
      "==================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(\"dat5.xlsx\")\n",
    "df = df.dropna(subset=['separated_1'])\n",
    "df = df.drop(columns=['Dept_code'])\n",
    "\n",
    "# Define dependent variable y\n",
    "y = df['separated_1']\n",
    "\n",
    "# Initialize X and add fixed effects for 'Dept' and 'ADMIT_TERM'\n",
    "X = df[['st_required']]\n",
    "X = pd.concat([X, pd.get_dummies(df['Dept'], prefix='Dept', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(df['ADMIT_TERM'], prefix='ADMIT_TERM', drop_first=True)], axis=1)\n",
    "\n",
    "# Ensure all dummy variables are numeric and handle missing values\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN or infinite values\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "# Add constant to X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit model\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "result = model.fit()\n",
    "\n",
    "\n",
    "## Calculate marginal effects\n",
    "\n",
    "# Retrieve coefficients from the fitted model\n",
    "coefficients = result.params\n",
    "\n",
    "# Calculate linear predictor (XB)\n",
    "lin_pred = np.dot(X.drop(columns=['const']), coefficients[1:]) + result.params['const']\n",
    "\n",
    "# Calculate predicted probabilities using the logistic function\n",
    "predicted_probs = 1 / (1 + np.exp(-lin_pred))\n",
    "\n",
    "# Calculate marginal effects for each variable\n",
    "marginal_effects = []\n",
    "\n",
    "for i, coef in enumerate(coefficients[1:]):  # Exclude Intercept\n",
    "    marginal_effect = coef * predicted_probs * (1 - predicted_probs)\n",
    "    marginal_effects.append(marginal_effect)\n",
    "\n",
    "# Include intercept effect (if needed)\n",
    "intercept_effect = result.params['const'] * predicted_probs * (1 - predicted_probs)\n",
    "marginal_effects.append(intercept_effect)\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "marginal_effects = np.array(marginal_effects)\n",
    "average_marginal_effect_st_required = np.mean(marginal_effects[1])\n",
    "\n",
    "# Print marginal effects\n",
    "print(f\"Average marginal effects for 'st_required': {average_marginal_effect_st_required}\")\n",
    "\n",
    "# Output p-value for the coefficient of `st_required`\n",
    "p_value_st_required = result.pvalues['st_required']\n",
    "print(f\"P-value for 'st_required': {p_value_st_required}\")\n",
    "\n",
    "\n",
    "# Output result summary\n",
    "print(\"\")\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second year separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average marginal effects for 'gre_required': 0.015107158026634126\n",
      "P-value for 'gre_required': 0.5075175605586371\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            separated_2   No. Observations:                12872\n",
      "Model:                            GLM   Df Residuals:                    12727\n",
      "Model Family:                Binomial   Df Model:                          144\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -35.215\n",
      "Date:                Thu, 11 Jul 2024   Deviance:                       70.430\n",
      "Time:                        21:47:20   Pearson chi2:                     472.\n",
      "No. Iterations:                    29   Pseudo R-squ. (CS):           0.004936\n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================================================================================\n",
      "                                                                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                                            -51.8300   1.15e+06   -4.5e-05      1.000   -2.26e+06    2.26e+06\n",
      "gre_required                                                                      -0.9933      1.499     -0.663      0.508      -3.931       1.944\n",
      "Dept_Applied Linguistics                                                          25.9050   1.55e+05      0.000      1.000   -3.05e+05    3.05e+05\n",
      "Dept_Archaeology                                                                  -0.1532   3.15e+05  -4.86e-07      1.000   -6.17e+05    6.17e+05\n",
      "Dept_Architecture                                                                  0.3379   3.39e+05   9.98e-07      1.000   -6.64e+05    6.64e+05\n",
      "Dept_Art History                                                                  -0.3807   2.72e+05   -1.4e-06      1.000   -5.33e+05    5.33e+05\n",
      "Dept_Asian Lang & Cult                                                            -0.2834   2.46e+05  -1.15e-06      1.000   -4.82e+05    4.82e+05\n",
      "Dept_Astronomy                                                                    -1.1614    2.9e+05     -4e-06      1.000   -5.69e+05    5.69e+05\n",
      "Dept_Atmospheric Sciences                                                         -0.2236   2.69e+05  -8.33e-07      1.000   -5.27e+05    5.27e+05\n",
      "Dept_Bioengineering                                                               -0.3882   1.99e+05  -1.96e-06      1.000   -3.89e+05    3.89e+05\n",
      "Dept_Bioinformatics                                                               25.9718   1.55e+05      0.000      1.000   -3.05e+05    3.05e+05\n",
      "Dept_Biology                                                                      -0.3452   2.23e+05  -1.55e-06      1.000   -4.37e+05    4.37e+05\n",
      "Dept_Biomedical Physics                                                           -0.9544    2.6e+05  -3.67e-06      1.000    -5.1e+05     5.1e+05\n",
      "Dept_Biostatistics                                                                -0.7725   2.69e+05  -2.87e-06      1.000   -5.28e+05    5.28e+05\n",
      "Dept_Chemical Engineering                                                         -0.6467   2.12e+05  -3.05e-06      1.000   -4.16e+05    4.16e+05\n",
      "Dept_Chemistry                                                                    22.4404   1.55e+05      0.000      1.000   -3.05e+05    3.05e+05\n",
      "Dept_Chicana and Chicano Studies                                                  -0.1844   3.59e+05  -5.13e-07      1.000   -7.04e+05    7.04e+05\n",
      "Dept_Choreographic Inquiry                                                        -0.6427   2.89e+05  -2.23e-06      1.000   -5.66e+05    5.66e+05\n",
      "Dept_Civil Engineering                                                            23.7134   1.55e+05      0.000      1.000   -3.05e+05    3.05e+05\n",
      "Dept_Clinical Research                                                            -0.4914   3.96e+05  -1.24e-06      1.000   -7.76e+05    7.76e+05\n",
      "Dept_Communication                                                                23.2015   7.76e+05   2.99e-05      1.000   -1.52e+06    1.52e+06\n",
      "Dept_Community Health Sciences                                                    -0.1428   3.41e+05  -4.19e-07      1.000   -6.67e+05    6.67e+05\n",
      "Dept_Comparative Literature                                                       -0.7615   2.92e+05  -2.61e-06      1.000   -5.72e+05    5.72e+05\n",
      "Dept_Computer Science                                                             23.8919   1.55e+05      0.000      1.000   -3.05e+05    3.05e+05\n",
      "Dept_Conservation of Material Culture                                             22.1353   1.87e+06   1.18e-05      1.000   -3.66e+06    3.66e+06\n",
      "Dept_Economics                                                                    -0.4049   1.96e+05  -2.06e-06      1.000   -3.85e+05    3.85e+05\n",
      "Dept_Education                                                                    -0.5633   1.77e+05  -3.19e-06      1.000   -3.46e+05    3.46e+05\n",
      "Dept_Education - Joint doctoral program in Special Education w/ Cal State - LA    -0.2173   3.96e+05  -5.48e-07      1.000   -7.77e+05    7.77e+05\n",
      "Dept_Elect. Engineerig                                                            -0.3783   1.79e+05  -2.11e-06      1.000   -3.52e+05    3.52e+05\n",
      "Dept_English                                                                      -0.6371   2.18e+05  -2.92e-06      1.000   -4.28e+05    4.28e+05\n",
      "Dept_Environment and Sustainability                                               22.1678   5.59e+05   3.96e-05      1.000    -1.1e+06     1.1e+06\n",
      "Dept_Environmental Health Sciences                                                 0.0284   3.61e+05   7.87e-08      1.000   -7.07e+05    7.07e+05\n",
      "Dept_Epidemiology                                                                 -0.7272   2.27e+05   -3.2e-06      1.000   -4.45e+05    4.45e+05\n",
      "Dept_Ethnomusicology                                                              -1.5910   4.45e+05  -3.57e-06      1.000   -8.73e+05    8.73e+05\n",
      "Dept_Film and TV (MA or PhD)                                                      -0.4028   2.81e+05  -1.44e-06      1.000    -5.5e+05     5.5e+05\n",
      "Dept_French & Francophone St                                                      -0.2909    3.4e+05  -8.57e-07      1.000   -6.66e+05    6.66e+05\n",
      "Dept_Gender Studies                                                               -0.7914    3.6e+05   -2.2e-06      1.000   -7.05e+05    7.05e+05\n",
      "Dept_Geography                                                                    -0.8320   2.41e+05  -3.45e-06      1.000   -4.72e+05    4.72e+05\n",
      "Dept_Geophysics & Space Phy                                                       -0.6883   2.29e+05  -3.01e-06      1.000   -4.49e+05    4.49e+05\n",
      "Dept_Greek                                                                        -0.2196   3.19e+05  -6.89e-07      1.000   -6.25e+05    6.25e+05\n",
      "Dept_Health Services                                                              -0.4996   2.61e+05  -1.92e-06      1.000   -5.11e+05    5.11e+05\n",
      "Dept_History                                                                      23.9306   1.55e+05      0.000      1.000   -3.05e+05    3.05e+05\n",
      "Dept_Human Genetics                                                               -0.1171   2.99e+05  -3.92e-07      1.000   -5.86e+05    5.86e+05\n",
      "Dept_Indo-European Studies                                                        -1.3546   6.96e+05  -1.95e-06      1.000   -1.36e+06    1.36e+06\n",
      "Dept_Information Studies                                                          -0.8618   3.07e+05  -2.81e-06      1.000   -6.02e+05    6.02e+05\n",
      "Dept_Islamic Studies                                                              -0.6248   2.52e+05  -2.48e-06      1.000   -4.94e+05    4.94e+05\n",
      "Dept_Italian                                                                      -0.6864   4.03e+05   -1.7e-06      1.000   -7.89e+05    7.89e+05\n",
      "Dept_Linguistics                                                                  -0.7619   2.57e+05  -2.96e-06      1.000   -5.05e+05    5.05e+05\n",
      "Dept_Management: M.B.A.                                                           -1.4236   2.52e+05  -5.65e-06      1.000   -4.94e+05    4.94e+05\n",
      "Dept_Manufacturing Engr.                                                          -1.2916   1.81e+05  -7.14e-06      1.000   -3.55e+05    3.55e+05\n",
      "Dept_Materials Science and Engineering                                            -0.4109   1.99e+05  -2.07e-06      1.000    -3.9e+05     3.9e+05\n",
      "Dept_Mathematics                                                                  -0.5334   1.87e+05  -2.85e-06      1.000   -3.67e+05    3.67e+05\n",
      "Dept_Molecular Biology                                                            -0.1765   1.86e+05  -9.49e-07      1.000   -3.64e+05    3.64e+05\n",
      "Dept_Molecular Toxicology                                                         -0.4065   3.79e+05  -1.07e-06      1.000   -7.42e+05    7.42e+05\n",
      "Dept_Molecular and Medical Pharmacology                                           -0.5663   2.33e+05  -2.43e-06      1.000   -4.57e+05    4.57e+05\n",
      "Dept_Music                                                                        -1.2342   3.56e+05  -3.47e-06      1.000   -6.97e+05    6.97e+05\n",
      "Dept_Musicology                                                                   -0.7722   2.99e+05  -2.58e-06      1.000   -5.86e+05    5.86e+05\n",
      "Dept_Neurobiology                                                                 -0.5216   2.08e+05   -2.5e-06      1.000   -4.09e+05    4.09e+05\n",
      "Dept_Nursing                                                                      -0.5173   2.55e+05  -2.03e-06      1.000      -5e+05       5e+05\n",
      "Dept_Oral Biology                                                                  0.2668   3.75e+05   7.11e-07      1.000   -7.36e+05    7.36e+05\n",
      "Dept_Philosophy                                                                   -0.6917   2.64e+05  -2.62e-06      1.000   -5.18e+05    5.18e+05\n",
      "Dept_Physics                                                                      -1.0301   1.86e+05  -5.54e-06      1.000   -3.64e+05    3.64e+05\n",
      "Dept_Political Science                                                            -0.6351   1.99e+05  -3.18e-06      1.000   -3.91e+05    3.91e+05\n",
      "Dept_Psychology                                                                   -0.1709    1.8e+05   -9.5e-07      1.000   -3.53e+05    3.53e+05\n",
      "Dept_Public Health                                                                -0.9656   3.18e+05  -3.04e-06      1.000   -6.23e+05    6.23e+05\n",
      "Dept_Scandinavian Section                                                         -1.6991   4.55e+05  -3.73e-06      1.000   -8.92e+05    8.92e+05\n",
      "Dept_Slavic Lang & Lit                                                            -0.2006   4.52e+05  -4.44e-07      1.000   -8.85e+05    8.85e+05\n",
      "Dept_Social Welfare                                                               -0.4413   2.72e+05  -1.63e-06      1.000   -5.32e+05    5.32e+05\n",
      "Dept_Sociology                                                                    -0.1199   2.14e+05  -5.59e-07      1.000    -4.2e+05     4.2e+05\n",
      "Dept_Spanish                                                                      -0.7482   2.49e+05     -3e-06      1.000   -4.88e+05    4.88e+05\n",
      "Dept_Statistics                                                                    0.0516   2.29e+05   2.25e-07      1.000    -4.5e+05     4.5e+05\n",
      "Dept_Theater & Performance St                                                     -0.4962   3.73e+05  -1.33e-06      1.000   -7.32e+05    7.32e+05\n",
      "Dept_UCLA ACCESS to Programs in the Molecular and Cellular Life Sciences          -2.8333   2.64e+06  -1.07e-06      1.000   -5.17e+06    5.17e+06\n",
      "Dept_Urban & Regional Planning                                                    -0.6219   2.83e+05  -2.19e-06      1.000   -5.56e+05    5.56e+05\n",
      "ADMIT_TERM_F03                                                                    25.0905   1.14e+06    2.2e-05      1.000   -2.23e+06    2.23e+06\n",
      "ADMIT_TERM_F04                                                                     0.3643   1.14e+06   3.18e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F05                                                                     0.1415   1.14e+06   1.24e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F06                                                                    24.3675   1.14e+06   2.14e-05      1.000   -2.23e+06    2.23e+06\n",
      "ADMIT_TERM_F07                                                                     0.3950   1.14e+06   3.45e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F08                                                                    -0.4563   1.14e+06  -3.99e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F09                                                                    23.6452   1.14e+06   2.07e-05      1.000   -2.23e+06    2.23e+06\n",
      "ADMIT_TERM_F10                                                                     0.1951   1.14e+06   1.71e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F11                                                                     0.0682   1.14e+06   5.96e-08      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F12                                                                     0.5651   1.14e+06   4.94e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F13                                                                     0.1517   1.14e+06   1.33e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F14                                                                     0.2729   1.14e+06   2.39e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F15                                                                    24.2206   1.14e+06   2.12e-05      1.000   -2.23e+06    2.23e+06\n",
      "ADMIT_TERM_F16                                                                    24.2518   1.14e+06   2.13e-05      1.000   -2.23e+06    2.23e+06\n",
      "ADMIT_TERM_F17                                                                     0.2531   1.14e+06   2.21e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F18                                                                     0.6480   1.14e+06   5.67e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F19                                                                     0.1219   1.14e+06   1.07e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F20                                                                    -0.7936   1.14e+06  -6.94e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F21                                                                    -1.0221   1.14e+06  -8.94e-07      1.000   -2.24e+06    2.24e+06\n",
      "ADMIT_TERM_F22                                                                    21.3810   2.88e+06   7.43e-06      1.000   -5.64e+06    5.64e+06\n",
      "ADMIT_TERM_S04                                                                     0.4512   1.53e+06   2.96e-07      1.000   -2.99e+06    2.99e+06\n",
      "ADMIT_TERM_S05                                                                     0.2917   1.52e+06   1.92e-07      1.000   -2.98e+06    2.98e+06\n",
      "ADMIT_TERM_S06                                                                    -0.1832   2.18e+06  -8.39e-08      1.000   -4.28e+06    4.28e+06\n",
      "ADMIT_TERM_S07                                                                    22.9111   1.74e+06   1.32e-05      1.000   -3.41e+06    3.41e+06\n",
      "ADMIT_TERM_S08                                                                     2.0902   1.42e+06   1.47e-06      1.000   -2.78e+06    2.78e+06\n",
      "ADMIT_TERM_S09                                                                     0.8078   1.38e+06   5.86e-07      1.000    -2.7e+06     2.7e+06\n",
      "ADMIT_TERM_S10                                                                    -0.8168   1.26e+06  -6.48e-07      1.000   -2.47e+06    2.47e+06\n",
      "ADMIT_TERM_S11                                                                    -0.1197   1.44e+06  -8.34e-08      1.000   -2.81e+06    2.81e+06\n",
      "ADMIT_TERM_S12                                                                     0.6090   1.24e+06    4.9e-07      1.000   -2.44e+06    2.44e+06\n",
      "ADMIT_TERM_S13                                                                    22.9226   1.35e+06   1.69e-05      1.000   -2.65e+06    2.65e+06\n",
      "ADMIT_TERM_S14                                                                     1.3192   1.29e+06   1.02e-06      1.000   -2.53e+06    2.53e+06\n",
      "ADMIT_TERM_S15                                                                    22.6505   1.37e+06   1.65e-05      1.000   -2.68e+06    2.68e+06\n",
      "ADMIT_TERM_S16                                                                     1.0546   1.33e+06   7.92e-07      1.000   -2.61e+06    2.61e+06\n",
      "ADMIT_TERM_S17                                                                    22.6403   1.41e+06    1.6e-05      1.000   -2.77e+06    2.77e+06\n",
      "ADMIT_TERM_S18                                                                     0.1544   1.27e+06   1.22e-07      1.000   -2.48e+06    2.48e+06\n",
      "ADMIT_TERM_S19                                                                     0.4883   1.22e+06   4.02e-07      1.000   -2.38e+06    2.38e+06\n",
      "ADMIT_TERM_S20                                                                     0.5891   1.31e+06   4.51e-07      1.000   -2.56e+06    2.56e+06\n",
      "ADMIT_TERM_S21                                                                     0.6627   1.25e+06    5.3e-07      1.000   -2.45e+06    2.45e+06\n",
      "ADMIT_TERM_W03                                                                    -0.3922   1.17e+06  -3.35e-07      1.000   -2.29e+06    2.29e+06\n",
      "ADMIT_TERM_W04                                                                    22.9437   2.89e+06   7.93e-06      1.000   -5.67e+06    5.67e+06\n",
      "ADMIT_TERM_W05                                                                    22.7907   2.87e+06   7.94e-06      1.000   -5.62e+06    5.62e+06\n",
      "ADMIT_TERM_W06                                                                    21.7726   2.13e+06   1.02e-05      1.000   -4.17e+06    4.17e+06\n",
      "ADMIT_TERM_W07                                                                    22.9515   1.47e+06   1.56e-05      1.000   -2.89e+06    2.89e+06\n",
      "ADMIT_TERM_W08                                                                     0.8140   1.38e+06   5.91e-07      1.000    -2.7e+06     2.7e+06\n",
      "ADMIT_TERM_W09                                                                     1.1100   1.35e+06    8.2e-07      1.000   -2.65e+06    2.65e+06\n",
      "ADMIT_TERM_W10                                                                    22.7900   1.27e+06    1.8e-05      1.000   -2.49e+06    2.49e+06\n",
      "ADMIT_TERM_W11                                                                    22.8194   1.41e+06   1.62e-05      1.000   -2.76e+06    2.76e+06\n",
      "ADMIT_TERM_W12                                                                     0.6603    1.4e+06   4.73e-07      1.000   -2.74e+06    2.74e+06\n",
      "ADMIT_TERM_W13                                                                    22.7597   1.57e+06   1.45e-05      1.000   -3.07e+06    3.07e+06\n",
      "ADMIT_TERM_W14                                                                     1.1637   1.31e+06   8.87e-07      1.000   -2.57e+06    2.57e+06\n",
      "ADMIT_TERM_W15                                                                     1.0530   1.26e+06   8.37e-07      1.000   -2.47e+06    2.47e+06\n",
      "ADMIT_TERM_W16                                                                     0.3695   1.34e+06   2.75e-07      1.000   -2.64e+06    2.64e+06\n",
      "ADMIT_TERM_W17                                                                    -1.3586    1.4e+06  -9.71e-07      1.000   -2.74e+06    2.74e+06\n",
      "ADMIT_TERM_W18                                                                    27.2389   1.14e+06   2.39e-05      1.000   -2.23e+06    2.23e+06\n",
      "ADMIT_TERM_W19                                                                    -0.7760   1.27e+06  -6.13e-07      1.000   -2.48e+06    2.48e+06\n",
      "ADMIT_TERM_W20                                                                     0.5466   1.26e+06   4.35e-07      1.000   -2.46e+06    2.46e+06\n",
      "ADMIT_TERM_W21                                                                     0.3186   1.29e+06   2.47e-07      1.000   -2.53e+06    2.53e+06\n",
      "ADMIT_TERM_X06                                                                    22.6355   2.18e+06   1.04e-05      1.000   -4.28e+06    4.28e+06\n",
      "ADMIT_TERM_X07                                                                    22.6681   2.87e+06    7.9e-06      1.000   -5.63e+06    5.63e+06\n",
      "ADMIT_TERM_X08                                                                    22.6355   2.87e+06   7.89e-06      1.000   -5.62e+06    5.62e+06\n",
      "ADMIT_TERM_X11                                                                    22.7185    1.9e+06    1.2e-05      1.000   -3.72e+06    3.72e+06\n",
      "ADMIT_TERM_X12                                                                    22.6355   1.64e+06   1.38e-05      1.000   -3.22e+06    3.22e+06\n",
      "ADMIT_TERM_X13                                                                    -0.3055   1.77e+06  -1.73e-07      1.000   -3.47e+06    3.47e+06\n",
      "ADMIT_TERM_X14                                                                    22.6355   2.18e+06   1.04e-05      1.000   -4.28e+06    4.28e+06\n",
      "ADMIT_TERM_X15                                                                     0.0323   1.62e+06      2e-08      1.000   -3.17e+06    3.17e+06\n",
      "ADMIT_TERM_X16                                                                    22.6355   2.18e+06   1.04e-05      1.000   -4.28e+06    4.28e+06\n",
      "ADMIT_TERM_X17                                                                     0.6608   1.46e+06   4.52e-07      1.000   -2.86e+06    2.86e+06\n",
      "ADMIT_TERM_X18                                                                    22.9247   2.18e+06   1.05e-05      1.000   -4.28e+06    4.28e+06\n",
      "ADMIT_TERM_X19                                                                    22.6355   2.18e+06   1.04e-05      1.000   -4.28e+06    4.28e+06\n",
      "ADMIT_TERM_X20                                                                    22.6355   2.87e+06   7.89e-06      1.000   -5.62e+06    5.62e+06\n",
      "ADMIT_TERM_X21                                                                    22.6355   2.87e+06   7.89e-06      1.000   -5.62e+06    5.62e+06\n",
      "==================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(\"dat5.xlsx\")\n",
    "df = df.dropna(subset=['separated_2'])\n",
    "df = df.drop(columns=['Dept_code'])\n",
    "\n",
    "# Define dependent variable y\n",
    "y = df['separated_2']\n",
    "\n",
    "# Initialize X and add fixed effects for 'Dept' and 'ADMIT_TERM'\n",
    "X = df[['st_required']]\n",
    "X = pd.concat([X, pd.get_dummies(df['Dept'], prefix='Dept', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(df['ADMIT_TERM'], prefix='ADMIT_TERM', drop_first=True)], axis=1)\n",
    "\n",
    "# Ensure all dummy variables are numeric and handle missing values\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN or infinite values\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "# Add constant to X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit model\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "result = model.fit()\n",
    "\n",
    "\n",
    "## Calculate marginal effects\n",
    "\n",
    "# Retrieve coefficients from the fitted model\n",
    "coefficients = result.params\n",
    "\n",
    "# Calculate linear predictor (XB)\n",
    "lin_pred = np.dot(X.drop(columns=['const']), coefficients[1:]) + result.params['const']\n",
    "\n",
    "# Calculate predicted probabilities using the logistic function\n",
    "predicted_probs = 1 / (1 + np.exp(-lin_pred))\n",
    "\n",
    "# Calculate marginal effects for each variable\n",
    "marginal_effects = []\n",
    "\n",
    "for i, coef in enumerate(coefficients[1:]):  # Exclude Intercept\n",
    "    marginal_effect = coef * predicted_probs * (1 - predicted_probs)\n",
    "    marginal_effects.append(marginal_effect)\n",
    "\n",
    "# Include intercept effect (if needed)\n",
    "intercept_effect = result.params['const'] * predicted_probs * (1 - predicted_probs)\n",
    "marginal_effects.append(intercept_effect)\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "marginal_effects = np.array(marginal_effects)\n",
    "average_marginal_effect_st_required = np.mean(marginal_effects[1])\n",
    "\n",
    "# Print marginal effects\n",
    "print(f\"Average marginal effects for 'st_required': {average_marginal_effect_st_required}\")\n",
    "\n",
    "# Output p-value for the coefficient of `st_required`\n",
    "p_value_st_required = result.pvalues['st_required']\n",
    "print(f\"P-value for 'st_required': {p_value_st_required}\")\n",
    "\n",
    "\n",
    "# Output result summary\n",
    "print(\"\")\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URG Identity: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average marginal effects for 'gre_required': -0.0658266374644187\n",
      "P-value for 'gre_required': 0.001841563758861527\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                    URM   No. Observations:                20540\n",
      "Model:                            GLM   Df Residuals:                    20387\n",
      "Model Family:                Binomial   Df Model:                          152\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -7534.1\n",
      "Date:                Thu, 11 Jul 2024   Deviance:                       15068.\n",
      "Time:                        21:47:26   Pearson chi2:                 2.01e+04\n",
      "No. Iterations:                    24   Pseudo R-squ. (CS):            0.08913\n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================================================================================\n",
      "                                                                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                                             -0.5374      0.586     -0.917      0.359      -1.686       0.611\n",
      "gre_required                                                                      -0.2837      0.091     -3.115      0.002      -0.462      -0.105\n",
      "Dept_Applied Linguistics                                                          -0.5904      0.430     -1.373      0.170      -1.433       0.252\n",
      "Dept_Archaeology                                                                  -0.1573      0.312     -0.504      0.614      -0.769       0.454\n",
      "Dept_Architecture                                                                 -0.9830      0.450     -2.183      0.029      -1.866      -0.100\n",
      "Dept_Art History                                                                  -0.3809      0.280     -1.359      0.174      -0.930       0.169\n",
      "Dept_Asian Lang & Cult                                                            -2.2327      0.528     -4.232      0.000      -3.267      -1.199\n",
      "Dept_Astronomy                                                                    -0.6379      0.324     -1.968      0.049      -1.273      -0.003\n",
      "Dept_Atmospheric Sciences                                                         -0.6467      0.286     -2.260      0.024      -1.208      -0.086\n",
      "Dept_Bioengineering                                                               -1.0779      0.230     -4.693      0.000      -1.528      -0.628\n",
      "Dept_Bioinformatics                                                               -1.2359      0.338     -3.661      0.000      -1.897      -0.574\n",
      "Dept_Biology                                                                       0.0940      0.212      0.443      0.658      -0.322       0.510\n",
      "Dept_Biomedical Physics                                                           -0.3669      0.283     -1.295      0.195      -0.922       0.188\n",
      "Dept_Biostatistics                                                                -0.8434      0.327     -2.580      0.010      -1.484      -0.203\n",
      "Dept_Chemical Engineering                                                         -0.7633      0.245     -3.118      0.002      -1.243      -0.283\n",
      "Dept_Chemistry                                                                    -0.2808      0.169     -1.666      0.096      -0.611       0.050\n",
      "Dept_Chicana and Chicano Studies                                                   2.0268      0.265      7.636      0.000       1.507       2.547\n",
      "Dept_Choreographic Inquiry                                                         0.3138      0.260      1.206      0.228      -0.196       0.824\n",
      "Dept_Civil Engineering                                                            -0.5348      0.221     -2.419      0.016      -0.968      -0.102\n",
      "Dept_Clinical Research                                                            -0.4153      0.409     -1.015      0.310      -1.218       0.387\n",
      "Dept_Communication                                                                -0.5021      0.639     -0.786      0.432      -1.754       0.750\n",
      "Dept_Community Health Sciences                                                     0.6558      0.271      2.421      0.015       0.125       1.187\n",
      "Dept_Comparative Literature                                                       -0.1975      0.303     -0.651      0.515      -0.792       0.397\n",
      "Dept_Computer Science                                                             -1.7982      0.242     -7.445      0.000      -2.272      -1.325\n",
      "Dept_Conservation of Material Culture                                             -0.2198      1.107     -0.199      0.843      -2.390       1.951\n",
      "Dept_Economics                                                                    -2.3356      0.357     -6.536      0.000      -3.036      -1.635\n",
      "Dept_Education                                                                     1.1466      0.162      7.067      0.000       0.829       1.465\n",
      "Dept_Education - Joint doctoral program in Special Education w/ Cal State - LA     0.4001      0.354      1.130      0.258      -0.294       1.094\n",
      "Dept_Elect. Engineerig                                                            -1.9007      0.229     -8.317      0.000      -2.349      -1.453\n",
      "Dept_English                                                                       0.1805      0.207      0.870      0.384      -0.226       0.587\n",
      "Dept_Environment and Sustainability                                                0.4689      0.375      1.251      0.211      -0.266       1.204\n",
      "Dept_Environmental Health Sciences                                                 0.2315      0.304      0.763      0.446      -0.364       0.827\n",
      "Dept_Epidemiology                                                                 -0.8317      0.244     -3.406      0.001      -1.310      -0.353\n",
      "Dept_Ethnomusicology                                                               0.0642      0.375      0.171      0.864      -0.670       0.799\n",
      "Dept_Film and TV (MA or PhD)                                                       0.2135      0.247      0.864      0.387      -0.271       0.697\n",
      "Dept_French & Francophone St                                                      -0.9243      0.451     -2.048      0.041      -1.809      -0.040\n",
      "Dept_Gender Studies                                                                0.8579      0.267      3.212      0.001       0.334       1.381\n",
      "Dept_Geography                                                                    -0.4005      0.249     -1.607      0.108      -0.889       0.088\n",
      "Dept_Geophysics & Space Phy                                                       -0.4879      0.248     -1.966      0.049      -0.974      -0.001\n",
      "Dept_Greek                                                                        -0.7114      0.382     -1.864      0.062      -1.459       0.037\n",
      "Dept_Health Services                                                              -0.0007      0.241     -0.003      0.998      -0.473       0.471\n",
      "Dept_History                                                                       0.0277      0.193      0.144      0.886      -0.350       0.405\n",
      "Dept_Human Genetics                                                               -0.0224      0.277     -0.081      0.936      -0.565       0.520\n",
      "Dept_Indo-European Studies                                                       -24.4110   5.08e+04     -0.000      1.000   -9.97e+04    9.96e+04\n",
      "Dept_Information Studies                                                           0.3435      0.255      1.345      0.179      -0.157       0.844\n",
      "Dept_Islamic Studies                                                              -0.4221      0.262     -1.613      0.107      -0.935       0.091\n",
      "Dept_Italian                                                                      -0.4377      0.460     -0.951      0.341      -1.339       0.464\n",
      "Dept_Latin American Studies                                                      -23.8255   2.16e+05     -0.000      1.000   -4.23e+05    4.23e+05\n",
      "Dept_Linguistics                                                                  -0.9423      0.309     -3.047      0.002      -1.548      -0.336\n",
      "Dept_Management: M.B.A.                                                           -1.9429      0.452     -4.295      0.000      -2.830      -1.056\n",
      "Dept_Manufacturing Engr.                                                          -0.7397      0.189     -3.908      0.000      -1.111      -0.369\n",
      "Dept_Materials Science and Engineering                                            -1.1744      0.242     -4.855      0.000      -1.649      -0.700\n",
      "Dept_Mathematics                                                                  -1.5937      0.247     -6.443      0.000      -2.078      -1.109\n",
      "Dept_Molecular Biology                                                            -0.0016      0.176     -0.009      0.993      -0.347       0.344\n",
      "Dept_Molecular Toxicology                                                          0.4711      0.322      1.461      0.144      -0.161       1.103\n",
      "Dept_Molecular and Medical Pharmacology                                           -0.3314      0.243     -1.365      0.172      -0.807       0.145\n",
      "Dept_Music                                                                        -0.2977      0.342     -0.871      0.384      -0.967       0.372\n",
      "Dept_Musicology                                                                   -0.2393      0.317     -0.755      0.450      -0.861       0.382\n",
      "Dept_Neurobiology                                                                 -0.1662      0.203     -0.816      0.414      -0.565       0.233\n",
      "Dept_Nursing                                                                       1.1951      0.208      5.755      0.000       0.788       1.602\n",
      "Dept_Oral Biology                                                                 -1.4625      0.535     -2.736      0.006      -2.510      -0.415\n",
      "Dept_Philosophy                                                                   -0.4587      0.283     -1.623      0.105      -1.013       0.095\n",
      "Dept_Physics                                                                      -0.8575      0.209     -4.102      0.000      -1.267      -0.448\n",
      "Dept_Planetary Science                                                            -0.7739      1.074     -0.721      0.471      -2.878       1.330\n",
      "Dept_Political Science                                                             0.2202      0.191      1.154      0.249      -0.154       0.594\n",
      "Dept_Psychology                                                                   -0.0804      0.178     -0.452      0.651      -0.429       0.268\n",
      "Dept_Public Health                                                                 0.9216      0.256      3.601      0.000       0.420       1.423\n",
      "Dept_Scandinavian Section                                                         -1.2959      0.742     -1.746      0.081      -2.751       0.159\n",
      "Dept_Slavic Lang & Lit                                                            -0.6828      0.551     -1.238      0.216      -1.763       0.398\n",
      "Dept_Social Welfare                                                                0.6197      0.226      2.746      0.006       0.177       1.062\n",
      "Dept_Sociology                                                                     0.3413      0.194      1.760      0.078      -0.039       0.721\n",
      "Dept_Spanish                                                                       1.4897      0.205      7.257      0.000       1.087       1.892\n",
      "Dept_Statistics                                                                   -1.0973      0.290     -3.783      0.000      -1.666      -0.529\n",
      "Dept_Theater & Performance St                                                      0.3925      0.311      1.264      0.206      -0.216       1.001\n",
      "Dept_UCLA ACCESS to Programs in the Molecular and Cellular Life Sciences          -0.0072      0.197     -0.036      0.971      -0.394       0.379\n",
      "Dept_Urban & Regional Planning                                                     0.0277      0.272      0.102      0.919      -0.505       0.560\n",
      "ADMIT_TERM_F03                                                                    -0.8931      0.567     -1.575      0.115      -2.004       0.218\n",
      "ADMIT_TERM_F04                                                                    -0.8154      0.568     -1.437      0.151      -1.928       0.297\n",
      "ADMIT_TERM_F05                                                                    -0.9194      0.568     -1.619      0.106      -2.033       0.194\n",
      "ADMIT_TERM_F06                                                                    -1.1543      0.568     -2.032      0.042      -2.268      -0.041\n",
      "ADMIT_TERM_F07                                                                    -0.8853      0.566     -1.564      0.118      -1.995       0.224\n",
      "ADMIT_TERM_F08                                                                    -1.1580      0.568     -2.040      0.041      -2.271      -0.045\n",
      "ADMIT_TERM_F09                                                                    -0.9959      0.569     -1.752      0.080      -2.110       0.119\n",
      "ADMIT_TERM_F10                                                                    -0.7068      0.568     -1.244      0.214      -1.821       0.407\n",
      "ADMIT_TERM_F11                                                                    -0.7865      0.568     -1.384      0.166      -1.900       0.327\n",
      "ADMIT_TERM_F12                                                                    -0.8042      0.569     -1.414      0.157      -1.919       0.311\n",
      "ADMIT_TERM_F13                                                                    -0.9372      0.568     -1.649      0.099      -2.051       0.177\n",
      "ADMIT_TERM_F14                                                                    -0.6224      0.568     -1.097      0.273      -1.735       0.490\n",
      "ADMIT_TERM_F15                                                                    -0.6349      0.567     -1.119      0.263      -1.747       0.477\n",
      "ADMIT_TERM_F16                                                                    -0.5738      0.567     -1.012      0.311      -1.685       0.537\n",
      "ADMIT_TERM_F17                                                                    -0.4418      0.566     -0.780      0.435      -1.551       0.668\n",
      "ADMIT_TERM_F18                                                                    -0.4749      0.566     -0.839      0.401      -1.584       0.634\n",
      "ADMIT_TERM_F19                                                                    -0.5835      0.566     -1.031      0.302      -1.692       0.525\n",
      "ADMIT_TERM_F20                                                                    -0.6360      0.566     -1.123      0.262      -1.746       0.474\n",
      "ADMIT_TERM_F21                                                                    -0.4662      0.566     -0.823      0.410      -1.576       0.644\n",
      "ADMIT_TERM_F22                                                                    -0.8223      0.570     -1.444      0.149      -1.939       0.294\n",
      "ADMIT_TERM_F23                                                                    -0.7264      0.570     -1.275      0.202      -1.843       0.390\n",
      "ADMIT_TERM_S03                                                                     0.7868      1.734      0.454      0.650      -2.611       4.185\n",
      "ADMIT_TERM_S04                                                                   -24.1720   6.26e+04     -0.000      1.000   -1.23e+05    1.23e+05\n",
      "ADMIT_TERM_S05                                                                   -24.3818    8.5e+04     -0.000      1.000   -1.67e+05    1.67e+05\n",
      "ADMIT_TERM_S06                                                                   -24.3961   6.22e+04     -0.000      1.000   -1.22e+05    1.22e+05\n",
      "ADMIT_TERM_S07                                                                     0.2025      0.928      0.218      0.827      -1.617       2.022\n",
      "ADMIT_TERM_S08                                                                     0.0030      0.827      0.004      0.997      -1.618       1.623\n",
      "ADMIT_TERM_S09                                                                   -24.0278   4.35e+04     -0.001      1.000   -8.53e+04    8.53e+04\n",
      "ADMIT_TERM_S10                                                                     0.1451      0.715      0.203      0.839      -1.257       1.547\n",
      "ADMIT_TERM_S11                                                                    -0.4951      0.966     -0.513      0.608      -2.388       1.398\n",
      "ADMIT_TERM_S12                                                                    -0.9172      0.935     -0.981      0.327      -2.750       0.916\n",
      "ADMIT_TERM_S13                                                                    -1.0845      1.179     -0.920      0.358      -3.395       1.226\n",
      "ADMIT_TERM_S14                                                                    -1.4721      1.185     -1.242      0.214      -3.794       0.850\n",
      "ADMIT_TERM_S15                                                                    -0.4727      0.946     -0.500      0.617      -2.326       1.381\n",
      "ADMIT_TERM_S16                                                                   -23.7375   5.42e+04     -0.000      1.000   -1.06e+05    1.06e+05\n",
      "ADMIT_TERM_S17                                                                    -0.1315      0.945     -0.139      0.889      -1.984       1.721\n",
      "ADMIT_TERM_S18                                                                    -1.4780      1.170     -1.263      0.207      -3.772       0.816\n",
      "ADMIT_TERM_S19                                                                    -1.2904      0.922     -1.400      0.161      -3.097       0.516\n",
      "ADMIT_TERM_S20                                                                   -23.6916   5.17e+04     -0.000      1.000   -1.01e+05    1.01e+05\n",
      "ADMIT_TERM_S21                                                                    -0.8030      0.930     -0.863      0.388      -2.626       1.021\n",
      "ADMIT_TERM_S22                                                                    -0.5404      0.938     -0.576      0.565      -2.379       1.298\n",
      "ADMIT_TERM_S23                                                                   -23.8318   5.06e+04     -0.000      1.000   -9.92e+04    9.91e+04\n",
      "ADMIT_TERM_W03                                                                    -3.0753      0.908     -3.387      0.001      -4.855      -1.296\n",
      "ADMIT_TERM_W04                                                                    -1.0179      1.211     -0.841      0.401      -3.392       1.356\n",
      "ADMIT_TERM_W05                                                                   -23.1512   2.16e+05     -0.000      1.000   -4.23e+05    4.23e+05\n",
      "ADMIT_TERM_W06                                                                     2.9068      1.434      2.027      0.043       0.096       5.717\n",
      "ADMIT_TERM_W07                                                                    -1.0008      0.975     -1.027      0.304      -2.911       0.909\n",
      "ADMIT_TERM_W08                                                                    -0.7313      0.953     -0.768      0.443      -2.599       1.136\n",
      "ADMIT_TERM_W09                                                                    -0.6226      0.854     -0.729      0.466      -2.296       1.051\n",
      "ADMIT_TERM_W10                                                                    -1.5728      0.770     -2.043      0.041      -3.081      -0.064\n",
      "ADMIT_TERM_W11                                                                   -24.4532   3.78e+04     -0.001      0.999   -7.41e+04     7.4e+04\n",
      "ADMIT_TERM_W12                                                                    -1.3455      1.184     -1.137      0.256      -3.666       0.975\n",
      "ADMIT_TERM_W13                                                                     0.1520      0.870      0.175      0.861      -1.553       1.857\n",
      "ADMIT_TERM_W14                                                                    -0.6890      0.940     -0.733      0.464      -2.532       1.154\n",
      "ADMIT_TERM_W15                                                                    -1.5718      0.968     -1.625      0.104      -3.468       0.325\n",
      "ADMIT_TERM_W16                                                                   -24.1791   4.81e+04     -0.001      1.000   -9.43e+04    9.42e+04\n",
      "ADMIT_TERM_W17                                                                   -24.1369   5.79e+04     -0.000      1.000   -1.14e+05    1.13e+05\n",
      "ADMIT_TERM_W18                                                                   -23.8975   3.28e+04     -0.001      0.999   -6.43e+04    6.43e+04\n",
      "ADMIT_TERM_W19                                                                    -0.3666      0.940     -0.390      0.697      -2.209       1.476\n",
      "ADMIT_TERM_W20                                                                    -1.2105      0.944     -1.282      0.200      -3.061       0.641\n",
      "ADMIT_TERM_W21                                                                   -23.8051   4.85e+04     -0.000      1.000   -9.51e+04     9.5e+04\n",
      "ADMIT_TERM_W22                                                                   -23.7983   4.72e+04     -0.001      1.000   -9.24e+04    9.24e+04\n",
      "ADMIT_TERM_W23                                                                    -0.9623      1.188     -0.810      0.418      -3.292       1.367\n",
      "ADMIT_TERM_X06                                                                   -22.8442   1.53e+05     -0.000      1.000   -2.99e+05    2.99e+05\n",
      "ADMIT_TERM_X07                                                                   -23.5705   2.16e+05     -0.000      1.000   -4.23e+05    4.23e+05\n",
      "ADMIT_TERM_X08                                                                   -22.8442   2.16e+05     -0.000      1.000   -4.23e+05    4.23e+05\n",
      "ADMIT_TERM_X11                                                                   -23.2297   1.06e+05     -0.000      1.000   -2.08e+05    2.08e+05\n",
      "ADMIT_TERM_X12                                                                   -22.8442   8.82e+04     -0.000      1.000   -1.73e+05    1.73e+05\n",
      "ADMIT_TERM_X13                                                                   -23.1948   1.24e+05     -0.000      1.000   -2.42e+05    2.42e+05\n",
      "ADMIT_TERM_X14                                                                   -22.8442   1.53e+05     -0.000      1.000   -2.99e+05    2.99e+05\n",
      "ADMIT_TERM_X15                                                                   -22.8652   9.66e+04     -0.000      1.000   -1.89e+05    1.89e+05\n",
      "ADMIT_TERM_X16                                                                   -22.8442   1.25e+05     -0.000      1.000   -2.44e+05    2.44e+05\n",
      "ADMIT_TERM_X17                                                                   -23.2415   7.03e+04     -0.000      1.000   -1.38e+05    1.38e+05\n",
      "ADMIT_TERM_X18                                                                     1.4468      1.530      0.946      0.344      -1.552       4.446\n",
      "ADMIT_TERM_X19                                                                   -22.8442   1.53e+05     -0.000      1.000   -2.99e+05    2.99e+05\n",
      "ADMIT_TERM_X20                                                                   -22.8442   2.16e+05     -0.000      1.000   -4.23e+05    4.23e+05\n",
      "ADMIT_TERM_X21                                                                   -22.8442   2.16e+05     -0.000      1.000   -4.23e+05    4.23e+05\n",
      "==================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(\"dat6.xlsx\")\n",
    "df = df.dropna(subset=['URM'])\n",
    "df = df.drop(columns=['Dept_code'])\n",
    "\n",
    "# Define dependent variable y\n",
    "y = df['URM']\n",
    "\n",
    "# Initialize X and add fixed effects for 'Dept' and 'ADMIT_TERM'\n",
    "X = df[['st_required']]\n",
    "X = pd.concat([X, pd.get_dummies(df['Dept'], prefix='Dept', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(df['ADMIT_TERM'], prefix='ADMIT_TERM', drop_first=True)], axis=1)\n",
    "\n",
    "# Ensure all dummy variables are numeric and handle missing values\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN or infinite values\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "# Add constant to X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit model\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "result = model.fit()\n",
    "\n",
    "\n",
    "## Calculate marginal effects\n",
    "\n",
    "# Retrieve coefficients from the fitted model\n",
    "coefficients = result.params\n",
    "\n",
    "# Calculate linear predictor (XB)\n",
    "lin_pred = np.dot(X.drop(columns=['const']), coefficients[1:]) + result.params['const']\n",
    "\n",
    "# Calculate predicted probabilities using the logistic function\n",
    "predicted_probs = 1 / (1 + np.exp(-lin_pred))\n",
    "\n",
    "# Calculate marginal effects for each variable\n",
    "marginal_effects = []\n",
    "\n",
    "for i, coef in enumerate(coefficients[1:]):  # Exclude Intercept\n",
    "    marginal_effect = coef * predicted_probs * (1 - predicted_probs)\n",
    "    marginal_effects.append(marginal_effect)\n",
    "\n",
    "# Include intercept effect (if needed)\n",
    "intercept_effect = result.params['const'] * predicted_probs * (1 - predicted_probs)\n",
    "marginal_effects.append(intercept_effect)\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "marginal_effects = np.array(marginal_effects)\n",
    "average_marginal_effect_st_required = np.mean(marginal_effects[1])\n",
    "\n",
    "# Print marginal effects\n",
    "print(f\"Average marginal effects for 'st_required': {average_marginal_effect_st_required}\")\n",
    "\n",
    "# Output p-value for the coefficient of `st_required`\n",
    "p_value_st_required = result.pvalues['st_required']\n",
    "print(f\"P-value for 'st_required': {p_value_st_required}\")\n",
    "\n",
    "\n",
    "# Output result summary\n",
    "print(\"\")\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average marginal effects for 'gre_required': 0.11394736381658957\n",
      "P-value for 'gre_required': 0.05601985243627313\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               Non_Male   No. Observations:                20540\n",
      "Model:                            GLM   Df Residuals:                    20387\n",
      "Model Family:                Binomial   Df Model:                          152\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -12220.\n",
      "Date:                Thu, 11 Jul 2024   Deviance:                       24440.\n",
      "Time:                        21:47:33   Pearson chi2:                 2.05e+04\n",
      "No. Iterations:                    22   Pseudo R-squ. (CS):             0.1702\n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================================================================================\n",
      "                                                                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                                              0.0036      0.541      0.007      0.995      -1.057       1.064\n",
      "gre_required                                                                       0.1328      0.070      1.911      0.056      -0.003       0.269\n",
      "Dept_Applied Linguistics                                                           0.5572      0.301      1.852      0.064      -0.032       1.147\n",
      "Dept_Archaeology                                                                  -0.1967      0.236     -0.832      0.405      -0.660       0.267\n",
      "Dept_Architecture                                                                 -0.5569      0.247     -2.257      0.024      -1.041      -0.073\n",
      "Dept_Art History                                                                   0.4366      0.218      2.007      0.045       0.010       0.863\n",
      "Dept_Asian Lang & Cult                                                            -0.1981      0.193     -1.024      0.306      -0.577       0.181\n",
      "Dept_Astronomy                                                                    -0.8889      0.222     -4.011      0.000      -1.323      -0.455\n",
      "Dept_Atmospheric Sciences                                                         -0.6072      0.190     -3.189      0.001      -0.980      -0.234\n",
      "Dept_Bioengineering                                                               -1.3371      0.151     -8.828      0.000      -1.634      -1.040\n",
      "Dept_Bioinformatics                                                               -1.1749      0.203     -5.774      0.000      -1.574      -0.776\n",
      "Dept_Biology                                                                      -0.0110      0.174     -0.063      0.949      -0.352       0.330\n",
      "Dept_Biomedical Physics                                                           -0.9738      0.203     -4.787      0.000      -1.372      -0.575\n",
      "Dept_Biostatistics                                                                -0.5596      0.201     -2.782      0.005      -0.954      -0.165\n",
      "Dept_Chemical Engineering                                                         -1.3385      0.166     -8.058      0.000      -1.664      -1.013\n",
      "Dept_Chemistry                                                                    -1.0181      0.133     -7.642      0.000      -1.279      -0.757\n",
      "Dept_Chicana and Chicano Studies                                                   0.0706      0.251      0.281      0.779      -0.422       0.563\n",
      "Dept_Choreographic Inquiry                                                         0.3754      0.231      1.626      0.104      -0.077       0.828\n",
      "Dept_Civil Engineering                                                            -1.1988      0.159     -7.533      0.000      -1.511      -0.887\n",
      "Dept_Clinical Research                                                            -1.4120      0.298     -4.745      0.000      -1.995      -0.829\n",
      "Dept_Communication                                                                 0.2563      0.489      0.524      0.600      -0.702       1.215\n",
      "Dept_Community Health Sciences                                                     1.3492      0.345      3.909      0.000       0.673       2.026\n",
      "Dept_Comparative Literature                                                       -0.0651      0.228     -0.285      0.775      -0.512       0.382\n",
      "Dept_Computer Science                                                             -2.2584      0.152    -14.854      0.000      -2.556      -1.960\n",
      "Dept_Conservation of Material Culture                                             -0.6889      0.827     -0.833      0.405      -2.310       0.932\n",
      "Dept_Economics                                                                    -1.6334      0.159    -10.293      0.000      -1.944      -1.322\n",
      "Dept_Education                                                                     0.2347      0.138      1.702      0.089      -0.036       0.505\n",
      "Dept_Education - Joint doctoral program in Special Education w/ Cal State - LA     1.2449      0.424      2.938      0.003       0.414       2.075\n",
      "Dept_Elect. Engineerig                                                            -2.4311      0.147    -16.590      0.000      -2.718      -2.144\n",
      "Dept_English                                                                      -0.2261      0.169     -1.339      0.181      -0.557       0.105\n",
      "Dept_Environment and Sustainability                                               -0.2837      0.341     -0.831      0.406      -0.952       0.385\n",
      "Dept_Environmental Health Sciences                                                -0.1680      0.257     -0.653      0.514      -0.673       0.336\n",
      "Dept_Epidemiology                                                                  0.1287      0.168      0.768      0.442      -0.200       0.457\n",
      "Dept_Ethnomusicology                                                              -1.0547      0.328     -3.216      0.001      -1.697      -0.412\n",
      "Dept_Film and TV (MA or PhD)                                                      -0.3741      0.199     -1.884      0.060      -0.763       0.015\n",
      "Dept_French & Francophone St                                                       0.7780      0.305      2.550      0.011       0.180       1.376\n",
      "Dept_Gender Studies                                                                1.1654      0.323      3.607      0.000       0.532       1.799\n",
      "Dept_Geography                                                                    -0.5329      0.179     -2.984      0.003      -0.883      -0.183\n",
      "Dept_Geophysics & Space Phy                                                       -0.9539      0.176     -5.407      0.000      -1.300      -0.608\n",
      "Dept_Greek                                                                        -0.7143      0.239     -2.994      0.003      -1.182      -0.247\n",
      "Dept_Health Services                                                              -0.1469      0.192     -0.765      0.444      -0.523       0.229\n",
      "Dept_History                                                                      -0.5818      0.151     -3.845      0.000      -0.878      -0.285\n",
      "Dept_Human Genetics                                                               -0.3368      0.217     -1.553      0.120      -0.762       0.088\n",
      "Dept_Indo-European Studies                                                        -1.5353      0.544     -2.823      0.005      -2.601      -0.469\n",
      "Dept_Information Studies                                                          -0.3697      0.213     -1.739      0.082      -0.786       0.047\n",
      "Dept_Islamic Studies                                                              -0.9085      0.186     -4.883      0.000      -1.273      -0.544\n",
      "Dept_Italian                                                                       0.4326      0.334      1.294      0.195      -0.222       1.088\n",
      "Dept_Latin American Studies                                                       22.8367   7.95e+04      0.000      1.000   -1.56e+05    1.56e+05\n",
      "Dept_Linguistics                                                                  -0.4696      0.198     -2.370      0.018      -0.858      -0.081\n",
      "Dept_Management: M.B.A.                                                           -1.2620      0.216     -5.847      0.000      -1.685      -0.839\n",
      "Dept_Manufacturing Engr.                                                          -2.3080      0.150    -15.397      0.000      -2.602      -2.014\n",
      "Dept_Materials Science and Engineering                                            -1.7596      0.160    -11.000      0.000      -2.073      -1.446\n",
      "Dept_Mathematics                                                                  -2.2374      0.159    -14.043      0.000      -2.550      -1.925\n",
      "Dept_Molecular Biology                                                            -0.5089      0.141     -3.606      0.000      -0.785      -0.232\n",
      "Dept_Molecular Toxicology                                                         -0.2469      0.279     -0.886      0.376      -0.793       0.299\n",
      "Dept_Molecular and Medical Pharmacology                                           -0.5698      0.177     -3.223      0.001      -0.916      -0.223\n",
      "Dept_Music                                                                        -1.3402      0.277     -4.846      0.000      -1.882      -0.798\n",
      "Dept_Musicology                                                                   -0.1826      0.232     -0.786      0.432      -0.638       0.273\n",
      "Dept_Neurobiology                                                                 -0.4855      0.156     -3.102      0.002      -0.792      -0.179\n",
      "Dept_Nursing                                                                       1.0369      0.226      4.596      0.000       0.595       1.479\n",
      "Dept_Oral Biology                                                                 -0.2050      0.252     -0.815      0.415      -0.698       0.288\n",
      "Dept_Philosophy                                                                   -0.9237      0.199     -4.632      0.000      -1.314      -0.533\n",
      "Dept_Physics                                                                      -2.2620      0.166    -13.610      0.000      -2.588      -1.936\n",
      "Dept_Planetary Science                                                            -0.4984      0.684     -0.729      0.466      -1.839       0.842\n",
      "Dept_Political Science                                                            -1.0075      0.155     -6.512      0.000      -1.311      -0.704\n",
      "Dept_Psychology                                                                    0.1744      0.144      1.214      0.225      -0.107       0.456\n",
      "Dept_Public Health                                                                 0.8575      0.264      3.246      0.001       0.340       1.375\n",
      "Dept_Scandinavian Section                                                         -0.1762      0.343     -0.514      0.607      -0.848       0.496\n",
      "Dept_Slavic Lang & Lit                                                             0.0167      0.352      0.047      0.962      -0.674       0.707\n",
      "Dept_Social Welfare                                                                0.7546      0.225      3.356      0.001       0.314       1.195\n",
      "Dept_Sociology                                                                    -0.1724      0.161     -1.074      0.283      -0.487       0.142\n",
      "Dept_Spanish                                                                       0.0158      0.190      0.083      0.933      -0.356       0.387\n",
      "Dept_Statistics                                                                   -1.4655      0.180     -8.138      0.000      -1.819      -1.113\n",
      "Dept_Theater & Performance St                                                      0.4120      0.288      1.432      0.152      -0.152       0.976\n",
      "Dept_UCLA ACCESS to Programs in the Molecular and Cellular Life Sciences          -0.3551      0.152     -2.337      0.019      -0.653      -0.057\n",
      "Dept_Urban & Regional Planning                                                    -0.5263      0.210     -2.511      0.012      -0.937      -0.116\n",
      "ADMIT_TERM_F03                                                                     0.4585      0.527      0.870      0.384      -0.574       1.491\n",
      "ADMIT_TERM_F04                                                                     0.5339      0.527      1.012      0.311      -0.500       1.568\n",
      "ADMIT_TERM_F05                                                                     0.5930      0.527      1.125      0.261      -0.440       1.626\n",
      "ADMIT_TERM_F06                                                                     0.3928      0.527      0.746      0.456      -0.639       1.425\n",
      "ADMIT_TERM_F07                                                                     0.4983      0.526      0.947      0.344      -0.533       1.530\n",
      "ADMIT_TERM_F08                                                                     0.4363      0.526      0.829      0.407      -0.595       1.468\n",
      "ADMIT_TERM_F09                                                                     0.5271      0.527      1.000      0.317      -0.506       1.560\n",
      "ADMIT_TERM_F10                                                                     0.5726      0.528      1.085      0.278      -0.462       1.607\n",
      "ADMIT_TERM_F11                                                                     0.4336      0.528      0.822      0.411      -0.601       1.468\n",
      "ADMIT_TERM_F12                                                                     0.3015      0.528      0.571      0.568      -0.733       1.336\n",
      "ADMIT_TERM_F13                                                                     0.3745      0.527      0.710      0.478      -0.659       1.408\n",
      "ADMIT_TERM_F14                                                                     0.4407      0.528      0.835      0.404      -0.594       1.475\n",
      "ADMIT_TERM_F15                                                                     0.3975      0.528      0.753      0.451      -0.637       1.432\n",
      "ADMIT_TERM_F16                                                                     0.5483      0.527      1.040      0.299      -0.485       1.582\n",
      "ADMIT_TERM_F17                                                                     0.4411      0.527      0.836      0.403      -0.593       1.475\n",
      "ADMIT_TERM_F18                                                                     0.5491      0.527      1.042      0.298      -0.484       1.582\n",
      "ADMIT_TERM_F19                                                                     0.5349      0.527      1.015      0.310      -0.498       1.568\n",
      "ADMIT_TERM_F20                                                                     0.6823      0.527      1.294      0.196      -0.351       1.716\n",
      "ADMIT_TERM_F21                                                                     0.7022      0.528      1.331      0.183      -0.332       1.736\n",
      "ADMIT_TERM_F22                                                                     0.7205      0.529      1.362      0.173      -0.316       1.757\n",
      "ADMIT_TERM_F23                                                                     0.7159      0.529      1.353      0.176      -0.321       1.753\n",
      "ADMIT_TERM_S03                                                                     0.4148      1.613      0.257      0.797      -2.746       3.576\n",
      "ADMIT_TERM_S04                                                                     1.7940      0.878      2.044      0.041       0.074       3.514\n",
      "ADMIT_TERM_S05                                                                     1.7266      1.059      1.631      0.103      -0.348       3.802\n",
      "ADMIT_TERM_S06                                                                    -0.5813      0.941     -0.618      0.537      -2.426       1.263\n",
      "ADMIT_TERM_S07                                                                    -0.0493      0.939     -0.053      0.958      -1.889       1.790\n",
      "ADMIT_TERM_S08                                                                     0.6987      0.759      0.921      0.357      -0.788       2.186\n",
      "ADMIT_TERM_S09                                                                    -0.5473      0.801     -0.683      0.495      -2.117       1.023\n",
      "ADMIT_TERM_S10                                                                    -0.1943      0.675     -0.288      0.773      -1.518       1.129\n",
      "ADMIT_TERM_S11                                                                     0.8615      0.773      1.114      0.265      -0.654       2.377\n",
      "ADMIT_TERM_S12                                                                     0.1868      0.701      0.266      0.790      -1.188       1.561\n",
      "ADMIT_TERM_S13                                                                    -0.0423      0.797     -0.053      0.958      -1.604       1.520\n",
      "ADMIT_TERM_S14                                                                    -1.3081      0.937     -1.397      0.163      -3.144       0.528\n",
      "ADMIT_TERM_S15                                                                     0.4863      0.750      0.648      0.517      -0.984       1.957\n",
      "ADMIT_TERM_S16                                                                     0.1610      0.863      0.187      0.852      -1.530       1.852\n",
      "ADMIT_TERM_S17                                                                    -0.0262      0.845     -0.031      0.975      -1.681       1.629\n",
      "ADMIT_TERM_S18                                                                    -1.5227      1.159     -1.313      0.189      -3.795       0.749\n",
      "ADMIT_TERM_S19                                                                     0.5259      0.641      0.821      0.412      -0.730       1.782\n",
      "ADMIT_TERM_S20                                                                     0.9323      0.754      1.236      0.216      -0.546       2.411\n",
      "ADMIT_TERM_S21                                                                     0.5963      0.679      0.879      0.379      -0.734       1.926\n",
      "ADMIT_TERM_S22                                                                     0.9641      0.715      1.348      0.178      -0.438       2.366\n",
      "ADMIT_TERM_S23                                                                     1.3984      0.734      1.905      0.057      -0.040       2.837\n",
      "ADMIT_TERM_W03                                                                     0.5184      0.551      0.941      0.347      -0.562       1.598\n",
      "ADMIT_TERM_W04                                                                     0.8174      0.971      0.842      0.400      -1.085       2.720\n",
      "ADMIT_TERM_W05                                                                   -21.4651   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_W06                                                                   -22.0924   4.59e+04     -0.000      1.000   -8.99e+04    8.99e+04\n",
      "ADMIT_TERM_W07                                                                     0.4946      0.797      0.620      0.535      -1.068       2.057\n",
      "ADMIT_TERM_W08                                                                     0.7955      0.726      1.096      0.273      -0.627       2.218\n",
      "ADMIT_TERM_W09                                                                    -0.5147      0.748     -0.689      0.491      -1.980       0.950\n",
      "ADMIT_TERM_W10                                                                    -0.2210      0.601     -0.368      0.713      -1.399       0.957\n",
      "ADMIT_TERM_W11                                                                     0.9875      0.673      1.466      0.143      -0.332       2.307\n",
      "ADMIT_TERM_W12                                                                     1.4849      0.724      2.052      0.040       0.066       2.903\n",
      "ADMIT_TERM_W13                                                                     2.5339      0.771      3.288      0.001       1.023       4.044\n",
      "ADMIT_TERM_W14                                                                    -0.4974      0.791     -0.628      0.530      -2.049       1.054\n",
      "ADMIT_TERM_W15                                                                     1.8668      0.701      2.664      0.008       0.493       3.240\n",
      "ADMIT_TERM_W16                                                                    -0.1210      0.801     -0.151      0.880      -1.690       1.449\n",
      "ADMIT_TERM_W17                                                                     0.5496      0.804      0.684      0.494      -1.026       2.125\n",
      "ADMIT_TERM_W18                                                                     0.4887      0.647      0.756      0.450      -0.779       1.757\n",
      "ADMIT_TERM_W19                                                                     0.9962      0.729      1.366      0.172      -0.433       2.426\n",
      "ADMIT_TERM_W20                                                                    -0.2874      0.718     -0.400      0.689      -1.695       1.121\n",
      "ADMIT_TERM_W21                                                                     0.5204      0.769      0.677      0.498      -0.986       2.027\n",
      "ADMIT_TERM_W22                                                                     0.2710      0.778      0.348      0.728      -1.253       1.795\n",
      "ADMIT_TERM_W23                                                                     0.7046      0.765      0.921      0.357      -0.795       2.204\n",
      "ADMIT_TERM_X06                                                                   -21.2714   5.62e+04     -0.000      1.000    -1.1e+05     1.1e+05\n",
      "ADMIT_TERM_X07                                                                    25.1892   7.95e+04      0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_X08                                                                   -21.2714   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_X11                                                                     0.8707      1.297      0.672      0.502      -1.671       3.412\n",
      "ADMIT_TERM_X12                                                                     0.6852      1.216      0.563      0.573      -1.699       3.069\n",
      "ADMIT_TERM_X13                                                                     1.1952      1.357      0.881      0.378      -1.464       3.854\n",
      "ADMIT_TERM_X14                                                                   -21.2714   5.62e+04     -0.000      1.000    -1.1e+05     1.1e+05\n",
      "ADMIT_TERM_X15                                                                     0.8724      1.236      0.706      0.480      -1.551       3.296\n",
      "ADMIT_TERM_X16                                                                   -21.2714   4.59e+04     -0.000      1.000   -8.99e+04    8.99e+04\n",
      "ADMIT_TERM_X17                                                                     0.7215      0.977      0.738      0.460      -1.194       2.637\n",
      "ADMIT_TERM_X18                                                                   -22.5596   5.58e+04     -0.000      1.000   -1.09e+05    1.09e+05\n",
      "ADMIT_TERM_X19                                                                   -21.2714   5.62e+04     -0.000      1.000    -1.1e+05     1.1e+05\n",
      "ADMIT_TERM_X20                                                                   -21.2714   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_X21                                                                   -21.2714   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "==================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(\"dat6.xlsx\")\n",
    "df = df.dropna(subset=['Non_Male'])\n",
    "df = df.drop(columns=['Dept_code'])\n",
    "\n",
    "# Define dependent variable y\n",
    "y = df['Non_Male']\n",
    "\n",
    "# Initialize X and add fixed effects for 'Dept' and 'ADMIT_TERM'\n",
    "X = df[['st_required']]\n",
    "X = pd.concat([X, pd.get_dummies(df['Dept'], prefix='Dept', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(df['ADMIT_TERM'], prefix='ADMIT_TERM', drop_first=True)], axis=1)\n",
    "\n",
    "# Ensure all dummy variables are numeric and handle missing values\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN or infinite values\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "# Add constant to X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit model\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "result = model.fit()\n",
    "\n",
    "\n",
    "## Calculate marginal effects\n",
    "\n",
    "# Retrieve coefficients from the fitted model\n",
    "coefficients = result.params\n",
    "\n",
    "# Calculate linear predictor (XB)\n",
    "lin_pred = np.dot(X.drop(columns=['const']), coefficients[1:]) + result.params['const']\n",
    "\n",
    "# Calculate predicted probabilities using the logistic function\n",
    "predicted_probs = 1 / (1 + np.exp(-lin_pred))\n",
    "\n",
    "# Calculate marginal effects for each variable\n",
    "marginal_effects = []\n",
    "\n",
    "for i, coef in enumerate(coefficients[1:]):  # Exclude Intercept\n",
    "    marginal_effect = coef * predicted_probs * (1 - predicted_probs)\n",
    "    marginal_effects.append(marginal_effect)\n",
    "\n",
    "# Include intercept effect (if needed)\n",
    "intercept_effect = result.params['const'] * predicted_probs * (1 - predicted_probs)\n",
    "marginal_effects.append(intercept_effect)\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "marginal_effects = np.array(marginal_effects)\n",
    "average_marginal_effect_st_required = np.mean(marginal_effects[1])\n",
    "\n",
    "# Print marginal effects\n",
    "print(f\"Average marginal effects for 'st_required': {average_marginal_effect_st_required}\")\n",
    "\n",
    "# Output p-value for the coefficient of `st_required`\n",
    "p_value_st_required = result.pvalues['st_required']\n",
    "print(f\"P-value for 'st_required': {p_value_st_required}\")\n",
    "\n",
    "\n",
    "# Output result summary\n",
    "print(\"\")\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous Degree Hold: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average marginal effects for 'gre_required': 0.3341016949291302\n",
      "P-value for 'gre_required': 0.05200504738826789\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               prev_deg   No. Observations:                17149\n",
      "Model:                            GLM   Df Residuals:                    17026\n",
      "Model Family:                Binomial   Df Model:                          122\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -9765.2\n",
      "Date:                Thu, 11 Jul 2024   Deviance:                       19530.\n",
      "Time:                        21:47:40   Pearson chi2:                 1.71e+04\n",
      "No. Iterations:                    22   Pseudo R-squ. (CS):             0.1602\n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================================================================================\n",
      "                                                                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                                             -0.4165      1.435     -0.290      0.772      -3.229       2.396\n",
      "gre_required                                                                       0.1572      0.081      1.943      0.052      -0.001       0.316\n",
      "Dept_Applied Linguistics                                                           1.7246      0.360      4.788      0.000       1.019       2.430\n",
      "Dept_Archaeology                                                                   0.3651      0.236      1.546      0.122      -0.098       0.828\n",
      "Dept_Architecture                                                                  0.9070      0.294      3.090      0.002       0.332       1.482\n",
      "Dept_Art History                                                                  -0.0007      0.206     -0.003      0.997      -0.404       0.402\n",
      "Dept_Asian Lang & Cult                                                             1.5117      0.226      6.698      0.000       1.069       1.954\n",
      "Dept_Astronomy                                                                    -1.8050      0.320     -5.640      0.000      -2.432      -1.178\n",
      "Dept_Atmospheric Sciences                                                         -0.9265      0.226     -4.090      0.000      -1.370      -0.483\n",
      "Dept_Bioengineering                                                               -0.7370      0.161     -4.571      0.000      -1.053      -0.421\n",
      "Dept_Bioinformatics                                                               -1.0082      0.240     -4.195      0.000      -1.479      -0.537\n",
      "Dept_Biology                                                                      -0.4718      0.183     -2.580      0.010      -0.830      -0.113\n",
      "Dept_Biomedical Physics                                                           -0.8906      0.227     -3.915      0.000      -1.336      -0.445\n",
      "Dept_Biostatistics                                                                 0.0522      0.235      0.222      0.825      -0.409       0.514\n",
      "Dept_Chemical Engineering                                                         -1.1441      0.191     -5.994      0.000      -1.518      -0.770\n",
      "Dept_Chemistry                                                                    -1.7370      0.149    -11.672      0.000      -2.029      -1.445\n",
      "Dept_Chicana and Chicano Studies                                                  -0.2790      0.261     -1.070      0.285      -0.790       0.232\n",
      "Dept_Choreographic Inquiry                                                         0.8949      0.238      3.767      0.000       0.429       1.360\n",
      "Dept_Civil Engineering                                                             0.7720      0.176      4.381      0.000       0.427       1.117\n",
      "Dept_Clinical Research                                                            -0.6272      0.333     -1.883      0.060      -1.280       0.026\n",
      "Dept_Communication                                                                 0.0431      0.441      0.098      0.922      -0.822       0.908\n",
      "Dept_Community Health Sciences                                                     2.2732      0.383      5.939      0.000       1.523       3.023\n",
      "Dept_Comparative Literature                                                       -0.4235      0.232     -1.826      0.068      -0.878       0.031\n",
      "Dept_Computer Science                                                             -0.3831      0.145     -2.645      0.008      -0.667      -0.099\n",
      "Dept_Conservation of Material Culture                                              0.9093      0.923      0.985      0.324      -0.899       2.718\n",
      "Dept_Economics                                                                     0.1696      0.154      1.099      0.272      -0.133       0.472\n",
      "Dept_Education                                                                     0.6842      0.140      4.886      0.000       0.410       0.959\n",
      "Dept_Education - Joint doctoral program in Special Education w/ Cal State - LA     3.4460      0.732      4.705      0.000       2.011       4.882\n",
      "Dept_Elect. Engineerig                                                             0.2867      0.142      2.017      0.044       0.008       0.565\n",
      "Dept_English                                                                      -0.2894      0.172     -1.680      0.093      -0.627       0.048\n",
      "Dept_Environment and Sustainability                                               -0.3615      0.358     -1.009      0.313      -1.064       0.340\n",
      "Dept_Environmental Health Sciences                                                 0.3751      0.313      1.197      0.231      -0.239       0.989\n",
      "Dept_Epidemiology                                                                  1.1901      0.204      5.845      0.000       0.791       1.589\n",
      "Dept_Ethnomusicology                                                               1.0539      0.355      2.965      0.003       0.357       1.751\n",
      "Dept_Film and TV (MA or PhD)                                                       0.4784      0.250      1.916      0.055      -0.011       0.968\n",
      "Dept_French & Francophone St                                                      -0.1390      0.259     -0.536      0.592      -0.647       0.369\n",
      "Dept_Gender Studies                                                                0.9753      0.268      3.637      0.000       0.450       1.501\n",
      "Dept_Geography                                                                     0.0219      0.184      0.119      0.905      -0.339       0.382\n",
      "Dept_Geophysics & Space Phy                                                       -1.0042      0.205     -4.908      0.000      -1.405      -0.603\n",
      "Dept_Greek                                                                        -0.4344      0.253     -1.720      0.085      -0.929       0.061\n",
      "Dept_Health Services                                                               1.2209      0.224      5.443      0.000       0.781       1.661\n",
      "Dept_History                                                                       0.0400      0.153      0.261      0.794      -0.261       0.341\n",
      "Dept_Human Genetics                                                               -1.2925      0.301     -4.296      0.000      -1.882      -0.703\n",
      "Dept_Indo-European Studies                                                         0.0197      0.551      0.036      0.971      -1.060       1.099\n",
      "Dept_Information Studies                                                           1.2234      0.256      4.780      0.000       0.722       1.725\n",
      "Dept_Islamic Studies                                                               0.4474      0.194      2.308      0.021       0.067       0.827\n",
      "Dept_Italian                                                                      -0.1539      0.317     -0.485      0.627      -0.775       0.468\n",
      "Dept_Latin American Studies                                                      -23.3435   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "Dept_Linguistics                                                                  -0.2142      0.208     -1.028      0.304      -0.623       0.194\n",
      "Dept_Management: M.B.A.                                                            0.6348      0.222      2.855      0.004       0.199       1.070\n",
      "Dept_Manufacturing Engr.                                                          -0.2945      0.144     -2.047      0.041      -0.576      -0.013\n",
      "Dept_Materials Science and Engineering                                            -0.1396      0.160     -0.871      0.384      -0.454       0.175\n",
      "Dept_Mathematics                                                                  -1.0752      0.156     -6.908      0.000      -1.380      -0.770\n",
      "Dept_Molecular Biology                                                            -0.7581      0.155     -4.890      0.000      -1.062      -0.454\n",
      "Dept_Molecular Toxicology                                                         -0.6788      0.339     -2.004      0.045      -1.343      -0.015\n",
      "Dept_Molecular and Medical Pharmacology                                           -1.1912      0.220     -5.414      0.000      -1.622      -0.760\n",
      "Dept_Music                                                                         1.3052      0.307      4.256      0.000       0.704       1.906\n",
      "Dept_Musicology                                                                    0.6155      0.243      2.537      0.011       0.140       1.091\n",
      "Dept_Neurobiology                                                                 -1.5352      0.202     -7.617      0.000      -1.930      -1.140\n",
      "Dept_Nursing                                                                       1.1262      0.214      5.260      0.000       0.707       1.546\n",
      "Dept_Oral Biology                                                                 -0.2341      0.306     -0.765      0.444      -0.834       0.365\n",
      "Dept_Philosophy                                                                    0.1201      0.203      0.591      0.555      -0.279       0.519\n",
      "Dept_Physics                                                                      -1.6850      0.177     -9.508      0.000      -2.032      -1.338\n",
      "Dept_Planetary Science                                                            -1.6305      1.070     -1.524      0.128      -3.728       0.467\n",
      "Dept_Political Science                                                             0.0555      0.157      0.355      0.723      -0.251       0.363\n",
      "Dept_Psychology                                                                   -1.4815      0.158     -9.353      0.000      -1.792      -1.171\n",
      "Dept_Public Health                                                                 0.6821      0.266      2.560      0.010       0.160       1.204\n",
      "Dept_Scandinavian Section                                                          0.6676      0.389      1.715      0.086      -0.095       1.431\n",
      "Dept_Slavic Lang & Lit                                                            -1.3396      0.468     -2.865      0.004      -2.256      -0.423\n",
      "Dept_Social Welfare                                                                0.6828      0.212      3.222      0.001       0.267       1.098\n",
      "Dept_Sociology                                                                    -0.2822      0.163     -1.729      0.084      -0.602       0.038\n",
      "Dept_Spanish                                                                       0.3559      0.196      1.820      0.069      -0.027       0.739\n",
      "Dept_Statistics                                                                   -0.2047      0.191     -1.073      0.283      -0.579       0.169\n",
      "Dept_Theater & Performance St                                                      1.2092      0.292      4.144      0.000       0.637       1.781\n",
      "Dept_UCLA ACCESS to Programs in the Molecular and Cellular Life Sciences          -1.8116      0.186     -9.750      0.000      -2.176      -1.447\n",
      "Dept_Urban & Regional Planning                                                     1.1079      0.250      4.425      0.000       0.617       1.599\n",
      "ADMIT_TERM_F03                                                                    -0.0558      1.430     -0.039      0.969      -2.858       2.746\n",
      "ADMIT_TERM_F04                                                                     0.1181      1.430      0.083      0.934      -2.684       2.920\n",
      "ADMIT_TERM_F05                                                                     0.0366      1.430      0.026      0.980      -2.766       2.839\n",
      "ADMIT_TERM_F06                                                                     0.0024      1.430      0.002      0.999      -2.799       2.804\n",
      "ADMIT_TERM_F07                                                                     0.0463      1.430      0.032      0.974      -2.756       2.848\n",
      "ADMIT_TERM_F08                                                                     0.0089      1.429      0.006      0.995      -2.793       2.811\n",
      "ADMIT_TERM_F09                                                                     0.0170      1.430      0.012      0.991      -2.785       2.819\n",
      "ADMIT_TERM_F10                                                                     0.0280      1.430      0.020      0.984      -2.775       2.831\n",
      "ADMIT_TERM_F11                                                                     0.2130      1.430      0.149      0.882      -2.590       3.016\n",
      "ADMIT_TERM_F12                                                                     0.2173      1.430      0.152      0.879      -2.585       3.020\n",
      "ADMIT_TERM_F13                                                                     0.3306      1.430      0.231      0.817      -2.472       3.133\n",
      "ADMIT_TERM_F14                                                                     0.3573      1.430      0.250      0.803      -2.445       3.160\n",
      "ADMIT_TERM_F15                                                                     0.2057      1.430      0.144      0.886      -2.597       3.008\n",
      "ADMIT_TERM_F16                                                                    -0.0044      1.430     -0.003      0.998      -2.807       2.798\n",
      "ADMIT_TERM_F17                                                                    -0.9169      1.433     -0.640      0.522      -3.725       1.891\n",
      "ADMIT_TERM_F18                                                                    -0.2424      1.430     -0.170      0.865      -3.045       2.560\n",
      "ADMIT_TERM_F19                                                                    -0.1962      1.430     -0.137      0.891      -2.999       2.606\n",
      "ADMIT_TERM_F20                                                                    -0.1366      1.430     -0.096      0.924      -2.939       2.666\n",
      "ADMIT_TERM_F21                                                                    -0.0501      1.430     -0.035      0.972      -2.853       2.753\n",
      "ADMIT_TERM_F22                                                                    -0.1593      1.431     -0.111      0.911      -2.963       2.644\n",
      "ADMIT_TERM_F23                                                                     0.0607      1.431      0.042      0.966      -2.743       2.865\n",
      "ADMIT_TERM_S04                                                                    -0.3156      2.128     -0.148      0.882      -4.486       3.854\n",
      "ADMIT_TERM_S06                                                                     3.4493      1.808      1.908      0.056      -0.094       6.992\n",
      "ADMIT_TERM_S07                                                                   -23.6730    4.4e+04     -0.001      1.000   -8.62e+04    8.62e+04\n",
      "ADMIT_TERM_S08                                                                    -0.0844      1.686     -0.050      0.960      -3.389       3.220\n",
      "ADMIT_TERM_S09                                                                     0.0621      1.607      0.039      0.969      -3.087       3.211\n",
      "ADMIT_TERM_S10                                                                     0.3240      1.597      0.203      0.839      -2.806       3.454\n",
      "ADMIT_TERM_S11                                                                   -21.4953   5.62e+04     -0.000      1.000    -1.1e+05     1.1e+05\n",
      "ADMIT_TERM_S12                                                                    23.3779   7.95e+04      0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_S14                                                                     1.3566      2.076      0.653      0.514      -2.713       5.426\n",
      "ADMIT_TERM_S15                                                                   -23.0124   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_S17                                                                   -23.0124   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_S20                                                                   -23.5935   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_W03                                                                     1.0294      1.466      0.702      0.483      -1.845       3.904\n",
      "ADMIT_TERM_W04                                                                   -23.3061   4.59e+04     -0.001      1.000   -8.99e+04    8.99e+04\n",
      "ADMIT_TERM_W06                                                                   -22.9449   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_W07                                                                     0.5402      1.647      0.328      0.743      -2.689       3.769\n",
      "ADMIT_TERM_W08                                                                     0.5039      1.606      0.314      0.754      -2.644       3.651\n",
      "ADMIT_TERM_W09                                                                    -1.6949      1.800     -0.942      0.346      -5.223       1.833\n",
      "ADMIT_TERM_W10                                                                    -0.3613      1.532     -0.236      0.813      -3.363       2.641\n",
      "ADMIT_TERM_W11                                                                    -1.5281      1.645     -0.929      0.353      -4.753       1.697\n",
      "ADMIT_TERM_W12                                                                   -22.3026   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_W13                                                                   -22.5634   4.51e+04     -0.001      1.000   -8.84e+04    8.83e+04\n",
      "ADMIT_TERM_W15                                                                    24.1198   7.95e+04      0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_W16                                                                    23.4556   4.42e+04      0.001      1.000   -8.65e+04    8.66e+04\n",
      "ADMIT_TERM_W17                                                                   -23.0124   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "ADMIT_TERM_W18                                                                   -23.0124   7.95e+04     -0.000      1.000   -1.56e+05    1.56e+05\n",
      "==================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(\"dat6.xlsx\")\n",
    "df = df.dropna(subset=['prev_deg'])\n",
    "df = df.drop(columns=['Dept_code'])\n",
    "\n",
    "# Define dependent variable y\n",
    "y = df['prev_deg']\n",
    "\n",
    "# Initialize X and add fixed effects for 'Dept' and 'ADMIT_TERM'\n",
    "X = df[['st_required']]\n",
    "X = pd.concat([X, pd.get_dummies(df['Dept'], prefix='Dept', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(df['ADMIT_TERM'], prefix='ADMIT_TERM', drop_first=True)], axis=1)\n",
    "\n",
    "# Ensure all dummy variables are numeric and handle missing values\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN or infinite values\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "# Add constant to X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit model\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "result = model.fit()\n",
    "\n",
    "\n",
    "## Calculate marginal effects\n",
    "\n",
    "# Retrieve coefficients from the fitted model\n",
    "coefficients = result.params\n",
    "\n",
    "# Calculate linear predictor (XB)\n",
    "lin_pred = np.dot(X.drop(columns=['const']), coefficients[1:]) + result.params['const']\n",
    "\n",
    "# Calculate predicted probabilities using the logistic function\n",
    "predicted_probs = 1 / (1 + np.exp(-lin_pred))\n",
    "\n",
    "# Calculate marginal effects for each variable\n",
    "marginal_effects = []\n",
    "\n",
    "for i, coef in enumerate(coefficients[1:]):  # Exclude Intercept\n",
    "    marginal_effect = coef * predicted_probs * (1 - predicted_probs)\n",
    "    marginal_effects.append(marginal_effect)\n",
    "\n",
    "# Include intercept effect (if needed)\n",
    "intercept_effect = result.params['const'] * predicted_probs * (1 - predicted_probs)\n",
    "marginal_effects.append(intercept_effect)\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "marginal_effects = np.array(marginal_effects)\n",
    "average_marginal_effect_st_required = np.mean(marginal_effects[1])\n",
    "\n",
    "# Print marginal effects\n",
    "print(f\"Average marginal effects for 'st_required': {average_marginal_effect_st_required}\")\n",
    "\n",
    "# Output p-value for the coefficient of `st_required`\n",
    "p_value_st_required = result.pvalues['st_required']\n",
    "print(f\"P-value for 'st_required': {p_value_st_required}\")\n",
    "\n",
    "\n",
    "# Output result summary\n",
    "print(\"\")\n",
    "print(result.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
